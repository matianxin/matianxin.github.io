<<<<<<< HEAD
<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[解决Docker pull镜像速度过慢的问题]]></title>
    <url>%2F2020%2F07%2F06%2FDocker%2FdockerProxy%2F</url>
    <content type="text"><![CDATA[目前，Docker拥有中国的官方镜像，具体内容可访问https://www.docker-cn.com/registry-mirror 在使用时，Docker 中国官方镜像加速可通过 registry.docker-cn.com访问。该镜像库只包含流行的公有镜像。私有镜像仍需要从美国镜像库中拉取。 您可以使用以下命令直接从该镜像加速地址进行拉取： $ docker pull registry.docker-cn.com/myname/myrepo:mytag例如: $ docker pull registry.docker-cn.com/library/ubuntu:16.04注: 除非您修改了 Docker 守护进程的 --registry-mirror 参数 (见下文), 否则您将需要完整地指定官方镜像的名称。例如，library/ubuntu、library/redis、library/nginx。 使用 –registry-mirror 配置 Docker 守护进程您可以配置 Docker 守护进程默认使用 Docker 官方镜像加速。这样您可以默认通过官方镜像加速拉取镜像，而无需在每次拉取时指定 registry.docker-cn.com。 您可以在 Docker 守护进程启动时传入 –registry-mirror 参数： $ docker –registry-mirror=https://registry.docker-cn.com daemon为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。 123&#123; "registry-mirrors": ["https://registry.docker-cn.com"]&#125; 修改保存后重启 Docker 以使配置生效。 1systemctl docker restart 注: 您也可以使用适用于 Mac 的 Docker 和适用于 Windows 的 Docker 来进行设置。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7部署dzzoffice私有网盘]]></title>
    <url>%2F2020%2F07%2F06%2FOther%2Fdzzoffice%2F</url>
    <content type="text"><![CDATA[搭建Lamp框架(Linux+apache+mariadb+php)1.首先安装wget 1yum install -y wget 2.下载epel额外包及YUM源配置 12wget https://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-7 #epel额外包的密钥wget https://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm #epel额外包的yum的配置 3.导入密钥，为了防止安装错误，安装yum的配置文件 12rpm --import RPM-GPG-KEY-EPEL-7 #导入epel额外包的密钥rpm -ivh epel-release-latest-7.noarch.rpm #安装epel额外包的yum配置 4.安装升级php，作为依赖httpd都安装好了，apache(httpd)和php就安装好了 1234567891011121314yum install -y php php-mysql #升级php的软件包 php x86_64 7.3.4-1.el7.remi php 3.2 M为依赖而安装: libargon2 x86_64 20161029-3.el7 epel 23 k apr x86_64 1.4.8-3.el7_4.1 centos 103 k apr-util x86_64 1.5.2-6.el7 centos 92 k httpd x86_64 2.4.6-88.el7.centos centos 2.7 M httpd-tools x86_64 2.4.6-88.el7.centos centos 90 k mailcap noarch 2.1.41-2.el7 centos 31 k php-cli x86_64 7.3.4-1.el7.remi php 4.9 M php-common x86_64 7.3.4-1.el7.remi php 1.1 M php-json x86_64 7.3.4-1.el7.remi php 63 k——————————— 5.安装mariadb数据库 1yum -y install mariadb mariadb-server #安装mariadb数据库 6.关闭防火墙服务及关机selinux 1234systemctl stop firewalldsystemctl disable firewalldsetenforce 0vim /etc/selinux/config -&gt; disabled 7.开启mariadb和httpd,设置开机自动启动；执行脚本，设置mariadb数据库参数 1234567891011121314151617181920212223[root@localhost ~]# systemctl start mariadb #开启mariadb[root@localhost ~]# systemctl start httpd #开启httpd[root@localhost ~]# systemctl enable mariadb #设置开机自动开启mariadb[root@localhost ~]# systemctl enable httpd #设置开机自动开启httpdmysql_secure_installation #执行脚本...#省略部分内容Set root password? [Y/n] yNew password: 123456Re-enter new password: 123456Password updated successfully!Reload privilege tables now? [Y/n] y ... Success!Disallow root login remotely? [Y/n] n ... skipping.Remove test database and access to it? [Y/n] y - Dropping test database... ... Success! - Removing privileges on test database... ... Success!Reload privilege tables now? [Y/n] y ... Success! 安装dzzoffice1.下载最新稳定版本，我现在是2.02为最新版 1wget https://github.com/zyx0814/dzzoffice/archive/2.02.tar.gz 2.解压文件 1tar -zxvf 2.02.tar.gz 3.将解压后的文件移动到apache的目录下，并改名为dzzoffice 1mv dzzoffice-2.02 /var/www/html/dzzoffice 4.然后将目录权限授权给apache启动用户，默认为apache用户，如果自己修改了，则以你修改的为准 12cd /var/www/html/chown -R apache. dzzoffice 5.启动apache 12systemctl start httpdsystemctl enable httpd # 设置开机启动apache 访问页面进行安装上一步已启动apache，现在可以直接访问你服务器的ip或域名，后跟dzzoffice的路径来来访问dzzoffice，访问如：http://ip/dzzoffice 会自动跳转到安装界面： 安装完成后，手动删除安装文件rm -rf /var/www/html/dzzoffice/install/index.php 安装onlyoffice插件dzzoffice本身不支持excel或者文档的在线浏览和编辑，需要额外的第三方工具进行支持，在官方文档中也有说明：http://dzzoffice.com/corpus/list?cid=3# 这里我现在安装onlyoffice作为在线文档服务器，部署方式，由于直接在服务器上部署比较繁琐，这里我直接使用docker部署docker版本。首先安装docker，然后用docker启动onlyoffice 1.删除旧版本，确保机器没有docker 12yum remove docker docker-client docker-client-latest docker-common \ docker-latest docker-latest-logrotate docker-logrotate docker-engine 2.安装依赖 1yum install -y yum-utils device-mapper-persistent-data lvm2 3.安装yum仓库 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 4.安装docker 1yum install docker-ce docker-ce-cli containerd.io 5.启动docker 12systemctl start dockersystemctl enable docker 6.启动onlyoffice，使用本地的8000端口 1docker run -i -t -d -p8000:80 --restart=always onlyoffice/documentserver 启动onlyoffice服务后，在浏览器中访问http://ip:8000查看是否可以正常使用，如果出现如下界面，则为正常 √ Document Server is running 12345678910请输入OnlyOffice Document Server API地址:http://DZZOFFICE_IP:8000填写您的onlyoffice Document Server API地址，如:http://192.168.0.2:90/ 根据你的文档服务器填写请输入文件服务器(dzzoffice服务器)地址:填写您的文件服务器地址，如:http://dzzoffice.com:90/,根据你的dzzoffice服务器地址填写,留空使用当前地址。tips:设置内网地址可以提高文件传输速度缩略图后缀列表:支持生成缩略图的后缀列表，用小写字母。多个用英文逗号隔开，如：pdf,doc,docx,ppt,pptx,xls,xlsx 点击保存，然后启动应用 然后在文档，excel应用中，就可以直接点击在线浏览和编辑啦。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Too many open files的四种解决办法]]></title>
    <url>%2F2020%2F06%2F01%2FLinux%2FTooManyOpenFiles%2F</url>
    <content type="text"><![CDATA[【摘要】Too many open files有四种可能: 一 单个进程打开文件句柄数过多 二 操作系统打开的文件句柄数过多 三 systemd对该进程进行了限制 四 inotify达到上限 单个进程打开文件句柄数过多ulimit中的nofile表示单进程可以打开的最大文件句柄数，可以通过ulimit -a查看，子进程默认继承父进程的限制（注意，是继承，不是共享，子进程和父进程打开的文件句柄数是单独算的）。 网上还有一种解读是nofile表示单用户可以打开的文件句柄数，因为他们在limit.conf中看到类似于”openstack soft nofile 65536”，便认为是openstack用户最多可以打开的文件句柄数。该解读是错误的，”openstack soft nofile 65536”表示的含义是当你执行”su - openstack”切换到openstack用户后，你创建的所有进程最大可以打开的文件句柄数是65536。要查看一个进程可以打开的文件句柄数，可以通过”cat /proc//limits”查看。 要修改ulimit中的nofile，可以通过修改/etc/security/limits.conf文件，在其中加入类似”openstack soft nofile 65536”的语句来进行修改。修改完成后，可以通过”su - openstack”切换用户，或者重新登录，来使该配置生效。 要动态修改一个进程的限制，可以使用prlimit命令，具体用法为：”prlimit –pid ${pid} –nofile=102400:102400”。 操作系统打开的文件句柄数过多整个操作系统可以打开的文件句柄数是有限的，受内核参数”fs.file-max”影响。 可以通过执行”echo 100000000 &gt; /proc/sys/fs/file-max”命令来动态修改该值，也可以通过修改”/etc/sysctl.conf”文件来永久修改该值。 systemd对该进程进行了限制该场景仅针对被systemd管理的进程（也就是可以通过systemctl来控制的进程）生效，可以通过修改该进程的service文件（通常在/etc/systemd/system/目录下），在”[Service]”下面添加”LimitNOFILE=20480000”来实现，修改完成之后需要执行”systemctl daemon-reload”来使该配置生效。 inotify达到上限inotify是linux提供的一种监控机制，可以监控文件系统的变化。该机制受到2个内核参数的影响：”fs.inotify.max_user_instances”和 “fs.inotify.max_user_watches”，其中”fs.inotify.max_user_instances”表示每个用户最多可以创建的inotify instances数量上限，“fs.inotify.max_user_watches”表示么个用户同时可以添加的watch数目，当出现too many open files问题而上面三种方法都无法解决时，可以尝试通过修改这2个内核参数来生效。修改方法是修改”/etc/sysctl.conf”文件，并执行”sysctl -p”。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF中Crypto题目的常见题型]]></title>
    <url>%2F2020%2F05%2F20%2FCTF%2FCTFCrypto%2F</url>
    <content type="text"><![CDATA[CTF中Crypto题目的常见题型 BugKu 提供了很多加解密工具，链接：http://tool.bugku.com/ SSL在线工具网址提供了很多工具，链接：http://www.ssleye.com/ text bin hex base64 dec 转码工具：https://conv.darkbyte.ru/ 1. 摩斯密码 / Morse编码摩尔斯电码(Morse code)是一种时通时断的信号代码，通过不同的排列 顺序来表达不同的英文字母、数字和标点符号。是由美国人艾尔菲德·维 尔(Alfred Lewis Vail)与萨缪尔·摩尔斯(Samuel Finley Breese Morse) 在1836年发明。由点（·）和划（-）组成。 特征：点和横的组合。 在线工具：http://www.zhongguosou.com/zonghe/moErSiCodeConverter.aspxhttp://tool.bugku.com/mosi/ 例如：-… -.- -.-. - ..-. – .. … -.-. 解密结果：BKCTFMISC –/—/.-./…/.解密结果：MORSE 2.ASCII编码ASCII(American Standard Code for Information Interchange，美国信息交换标准代码)是基于拉丁字母的一套 电脑编码系统，主要用于显示现代英语和其他西欧语言。它是现今最通用的单字节编码系统，并等同于国际标准ISO/IEC 646。 例如：72 105 65 115 99 105 105解密结果：H i A s c i i 特点：一般常用字符为0-9（48-57）、A-Z（65-90）、a-z（97-122）、空格（32） 在线工具：http://www.ab126.com/goju/1711.html 3.Tap Code敲击码敲击码(Tap code)是一种以非常简单的方式对文本信息进行 编码的方法。因该编码对信息通过使用一系列的点击声音来编 码而命名，敲击码是基于 5 ×5 方格波利比奥斯方阵来实现的， 不同点是是用 K 字母被整合到 C 中。 1 2 3 4 51 A B C/K D E2 F G H I J3 L M N O P4 Q R S T U5 V W X Y Z 例如：2,3 1,5 3,1 3,1 3,4.. …/. …../… ./… ./… …./解密结果：H E L L O ps. 当出现1,3时，对比C/K，选择更合适的结果 4.Base编码Base64是网络上最常见的用于传输8Bit字节码的编码方式之一，Base64 就是一种基于64(65)个可打印字符来表示二进制数据的方法。 a-z、A-Z、0-9、符号“+”、“/”（再加上作为补位的”=”，实际上是 65个字符） 。 Base xx 中的 xx 表示的是采用多少个字符进行编码，比如说 base64 就是采用 64 个字符编码，由于 2 的 6 次方等于 64，所以每 6 个比特 为一个单元，对应某个可打印字符。 例如：d2VsY29tZQ==解密结果：welcome 特点：base64 结尾可能会有=号，但最多有2个 。 base32 结尾可能会有=号,最多有 3 个等号。根据 base 的不同，字符集会有所限制 。 有可能需要自己加等号。 在线工具：http://tool.chinaz.com/tools/base64.aspx 5.URL编码URL编码,又叫百分号编码，是统一资源定位(URL)编码方式。URL地址（常说网址）规定了常用地数字，字母可以直接使用，另外一批作为特殊用户字符也可以直接用（/,:@等），剩下的其它所有字符必须通过%xx编码 处理。现在已经成为一种规范了，基本所有程序语言都有这种编码，如js： 有encodeURI、encodeURIComponent，PHP有urlencode、urldecode等。编 码方法很简单，在该字节ascii码的的16进制字符前面加%.如空格字符， ascii码是32，对应16进制是‘20’，那么urlencode编码结果是:%20。 例如：URL%E7%BC%96%E7%A0%81解密结果：URL编码 特点：存在大量的%在线工具：https://tool.oschina.net/encode?type=4 6.Unicode编码Unicode（统一码、万国码、单一码）是计算机科学领域里的一项业界 标准,包括字符集、编码方案等。Unicode是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。1990年开始研发，1994年正式公布。 例如：&#72;&#101;&#108;&#108;&#111;&#67;&#84;&#70;解密结果：HelloCTF在线工具：https://tool.oschina.net/encode 7.jsfuckJSFuck 可以让你只用6个字符 !+来编写 JavaScript 程序在线工具：https://www.bugku.com/tools/jsfuck/ 8.brainfuckBrainfuck 是一种极小化的计算机语言，按照”Turing complete(完整图灵机) “思想设计的语言，它的主要设计思路是:用最小的概念实现一种“简单”的语 言，BrainFXXk语言只有八种符号，所有的操作都由这八种符号 &gt; &lt; + - . , [ ] 的组合来完成。 例如：+++++ +++++ [-&gt;++ +++++ +++&lt;] &gt;++++ .—. +++++ ++..+ ++.&lt;+ +++++ ++[-&gt;—– —&lt;] &gt;—. &lt;++++ ++++[ -&gt;+++ +++++ &lt;]&gt;++ +++++ ++++. —– —.+++.– —-. —– —.&lt; 解密结果：hello,world在线工具：https://www.splitbrain.org/services/ook 9.凯撒密码凯撒密码（Caesar）加密时会将明文中的每个字母都按照其在字母表中的顺序向后（或向前）移动固定数目（循环移动）作为密文。例如，当偏移量是左移 3 的时候（解密时 的密钥就是 3）。使用时，加密者查找明文字母表中需要加密的消息中的每一个字母所在位置，并且写下密文字母表中对应的字母。需要解密的人则根据事先已知的密钥反过来操作，得到原来的明文。 根据偏移量的不同，还存在若干特定的恺撒密码名称：偏移量为 10：Avocat （A→K）偏移量为 13：ROT13偏移量为 -5：Cassis （K 6）偏移量为 -6：Cassette （K 7） 例如：Uryyb,Jrypbzr解密结果：Hello,Welcome在线工具：http://www.mxcz.net/tools/rot13.aspx 10.栅栏密码特征：大小写和字符，其实就是分组替换加密 例如：一只小羊翻过了2个栅栏 KYsd3js2E{a2jda} 解密结果：KEY{sad23jjdsa2}在线工具：http://tool.bugku.com/jiemi/ 11.Ook 密码特征：Brainfuck 类型密码，密文由 Ook 和 三种标点 . ! ? 构成，不见得都得用上，有的是Ook，有的没有Ook只有标点。 在线工具：https://tool.bugku.com/brainfuck/ 12.类栅栏密码特征：会给你一串乱序的密文 C，同时给你从1 到 n 的一串乱序的数，找下 C 对于 n 的最大公约数，然后将他们重新排序。动手画一画就出来了 BugKu中的一道题：lf5{ag024c483549d7fd@@1} ， 一张纸条上凌乱的写着2 1 6 5 3 4 2 1 6 5 3 4l f 5 { a g0 2 4 c 4 83 5 4 9 d 7f d @ @ 1 }再按照123456的顺序数从第一行排到最后一行 flag{52048c453d794df1}@@ 提交 flag发现不对，这两个@@有点奇怪，去掉@就成功了，那么一般这种字符都是迷惑人的。 13.由0和1组成的摩斯密码特征：密文由0和1构成，可能由空格、tab或则其他字符分割，去掉这些分割后，0和1的总数是5的倍数将 0 和 1 替换为 . 或 - ，多试几次就可能有发现。 BugKu中的一道题： 0010 0100 01 110 1111011 11 11111 010 000 0 001101 1010 111 100 0 001101 01111 000 001101 00 10 1 0 010 0 000 1 01111 10 11110 101011 1111101 把0换成点 . 1换成 - 后：..-. .-.. .- –. —-.– – —– .-. … . ..–.- -.-. — -.. . ..–.- .—- … ..–.- .. -. - . .-. . … - .—- -. —-. -.-.– —–.-在线工具解密一下，得到： FLAG%u7bM0RSE_CODE_1S_INTEREST1N9!%u7d 结果有点奇怪，但八九不离十了。把%u7b 换成 { 把%u7d 换成 }，然后大小写切换 flag{m0rse_code_1s_interest1n9!} 14.键盘格子密码特征：由三到四个英文字母或数字为一组。 在键盘上找对应的键位，中间围起来的就是密文（这能能想得出。。。） 例如：r5yG lp9I BjM tFhBT6uh y7iJ QsZ bhM解密结果：t o n g y u a n 15.托马斯杰斐逊 转轮密码特征：给你一个密码表，n行的26个字母，key是 1 - n 的数列， 密文是 n 个英文字母根据 key 找对应行的密码表，然后在密码表上找密文字母，以这个字母为开头，重新排序。1： &lt;ZWAXJGDLUBVIQHKYPNTCRMOSFE &lt; 2： &lt;KPBELNACZDTRXMJQOYHGVSFUWI &lt; 3： &lt;BDMAIZVRNSJUWFHTEQGYXPLOCK &lt; 4： &lt;RPLNDVHGFCUKTEBSXQYIZMJWAO &lt; 5： &lt;IHFRLABEUOTSGJVDKCPMNZQWXY &lt; 6： &lt;AMKGHIWPNYCJBFZDRUSLOQXVET &lt; 7： &lt;GWTHSPYBXIZULVKMRAFDCEONJQ &lt; 8： &lt;NOZUTWDCVRJLXKISEFAPMYGHBQ &lt; 9： &lt;QWATDSRFHENYVUBMCOIKZGJXPL &lt; 10： &lt;WABMCXPLTDSRJQZGOIKFHENYVU &lt; 11： &lt;XPLTDAOIKFZGHENYSRUBMCQWVJ &lt; 12： &lt;TDSWAYXPLVUBOIKZGJRFHENMCQ &lt; 13： &lt;BMCSRFHLTDENQWAOXPYVUIKZGJ &lt; 14： &lt;XPHKZGJTDSENYVUBMLAOIRFCQW &lt; 密钥： 2,5,1,3,6,4,9,7,8,14,10,13,11,12密文：HCBTSXWCRQGL ES 在第 2 行密码表中找H开头的字母，然后以H开头再到尾过一遍，以此类推，整理出另一个密码表： HGVSFUWIKPBELNACZDTR X MJQOYCPMNZQWXYIHFRLABEUOT S GJVDKBVIQHKYPNTCRMOSFEZWA X JGDLUTEQGYXPLOCKBDMAIZVRN S JUWFHSLOQXVETAMKGHIWPNYCJ B FZDRUXQYIZMJWAORPLNDVHGFC U KTEBSWATDSRFHENYVUBMCOIKZ G JXPLQCEONJQGWTHSPYBXIZULV K MRAFDRJLXKISEFAPMYGHBQNOZ U TWDCVQWXPHKZGJTDSENYVUBML A OIRFCGOIKFHENYVUWABMCXPLT D SRJQZLTDENQWAOXPYVUIKZGJB M CSRFHENYSRUBMCQWVJXPLTDAO I KFZGHSWAYXPLVUBOIKZGJRFHE N MCQTD 然后在这里找一些比较明显的（语句通顺的）话，就是flag。 XSXSBUGKUADMIN提交不对的话就大小写换一下：xsxsbugkuadmin 这个其实可以写个程序出来，遍历密码表即可。 1234567891011121314151617181920212223242526272829303132333435363738# Rotor cipher decoder# parameter inputrotor = [ "ZWAXJGDLUBVIQHKYPNTCRMOSFE", "KPBELNACZDTRXMJQOYHGVSFUWI", "BDMAIZVRNSJUWFHTEQGYXPLOCK", "RPLNDVHGFCUKTEBSXQYIZMJWAO", "IHFRLABEUOTSGJVDKCPMNZQWXY", "AMKGHIWPNYCJBFZDRUSLOQXVET", "GWTHSPYBXIZULVKMRAFDCEONJQ", "NOZUTWDCVRJLXKISEFAPMYGHBQ", "QWATDSRFHENYVUBMCOIKZGJXPL", "WABMCXPLTDSRJQZGOIKFHENYVU", "XPLTDAOIKFZGHENYSRUBMCQWVJ", "TDSWAYXPLVUBOIKZGJRFHENMCQ", "BMCSRFHLTDENQWAOXPYVUIKZGJ", "XPHKZGJTDSENYVUBMLAOIRFCQW"]cipher = "HCBTSXWCRQGLES"key = [2, 5, 1, 3, 6, 4, 9, 7, 8, 14, 10, 13, 11, 12]tmp_list=[]for i in range(0, len(rotor)): tmp="" k = key[i] - 1 for j in range(0, len(rotor[k])): if cipher[i] == rotor[k][j]: if j == 0: tmp=rotor[k] break else: tmp=rotor[k][j:] + rotor[k][0:j] break tmp_list.append(tmp)# print(tmp_list)message_list = []for i in range(0, len(tmp_list[i])): tmp = "" for j in range(0, len(tmp_list)): tmp += tmp_list[j][i] message_list.append(tmp)print(message_list) 16.Base91编码特征：基本上是键盘上所有可打印的 ASC II 字符 1（0x21-0x7E），A-Z、a-z、1 - 9、 !@#$%^&amp;*()_+-=&#123;&#125;[]|\:;"'&lt;,&gt;.?/~· 之类的。 参考： http://base91.sourceforge.net/ （里面有工具源码）在线工具：http://ctf.ssleye.com/base91.html 17.Linux系统的 shadow 文件格式特征：就是Linux的shadow文件格式工具：Kali Linux 中的 Johnroot:$6$HRMJoyGA$26FIgg6CU0bGUOfqFB0Qo9AE2LRZxG8N3H.3BK8t49wGlYbkFbxVFtGOZqVIq3qQ6k0oetDbn2aVzdhuVQ6US.:17770:0:99999:7:::Linux的 /etc/shadow 文件存储了该系统下所有用户口令相关信息，只有 root 权限可以查看，用户口令是以 Hash + Salt 的形式保护的。每个字段都用 “$” 或“:”符号分割；第一个字段是用户名，如root ；第二个字段是哈希算法，比如 6 代表SHA-512，1 代表 MD5；第三个字段是盐，比如上面的 HRMJoyGA第四个字段是口令+盐加密后的哈希值后面分别是密码最后一次修改日期、密码的两次修改间隔时间（和第三个字段相比）、密码的有效期(和第三个字段相比）、密码修改到期前的警告天数（和第五个字段相比）、密码过期后的宽限天数（和第五个字段相比）、账号失效时间，这里不太重要要； 直接跑 John 试试john shadow如果解开了，加 –show 查看解密口令john –show shadow 18.ZIP 伪加密特征：一个ZIP压缩包，建议先读一下Zip文件解析与利用，里面提到：一格zip文件有三个部分组成：压缩源文件数据区 + 压缩源文件目录区 + 压缩源文件目录结束标志；每一部分都由明文 PK （50 4B）开始；这是三个头标记，主要看第二个；压缩源文件数据区：50 4B 03 04：这是头文件标记压缩源文件目录区：50 4B 01 02：目录中文件文件头标记后面两位（如 1F 00 或 3F 00）：压缩使用的 pkware 版本再后面两位（如 14 00）：解压文件所需 pkware 版本再后面两位：全局方式位标记（有无加密，这个更改这里进行伪加密，00 00 是无密码，改为09 00打开就会提示有密码了）压缩源文件目录结束标志 ：50 4B 05 06：目录结束标记工具：ZipCenOp.jar 或 WinHexe.g. BugKu 上的一道题 https://ctf.bugku.com/challenges#zip%E4%BC%AA%E5%8A%A0%E5%AF%86 使用 ZipCenOp.jar链接：https://pan.baidu.com/s/1yDcWWhY0lSlBArEJ4S6qUw提取码：g3it（需要java环境）windows下在cmd中输入：java -jar ZipCenOp.jar r xxx.zip 直接破解ZIP包； 使用 WinHex我们用winhex打开压缩包，搜索504B，点击第二个504B，从后面找第七、八位，发现是 09 00，改为 00 00 即可。这种方式只适用于ZIP的伪加密，真加密了此方法不适用。 19.RSA 加解密特征：给一些 RSA 算法的参数，然后加密\解密消息获取 flag。说一下 RSA 算法模式：分三部分，密钥生成、加密、解密：a) 密钥生成 1) 选取两个长度为 K 的素数 P 和 Q，计算 N = P * Q； 2) 计算 phi(N) = (P-1) * (Q-1)， 其中 phi(N) 是 Z_(N^*) 的阶； 3) 随机选取一个int整数 e ∈ [ 1, phi(N) - 1 ]，使得 gcd( e, phi(N)) = 1； 4) 计算它的逆 d，使得 [ e * d mod phi(N) ] = 1； 5) 输出私钥和公钥 sk = ( N, d ), pk = ( N, e )；b) 加密 c = m^e mod(N)c) 解密 m = c^d mod(N)工具：RsaCtfTool （用于输出RSA参数） libnum （用于密文的计算）具体参考Bugku-加密-rsa(WriteUp) 20.仿射密码 affine cipher特征：可能会提示你是放射密码 affine，公式： y = k * x + b mod 26 （跟一元一次函数似的）后面的取模，如果都是英文字母的话是26，不排除有其他形式，比如ASC II 什么的，取模可能会换。 工具：python代码 12345678910111213141516# Q: y = 17x-8 flag&#123;szzyfimhyzd&#125;flag = "szzyfimhyzd"flaglist = []for i in flag: flaglist.append(ord(i)-97)flags = ""for i in flaglist: for j in range(0,26): c = (17 * j - 8) % 26 if(c == i): flags += chr(j+97)print('flag&#123;'+ flags + '&#125;') 21.进制转换特征：二进制 b开头，八进制 o开头，十进制 d开头，十六进制 x开头 BugKu里的一道题：d87 x65 x6c x63 o157 d109 o145 b100000 d116 b1101111 o40 x6b b1100101 b1101100 o141 d105 x62 d101 b1101001 d46 o40 d71 x69 d118 x65 x20 b1111001 o157 b1110101 d32 o141 d32 d102 o154 x61 x67 b100000 o141 d115 b100000 b1100001 d32 x67 o151 x66 d116 b101110 b100000 d32 d102 d108 d97 o147 d123 x31 b1100101 b110100 d98 d102 b111000 d49 b1100001 d54 b110011 x39 o64 o144 o145 d53 x61 b1100010 b1100011 o60 d48 o65 b1100001 x63 b110110 d101 o63 b111001 d97 d51 o70 d55 b1100010 d125 x20 b101110 x20 b1001000 d97 d118 o145 x20 d97 o40 d103 d111 d111 x64 d32 o164 b1101001 x6d o145 x7e 12345678910111213141516171819202122232425262728s = 'd87 x65 x6c x63 o157 d109 o145 b100000 d116 b1101111 o40 x6b b1100101 b1101100 o141 d105 x62 d101 b1101001 d46 o40 d71 x69 d118 x65 x20 b1111001 o157 b1110101 d32 o141 d32 d102 o154 x61 x67 b100000 o141 d115 b100000 b1100001 d32 x67 o151 x66 d116 b101110 b100000 d32 d102 d108 d97 o147 d123 x31 b1100101 b110100 d98 d102 b111000 d49 b1100001 d54 b110011 x39 o64 o144 o145 d53 x61 b1100010 b1100011 o60 d48 o65 b1100001 x63 b110110 d101 o63 b111001 d97 d51 o70 d55 b1100010 d125 x20 b101110 x20 b1001000 d97 d118 o145 x20 d97 o40 d103 d111 d111 x64 d32 o164 b1101001 x6d o145 x7e'ss = s.split()sss = []print(ss)for i in ss: if i[0] == 'd': i = i[1:] i = int(i,10) i = chr(i) sss.append(i) elif i[0] == 'x': i = i[1:] i = int(i,16) i = chr(i) sss.append(i) elif i[0] == 'o': i = i[1:] i = int(i,8) i = chr(i) sss.append(i) elif i[0] == 'b': i = i[1:] i = int(i,2) i = chr(i) sss.append(i)print(sss)flag = ''.join(sss)print(flag)]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF中Reverse介绍]]></title>
    <url>%2F2020%2F05%2F20%2FCTF%2FCTFReverse%2F</url>
    <content type="text"><![CDATA[CTF中Reverse介绍什么是逆向？广义的逆向： 从目标代码反推源代码 从源代码理解开发者行为和目的 应用：软件破解、漏洞挖掘、恶意代码分析CTF逆向-侠义的逆向：与Crypto结合 CrackMe（破解密码，不修改程序） KeygenMe（生成注册码）与隐写取证结合 Recover（恢复文件）与Pwn结合 Reverse（interface，struct，format，protocol） Bypass auth，Patch bin逆向的基本流程 程序预处理，去混淆合过反调试 代码逆向，找到验证函数 验证函数逆向，找到验证算法 破解验证算法，得到flag 其中，80%的题目都与crypto结合，通过找到一个key过掉所有关卡。同时可能有一量与恢复文件有关。 逆向的核心逆向的核心是破解验证算法（过算法关）验证算法简化如下： 输入：key 验证： 12345if H(key) == Secret:&#123; flag = O(key); print flag;&#125; 输出：flag验证算法分类： 简单比较验证 密码算法验证 算法求解验证 也就是说，想成为一个优秀的逆向手，你要成为一个优秀的码农，算法大佬。 算法举例：算法1 key直接比较算法2 key简单变换算法3 key编码转换算法4 key散列计算算法5 key密钥加密算法6 key算法求解算法7 flag直接输出算法8 密钥空间过短算法9 伪随机算法 -&gt; 爆破 验证算法逆向思路简单变换验证： 人工逆向，找到可逆运算，按位分步破解（算法1-3）密码算法验证： 识别密码算法（有限），针对性解密（算法4-5）解题算法验证： 理解算法原理，针对性解题（算法6）验证常见漏洞： 直接输出flag（算法7） 密钥空间过短（算法8） 伪随机算法（算法9）现实竞赛： 分段、嵌套验证爆破神技： 简单验证（按位破解） 密码算法（密钥部分已知） 解题算法（暴力搜索） 双刃剑（100亿次以内，位数与取值都有关） 逆向的基础逆向的基础是理解目标代码（过语言关）必备知识 汇编，C语言 操作系统原理与核心编程，程序加载 反汇编与调试等常用工具 1.PE与ELF编辑、帧壳、脱壳工具 O1Oeditor、winhex peid、upx、resource hacker sysinternals 2.反汇编与反编译工具 IDA Pro、Hopper 3.调试器 OBydbg、gdb、windbg分析方法 静态分析方法：反汇编、反编译 动态分析方法：调试、模拟]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF中Web题目的常见题型及解题技巧]]></title>
    <url>%2F2020%2F05%2F19%2FCTF%2FCTFWeb%2F</url>
    <content type="text"><![CDATA[基础知识类题目考察基本的查看网页源代码、HTTP请求、修改页面元素等。 这些题很简单，比较难的比赛应该不会单独出，就算有应该也是Web的签到题。 实际做题的时候基本都是和其他更复杂的知识结合起来出现。 查看网页源代码按F12就都看到了，flag一般都在注释里，有时候注释里也会有一条hint或者是对解题有用的信息。 Bugku web2: http://123.206.87.240:8002/web2/ Bugku web3: http://123.206.87.240:8002/web3/ 发送HTTP请求可以用hackbar，有的也可以写脚本。 Bugku web基础$_GET: http://123.206.87.240:8002/get/ Bugku web基础$_POST: http://123.206.87.240:8002/post/ Bugku 点击一百万次: http://123.206.87.240:9001/test/ 举个写脚本的例子，（题目是Bugku web基础$POST）： 123import requestsr = requests.post('http://123.206.87.240:8002/post/', data=&#123;'what' : 'flag'&#125;)print(r.text) 不常见类型的请求发送考OPTIONS请求，如果要发送这类请求，写一个脚本应该就能解决了。 HTTP头相关的题目主要是查看和修改HTTP头。 目前做过的Web题目有很大一部分都是与HTTP头相关的，而且这种题目也相当常见，不和其他知识结合的情况下也算是属于基础题的范畴吧。 技巧：不同的类型有不同的利用方法，基本都离不开抓包改包，有些简单的也可以利用浏览器F12的网络标签解决。 但是最根本的应对策略，是熟悉一些常见请求头的格式、作用等，这样题目考到的时候就很容易知道要怎样做了。 查看响应头有时候响应头里会有hint或者题目的关键信息，也有的时候会直接把flag放在响应头里给你，但是直接查看响应头拿flag的题目并不多，因为太简单了。 只是查看的话，可以不用抓包，用F12的“网络”标签就可以解决了。 Bugku 头等舱: http://123.206.87.240:9009/hd.php 修改请求头、伪造Cookie常见的有set-cookie、XFF和Referer，总之考法很灵活，做法比较固定，知道一些常见的请求头再根据题目随机应变就没问题了。 有些题目还需要伪造Cookie，根据题目要求做就行了。 可以用BurpSuite抓包，也可以直接在浏览器的F12“网络”标签里改。 实验吧 头有点大： http://ctf5.shiyanbar.com/sHeader/ Bugku 程序员本地网站： http://123.206.87.240:8002/localhost/ Bugku 管理员系统： http://123.206.31.85:1003/ XCTF xff_referer： https://adworld.xctf.org.cn/task/answer?type=web&amp;number=3&amp;grade=0&amp;id=5068 Git源码泄露flag一般在源码的某个文件里，但也有和其他知识结合、需要进一步利用的情况，比如XCTF社区的mfw这道题。 技巧：GitHack一把梭 XCTF mfw: https://adworld.xctf.org.cn/task/answer?type=web&amp;number=3&amp;grade=1&amp;id=5002 Python爬虫信息处理这类题目一般都是给一个页面，页面中有算式或者是一些数字，要求在很短的时间内求出结果并提交，如果结果正确就可以返回flag。 因为所给时间一般都很短而且计算比较复杂，所以只能写脚本。这种题目的脚本一般都需要用到requests库和BeautifulSoup库（或者re库（正则表达式）），个人感觉使用BeautifulSoup简单一些。 技巧：requests库和BeautifulSoup库熟练掌握后，再多做几道题或者写几个爬虫的项目，一般这类题目就没有什么问题了。主要还是对BeautifulSoup的熟练掌握，另外还需要一点点web前端（HTML）的知识。 Bugku 秋名山老司机： http://123.206.87.240:8002/qiumingshan/ 1234567891011121314151617#这道题的脚本如下，还可以继续优化#经常出现执行了但是不弹flag的情况，多试几次就行了from bs4 import BeautifulSoupimport requestsr = requests.Session()s = r.get("http://123.206.87.240:8002/qiumingshan/")s.encoding = 'utf-8'text = s.textsoup = BeautifulSoup(text)tag = soup.divexpress = str(tag.string)express = express[0 : -3]answer = eval(express)ans = &#123;"value" : answer&#125;flag = r.post('http://123.206.87.240:8002/qiumingshan/', data = ans)print(flag.text) 实验吧 速度爆破： http://www.shiyanbar.com/ctf/1841HGAME2019的部分题目似乎还出现了反爬虫措施。 PHP代码审计代码审计覆盖面特别广，分类也很多，而且几乎什么样的比赛都会有，算是比较重要的题目类型之一吧。 技巧：具体问题具体分析，归根结底还是要熟练掌握PHP这门语言，了解一些常见的会造成漏洞的函数及利用方法等。 hash加密相关PHP弱类型hash比较缺陷这是代码审计最基础的题目了，也比较常见。 典型代码： 123if(md5($a) == md5($b)) &#123; //注意两个等号“==” echo $flag;&#125; 加密函数也有可能是sha1或者其他的，但是原理都是不变的。 这个漏洞的原理如下： 12== 在进行比较的时候，会先将两边的变量类型转化成相同的，再进行比较。0e在比较的时候会将其视作为科学计数法，所以无论0e后面是什么，0的多少次方还是0。 所以只要让b在经过相应的函数加密之后都是以0e开头就可以。 以下是一些md5加密后开头为0e的字符串： 12345678910111213141516171819202122232425QNKCDZO0e830400451993494058024219903391s878926199a0e545993274517709034328855841020s155964671a0e342768416822451524974117254469s214587387a0e848240448830537924465865611904s214587387a0e848240448830537924465865611904s878926199a0e545993274517709034328855841020s1091221200a0e940624217856561557816327384675s1885207154a0e509367213418206700842008763514aabg7XSs 另外，这个也可以用数组绕过，这个方法在下面会详细说。 数组返回NULL绕过PHP绝大多数函数无法处理数组，向md5函数传入数组类型的参数会使md5()函数返回NULL（转换后为False），进而绕过某些限制。 如果上面的代码变成： 123if(md5($a) === md5($b)) &#123; //两个等号变成三个 echo $flag;&#125; 那么利用弱类型hash比较缺陷将无法绕过，这时可以使用数组绕过。 传入?a[]=1&amp;b[]=2就可以成功绕过判断。 这样的方法也可以用来绕过sha1()等hash加密函数相关的判断，也可以绕过正则判断，可以根据具体情况来灵活运用。 正则表达式相关ereg正则%00截断ereg函数存在NULL截断漏洞，使用NULL可以截断过滤，所以可以使用%00截断正则匹配。 Bugku ereg正则%00截断：http://123.206.87.240:9009/5.php 数组绕过正则表达式相关的函数也可以使用数组绕过过滤，绕过方法详见数组返回NULL绕过。 上面那道题也可以用数组绕过。 单引号绕过preg_match()正则匹配在每一个字符前加上单引号可以绕过preg_match的匹配，原理暂时不明。 例如有如下代码： 1234567891011&lt;?php $p = $_GET['p']; if (preg_match('/[0-9a-zA-Z]&#123;2&#125;/',$p) === 1) &#123; echo 'False'; &#125; else &#123; $pp = trim(base64_decode($p)); if ($pp === 'flag.php') &#123; echo 'success'; &#125; &#125;?&gt; 1payload：p='Z'm'x'h'Z'y'5'w'a'H'A'= 不含数字与字母的WebShell如果题目使用preg_match()过滤掉了所有的数字和字母，但是没有过滤PHP的变量符号$，可以考虑使用这种方法。 典型代码： 123456789101112131415161718&lt;?phpinclude'flag.php';if(isset($_GET['code']))&#123; $code=$_GET['code']; if(strlen($code)&gt;50)&#123; die("Too Long."); &#125; if(preg_match("/[A-Za-z0-9_]+/",$code))&#123; die("Not Allowed."); &#125; @eval($code);&#125;else&#123; highlight_file(__FILE__);&#125;//$hint = "php function getFlag() to get flag";?&gt; 这种方法的核心是字符串的异或操作。 爆破脚本： 123456chr1 = ['@', '!', '"', '#', '$', '%', '&amp;', '\'', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '&lt;', '=', '&gt;', '?', '[', '\\', ']', '^', '_', '`', '&#123;', '|', '&#125;', '~']chr2 = ['@', '!', '"', '#', '$', '%', '&amp;', '\'', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '&lt;', '=', '&gt;', '?', '[', '\\', ']', '^', '_', '`', '&#123;', '|', '&#125;', '~']for i in chr1 : for j in chr2 : print(i + 'xor' + j + '=' + (chr(ord(i) ^ ord(j)))) 根据题目的要求，用异或出来的字符串拼出合适的Payload，并放在PHP变量中执行。变量名可以用中文。 比如这道题的 1Payload：?code=$啊="@@^|@@@"^"'%*:,!'";$啊(); Linux通配符绕过正则匹配典型代码如下，与前一种题目非常相似，但也不大一样： 12345678910111213141516&lt;?phpif(isset($_GET['code']))&#123; $code=$_GET['code']; if(strlen($code)&gt;50)&#123; die("Too Long."); &#125; if(preg_match("/[A-Za-z0-9_$]+/",$code))&#123; die("Not Allowed."); &#125; @eval($code);&#125;else&#123; highlight_file(__FILE__);&#125;//flag in /?&gt; 最主要的区别就是过滤了$和_，也就是说无法使用变量符号$了。 这时候可以考虑采用通配符绕过。 通配符有点像正则表达式，有自己的匹配规则： | 字符 | 解释 || * | 匹配任意长度任意字符 || ? | 匹配任意单个字符 || [list] | 匹配指定范围内(list)任意单个字符，也可以是单个字符组成的集合 || [^list] | 匹配指定范围外的任意单个字符或字符集合 || [!list] | 同[^list] || {str1,str2,…} | 匹配str1或者str2或者更多字符串，也可以是集合 | 所以构造一下通配符就是 1/???/??? /* 因为过滤了变量符号，没法通过上面那种方法来执行了。但是，可以通过闭合PHP标记来执行，也就是：?&gt;（/bin/cat /*）。 所以本题的 1payload为：?code=?&gt;&lt;?=/???/??? /*?&gt; 具体解法可以参照此篇文章的前两道题目：https://www.jianshu.com/p/ecc2414ec110 命令执行漏洞assert()函数引起的命令执行assert函数的参数为字符串时，会将字符串当做PHP命令来执行。 例如：assert(‘phpinfo()’)相当于执行 以一道题目为例： 本题目中题目文件夹下放置了一个隐藏的flag文件。 1234567891011121314&lt;?phperror_reporting(0);if (isset($_GET['file'])) &#123; if($_GET['file'] === "flag")&#123; highlight_file("flag.php"); &#125;else&#123; $page = $_GET['file']; &#125;&#125; else &#123; $page = "./flag.php";&#125;assert("file_exists('$page')");?&gt; 解法： 构造闭合 file_exists()函数，并使assert()执行恶意代码。 Linux命令ls -a可用于查看该目录下所有文件，包括隐藏文件。 123payload：?file=123') or system('ls -a');#?file=123') or system('cat .ffll44gg');# XSS题目这类题目会涉及到三种XSS类型，具体类型要根据题目来判断。一般都是向后台发送一个带有XSS Payload的文本，在返回的Cookie中含有flag，解法是在XSS Payload。 这类题目一般都会带有过滤和各种限制，需要了解一些常用的绕过方法。 技巧：XSS归根结底还是JavaScript，JavaScript的威力有多大，XSS的威力就有多大。要知道一些常用的XSS Payload，还要把三类XSS的原理弄明白。做题时需要用到XSS平台，网上有公用的，也可以自己在VPS上搭一个。 JavisOJ babyxss：http://web.jarvisoj.com:32800/ 绕过waf其实绝大多数比较难的题目多多少都会对输入有过滤，毕竟在现实的网络中肯定是会对输入进行限制的，但是这里还是把过滤单独列出来了。 技巧：多掌握一些不同的绕过方法。 长度限制有些题目会要求输入较长的文本，但对文本的长度进行了限制。 对于这种题目，既可以用BurpSuite抓包改包绕过，也可以直接在F12里改页面源代码。 Bugku 计算器（修改页面源代码）：http://123.206.87.240:8002/yanzhengma/ DVWA 存储型XSS的标题栏会对长度进行限制，使用BurpSuite抓包绕过。 双写双写可以绕过对输入内容过滤的单次判断，在XSS、SQL注入和PHP代码审计的题目中比较常见。 双写顾名思义就是将被过滤的关键字符写两遍，比如，如果要添加XSS Payload，又需要插入script标签，就可以构造如下的 12Payload：&lt;scr&lt;script&gt;ipt&gt;` 来绕过对script标签的单次过滤限制。 这样的方法不仅对XSS有用，也可以用于代码审计和SQL注入。 HGAME2019有一道XSS题目就是过滤了script标签，可以用双写绕过。 等价替代就是不用被过滤的字符，而使用没有被过滤却会产生相同效果的字符。 比如，如果SQL注入题目中过滤了空格，可以用 1/**/ 绕过对空格的限制；XSS题目如果过滤了script标签，可以使用其他类型的 1payload；如果需要使用cat命令却被过滤，可以使用tac、more、less命令来替代等。 实验吧 简单的SQL注入：http://www.shiyanbar.com/ctf/1875 URL编码绕过如果过滤了某个必须要用的字符串，输入的内容是以GET方式获取的（也就是直接在地址栏中输入），可以采用url编码绕过的方式。比如，过滤了 cat，可以使用 c%61t来绕过。 Linux命令使用反斜杠绕过在Linux下，命令中加入反斜杠与原命令完全等价。例如，cat与 ca\t两条命令等价，效果完全相同。 可以利用这个特性来进行一些绕过操作（当然，这个仅限于命令执行漏洞）。 URL二次解码绕过这个类型本来应该放在代码审计里面，但是既然是一种绕过过滤的姿势，就写在这里了。 如果源码中出现了urldecode()函数，可以利用url二次解码来绕过。 以下是一些常用的HTML URL编码： | ASCII Value | URL-encode | ASCII Value | URL-encode | ASCII Value | URL-encode || æ | %00 | 0 | %30 | ` | %60 || | %01 | 1 | %31 | a | %61 || | %02 | 2 | %32 | b | %62 || | %03 | 3 | %33 | c | %63 || | %04 | 4 | %34 | d | %64 || | %05 | 5 | %35 | e | %65 || | %06 | 6 | %36 | f | %66 || | %07 | 7 | %37 | g | %67 || backspace | %08 | 8 | %38 | h | %68 || tab | %09 | 9 | %39 | i | %69 || linefeed | %0a | : | %3a | j | %6a || | %0b | ; | %3b | k | %6b || | %0c | &lt; | %3c | l | %6c || c return | %0d | = | %3d | m | %6d || | %0e | &gt; | %3e | n | %6e || | %0f | ? | %3f | o | %6f || | %10 | @ | %40 | p | %70 || | %11 | A | %41 | q | %71 || | %12 | B | %42 | r | %72 || | %13 | C | %43 | s | %73 || | %14 | D | %44 | t | %74 || | %15 | E | %45 | u | %75 || | %16 | F | %46 | v | %76 || | %17 | G | %47 | w | %77 || | %18 | H | %48 | x | %78 || | %19 | I | %49 | y | %79 || | %1a | J | %4a | z | %7a || | %1b | K | %4b | { | %7b || | %1c | L | %4c | | | %7c || | %1d | M | %4d | } | %7d || | %1e | N | %4e | ~ | %7e || | %1f | O | %4f | | %7f || space | %20 | P | %50 | € | %80 || ! | %21 | Q | %51 | | %81 || “ | %22 | R | %52 | ‚ | %82 || # | %23 | S | %53 | ƒ | %83 || $ | %24 | T | %54 | „ | %84 || % | %25 | U | %55 | … | %85 || &amp; | %26 | V | %56 | † | %86 || ‘ | %27 | W | %57 | ‡ | %87 || ( | %28 | X | %58 | ˆ | %88 || ) | %29 | Y | %59 | ‰ | %89 || * | %2a | Z | %5a | Š | %8a || + | %2b | [ | %5b | ‹ | %8b || , | %2c | \ | %5c | Œ | %8c || - | %2d | ] | %5d | | %8d || . | %2e | ^ | %5e | Ž | %8e || / | %2f | _ | %5f | | %8f | Bugku urldecode二次编码绕过：http://123.206.87.240:9009/10.php 数组绕过详见PHP代码审计的“数组返回NULL”绕过。 数组绕过的应用很广，很多题目都可以用数组绕过。 SQL注入SQL注入是一种灵活而复杂的攻击方式，归根结底还是考察对SQL语言的了解和根据输入不同数据网页的反应对后台语句的判断，当然也有sqlmap这样的自动化工具可以使用。 技巧：如果不用sqlmap或者是用不了，就一定要把SQL语言弄明白，sqlmap这样的自动化工具也可以使用。 使用sqlmapsqlmap的应用范围还不大明确，我都是如果sqlmap没法注入就手工注入。 sqlmap的使用：https://www.jianshu.com/p/4509bdf5e3d0 一些sqlmap的命令，留着备用：https://www.freebuf.com/sectool/164608.html 感觉这篇教程也不错：https://www.cnblogs.com/im404/p/3505894.html 命令合集：https://www.jianshu.com/p/fa77f2ed788b]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF常见的题型]]></title>
    <url>%2F2020%2F05%2F19%2FCTF%2FCTFType%2F</url>
    <content type="text"><![CDATA[CTF常见的题型CTF比赛通常包含的题目类型有七种，包括MISC、PPC、CRYPTO、PWN、REVERSE、WEB、STEGA。 1.MISC(Miscellaneous)√ 类型，即安全杂项，题目或涉及流量分析、电子取证、人肉搜索、数据分析等等。杂项介绍Miscellaneous简称MISC，意思是杂项，混杂的意思。杂项大致有几种类型： 1.隐写，包括图片/音频/视频/其他等 2.压缩包处理，包括zip/rar等 3.流量分析，包括协议/文件/usb/wifi等 4.攻击取证，包括日志分析/内存分析/文件镜像等 5.基础 6.其它处理方法： 1.查看文件类型： file、 010Editor 2.文件分离： Binwalk、 foremost、 dd、 010Editor 3.文件合并： linux环境、 windows环境、 python脚本 2.PPC(Professionally Program Coder)类型，即编程类题目，题目涉及到编程算法，相比ACM较为容易。 3.CRYPTO(Cryptography)√ 类型，即密码学，题目考察各种加解密技术，包括古典加密技术、现代加密技术甚至出题者自创加密技术。 Morse编码 ASCII编码 Tap Code敲击码 Base编码 URL编码 Unicode编码 凯撒密码 RSA 加解密 4.PWN√ 类型，PWN在黑客俚语中代表着攻破、取得权限，多为溢出类题目。 Pwn 是其中的一类重要题型，主要考查选手二进制逆向分析、漏洞挖掘以及 Exploit 编写的能力。 PWN是一个黑客语法的俚语词，自”own”这个字引申出来的，这个词的含意在于，玩家在整个游戏对战中处在胜利的优势，或是说明竞争对手处在完全惨败的 情形下，这个词习惯上在网络游戏文化主要用于嘲笑竞争对手在整个游戏对战中已经完全被击败（例如：”You just got pwned!”）。有一个非常著名的国际赛事叫做Pwn2Own，相信你现在已经能够理解这个名字的含义了，即通过打败对手来达到拥有的目的。 CTF中PWN题型通常会直接给定一个已经编译好的二进制程序（Windows下的EXE或者Linux下的ELF文件等），然后参赛选手通过对二进制程 序进行逆向分析和调试来找到利用漏洞，并编写利用代码，通过远程代码执行来达到溢出攻击的效果，最终拿到目标机器的shell夺取flag 5.REVERSE√ 类型，即逆向工程，题目涉及到软件逆向、破解技术。 通过Ollydbg/IDA Pro/PEiD等工具在逆向分析中的基本使用方法，并通过动态调试和静态分析两种方法来找到程序密码。 6.STEGA(Steganography)类型，即隐写术，题目的Flag会隐藏到图片、音频、视频等各类数据载体中供参赛者获取。 7.WEB√ 类型，即题目会涉及到常见的Web漏洞，诸如注入、XSS、文件包含、代码执行等漏洞。工具集 基础工具：Burpsuite，python，firefox(hackbar，foxyproxy，user-agent，swither等) 扫描工具：nmap，nessus，openvas sql注入工具：sqlmap等 xss平台：xssplatfrom，beef 文件上传工具：cknife 文件包含工具：LFlsuite 暴力破解工具：burp暴力破解模块，md5Crack，hydra 常用套路总结 直接查看网页源码，即可找到flag 查看http请求/响应，使用burp查看http头部信息，修改或添加http请求头（referer–来源伪造，x-forwarded-for–ip伪造，user-agent–用户浏览器，cookie–维持登陆状态，用户身份识别） web源码泄漏：vim源码泄漏(线上CTF常见)，如果发现页面上有提示vi或vim，说明存在swp文件泄漏，地址：/.index.php.swp或index.php~ 恢复文件 vim -r index.php。备份文件泄漏，地址：index.php.bak，www.zip，htdocs.zip，可以是zip，rar，tar.gz，7z等 .git源码泄漏，地址：http://www.xxx.com/.git/config，工具：GitHack，dvcs-ripper svn导致文件泄漏，地址：http://www/xxx/com/.svn/entries，工具：dvcs-ripper，seay-svn 编码和加解密，各类编码和加密，可以使用在线工具解密，解码 windows特性，短文件名，利用～字符猜解暴露短文件/文件夹名，如backup-81231sadasdasasfa.sql的长文件，其短文件是backup1.sql，iis解析漏洞，绕过文件上传检测 php弱类型 绕waf，大小写混合，使用编码，使用注释，使用空字节 当前我们环境中的题型为： 1.CRYPTO：字符串(可能很长) 或 上传一个文件 2.PWN：每一道题Docker container对外开放一个端口映射 3.MISC:全部为 上传一个文件 4.Reserve：全部为 上传一个文件 5.Web：每一道题Docker container对外开放一个端口映射]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS 详解]]></title>
    <url>%2F2020%2F05%2F08%2FLinux%2FNFS%2F</url>
    <content type="text"><![CDATA[nfs客户端卡住问题碰到nfs客户端卡住的情况，umount -f /mnt提示device is busy，并且尝试访问挂载目录、df -h等操作都会使终端卡住，ctrl+c也不能强行退出。 造成这种现象的原因是nfs服务器/网络挂了，nfs客户端默认采用hard-mount选项，而不是soft-mount。他们的区别是soft-mount: 当客户端加载NFS不成功时，重试retrans设定的次数.如果retrans次都不成功，则放弃此操作，返回错误信息 “Connect time out”hard-mount: 当客户端加载NFS不成功时,一直重试，直到NFS服务器有响应。hard-mount 是系统的缺省值。在选定hard-mount 时，最好同时选 intr , 允许中断系统的调用请求，避免引起系统的挂起。当NFS服务器不能响应NFS客户端的 hard-mount请求时， NFS客户端会显示“NFS server hostname not responding, still trying” nfs参数介绍下面列出mount关于nfs相关的参数（1）-a：把/etc/fstab中列出的路径全部挂载。（2）-t：需要mount的类型，如nfs等。（3）-r：将mount的路径定为read only。（4）-v mount：过程的每一个操作都有message传回到屏幕上。（5）rsize=n：在NFS服务器读取文件时NFS使用的字节数，默认值是4096个字节。（6）wsize=n：向NFS服务器写文件时NFS使用的字节数，默认值是4096个字节。（7）timeo=n：从超时后到第1次重新传送占用的1/7秒的数目，默认值是7/7秒。（8）retry=n：在放弃后台mount操作之前可以尝试的次数，默认值是7 000次。（9）soft：使用软挂载的方式挂载系统，若Client的请求得不到回应，则重新请求并传回错误信息。（10）hard：使用硬挂载的方式挂载系统，该值是默认值，重复请求直到NFS服务器回应。（11）intr：允许NFS中断文件操作和向调用它的程序返回值，默认不允许文件操作被中断。（12）fg：一直在提示符下执行重复挂载。（13）bg：如果第1次挂载文件系统失败，继续在后台尝试执行挂载，默认值是失败后不在后台处理。（14）tcp：对文件系统的挂载使用TCP，而不是默认的UDP。 如#mount -t nfs -o soft 192.168.1.2:/home/nfs /mnt nfs传输尺寸至于传输尺寸的选择，可以进行实际测试：time dd if=/dev/zero of=/mnt/nfs.dat bs=16k count=16384即向nfs服务器上的nfs.dat文件里写入16384个16KB的块（也有经验说文件大小可以设定为nfs服务器内存的2倍）。得到输出如：输出了 16384+0 个块user 0m0.200s输出了 66535+0 个块user 0m0.420s192.168.1.4:/mnt /home/nfs nfs rsize=8192,wsize=8192,timeo=10,intr重新挂载nfs服务器，调整读写块大小后重复上述过程，可以找到最佳传输尺寸。 NFS服务器的故障排除故障排除思路:NFS出现了故障，可以从以下几个方面着手检查。（1）NFS客户机和服务器的负荷是否太高，服务器和客户端之间的网络是否正常。（2）/etc/exports文件的正确性。（3）必要时重新启动NFS或portmap服务。运行下列命令重新启动portmap和NFS：service portmap restartservice nfs start（4）检查客户端中的mount命令或/etc/fstab的语法是否正确。（5）查看内核是否支持NFS和RPC服务。普通的内核应有的选项为CONFIG_NFS_FS=m、CONFIG_NFS_V3=y、CONFIG_ NFSD=m、CONFIG_NFSD_V3=y和CONFIG_SUNRPC=m。我们可以使用常见的网络连接和测试工具ping及tracerroute来测试网络连接及速度是否正常，网络连接正常是NFS作用的基础。rpcinfo命令用于显示系统的RPC信息，一般使用-p参数列出某台主机的RPC服务。用rpcinfo-p命令检查服务器时，应该能看到portmapper、status、mountd nfs和nlockmgr。用该命令检查客户端时，应该至少能看到portmapper服务。 使用nfsstat命令查看NFS服务器状态nfsstat命令显示关于NFS和到内核的远程过程调用（RPC）接口的统计信息，也可以使用该命令重新初始化该信息。如果未给定标志，默认是nfsstat -csnr命令。使用该命令显示每条信息，但不能重新初始化任何信息。 nfsstat命令的主要参数如下。（1）-b：显示NFS V4服务器的其他统计信息。（2）c：只显示客户机端的NFS和RPC信息，允许用户仅查看客户机数据的报告。nfsstat命令提供关于被客户机发送和拒绝的RPC和NFS调用数目的信息。要只显示客户机NFS或者RPC信息，将该参数与-n或者-r参数结合。（3）-d：显示与NFS V4授权相关的信息。（4）-g：显示RPCSEC_GSS信息。（5）-m：显示每个NFS文件系统的统计信息，该文件系统和服务器名称、地址、安装标志、当前读和写大小，以及重新传输计数（6）-n：为客户机和服务器显示NFS信息。要只显示NFS客户机或服务器信息，将该参数与-c和-s参数结合。（7）-r：显示RPC信息。（8）-s：显示服务器信息。（9）-t：显示与NFS标识映射子系统的转换请求相关的统计信息，要只显示NFS客户机或服务器信息，将-c和-s选项结合。（10）-4：当与-c、-n、-s或-z参数组合使用时，将包含NFS V4客户机或服务器的信息，以及现有的NFS V2和V3数据。（11）-z：重新初始化统计信息。该参数仅供root用户使用，并且在显示上面的标志后可以和那些标志中的任何一个组合到统计信息的零特殊集合。 要显示关于客户机发送和拒绝的RPC和NFS调用数目的信息，输入：nfsstat -c要显示和打印与客户机NFS调用相关的信息，输入如下命令：nfsstat -cn要显示和打印客户机和服务器的与RPC调用相关的信息，输入如下命令：nfsstat -r要显示关于服务器接收和拒绝的RPC和NFS调用数目的信息，输入如下命令：nfsstat –s]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack凝思系统虚拟桌面鼠标漂移的问题]]></title>
    <url>%2F2020%2F05%2F06%2FOpenstack%2FOpenstackGraphicMouse%2F</url>
    <content type="text"><![CDATA[问题描述在OpenstackQueens环境下分别安装Windows，Kali及凝思图型界面操作系统，发现凝思操作系统出现鼠标漂移的问题。经调查，默认情况下有图型界面的实例使用的输入设备类型为usbtablet，Windows，Kali在usbtablet下没有问题，凝思操作系统鼠标漂移。凝思在使用ps2mouse下没有问题，而ps2mouse下Windows，Kali鼠标出现漂移。 解决办法镜像定制化:在制作除凝思操作系统的镜像时，使用定制属性: 1hw_pointer_model='usbtablet' 即使用glanceClient创建镜像时， 12glanceClient.images.create( name=imageName, container_format='bare', disk_format='qcow2', hw_pointer_model='usbtablet') 或者镜像创建后，修改镜像信息: 1glance image-update --property hw_pointer_model=usbtablet [IMAGE-ID] 然后在nova配置文件中[DEFAULT]中增加: 123[DEFAULT]...pointer_model=ps2mouse 更新后重启计算节点的Nova-compute服务: 1systemctl restart openstack-nova-compute.service 这时，使用hw_pointer_model属性的镜像默认仍使用镜像定制的usbtablet，而凝思系统则使用ps2mouse的输入方式。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack虚拟桌面协议SPICE代替vnc]]></title>
    <url>%2F2020%2F05%2F06%2FOpenstack%2FSPICE%2F</url>
    <content type="text"><![CDATA[题记VNC是OpenStack的Nova默认的连接协议，面对一些简单的管理工作表现也不错，但是如果用户经常使用Windows桌面，VNC就显得能力不足。一般情况下，使用Spice协议来代替VNC。 VNCVNC (Virtual Network Computing)是虚拟网络计算机的缩写。VNC 是一款优秀的远程控制工具软件，由著名的 AT&amp;T 的欧洲研究实验室开发的。VNC 是在基于 UNIX 和 Linux 操作系统的免费的开源软件，远程控制能力强大，高效实用，其性能可以和 Windows 和 MAC 中的任何远程控制软件媲美。 在 Linux 中，VNC 包括以下四个命令：vncserver，vncviewer，vncpasswd，和 vncconnect。大多数情况下我只需要其中的两个命令：vncserver 和 vncviewer。 SPICE 已经支持和即将支持的功能当前支持功能:• 图形界面 - processes and transmits 2D graphic commands• 视频流 - heuristically identifies video streams and transmits M-JPEG video streams• 图片压缩 - offers verios compression algorithm that were built specifically for Spice, including QUIC (based on SFALIC), LZ, GLZ (history-based global dictionary), and auto (heuristic compression choice per image)• 硬件鼠标- processes and transmits cursor-specific commands• 图像,颜色,鼠标缓存 - manages client caches to reduce bandwidth requirements• 在线切换 - supports clients while migrating Spice servers to new hosts, thus avoiding interruptions• Windows 驱动 - Windows drivers for QXL display device and VDI-port• 多监视器• 客户端支持linux和windows - can be easily ported to additional platforms.• 立体声音频 - supports audio playback and captures; audio data stream is optionally compressed using CELT• 加密 - using OpenSSL• 两种鼠标模式- provides client (more user-friendly) and server (increased accuracy and fully synchronized) modes• 音频视频同步 - synchronizes video streams with audio clocks• Spice 代理 - running on the guest and performs tasks for the client• 剪切板共享 - allows copy paste between clients and the virtual machine 未来将支持的新功能:• 网络隧道 (in progress) - using virtual network interface to enable sharing of network resources. Currently the focus is on printer sharing but is not limited to that.• Off-screen surfaces (in progress) - supports off-screen surfaces as infrastructure for future DirectDraw, video acceleration and 3D acceleration. GDI and X11 will also benefit from this feature. It will also lay foundation for multi-head support• 共享usb (in progress) - allows clients to share their USB devices with Spice servers• Direct Draw• 客户端GUI - Enables user-friendly configuration• 屏幕管理 - add support for enabling selection of the screen used by the client• 配置文件 - enables persistent user and administrative settings• 共享光驱 - share your CD with Spice server• 视频加速• 3D加速• 支持Aero• Linux features parity• OSX client• Simultaneous clients connection Openstack启用SPICE协议安装软件包控制节点: 1yum install spice-server spice-protocol openstack-nova-spicehtml5proxy spice-html5 计算节点: 1yum install spice-server spice-protocol spice-html5 12345678spice-html5来自epel源，spice-server，spice-protocol来自CentOS官方源如果找不到spice-html5，添加epel源wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmrpm -ivh epel-release-latest-7.noarch.rpmyum repolist ##检查是否已添加至源列表)如果离线安装:需安装epel-release-latest-7.noarch,openstack-nova-spicehtml5proxy-17.0.10-1.el7.noarch,spice-html5-0.1.7-1.el7.noarch,spice-protocol-0.12.14-1.el7.noarch,spice-server-0.14.0-9.el7.x86_64的RPM包 修改配置文件控制节点: 12345678910111213vi /etc/nova/nova.conf这里明确两点：指定vnc_enabled=false，否则即使配置了spice，系统也仍然使用vnc一定要注释掉原vnc配置[default]vnc_enabled=false[spice]html5proxy_host=192.100.200.140html5proxy_port=6082keymap=en-us 计算节点: 1234567891011vi /etc/nova/nova.conf[default]vnc_enabled=false[spice]html5proxy_base_url=http://192.100.200.140:6082/spice_auto.htmlserver_listen=0.0.0.0#server_proxyclient_address=192.100.200.150enabled=truekeymap=en-us 重启服务控制节点: 123456789停止novncproxy并取消自启动systemctl stop openstack-nova-novncproxy.servicesystemctl disable openstack-nova-novncproxy.service启用spicehtml5proxy开机自启动并启动它systemctl enable openstack-nova-spicehtml5proxy.servicesystemctl start openstack-nova-spicehtml5proxy.service 计算节点: 1systemctl restart openstack-nova-compute.service]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack控制节点删除计算节点的方法]]></title>
    <url>%2F2020%2F04%2F14%2FOpenstack%2FOpenstackDelCompute%2F</url>
    <content type="text"><![CDATA[在控制节点Controller的操作：删除计算节点名称为compute5：1.查看计算主机及服务相关： 1234567891011[root@controller ~]# openstack host list+------------+-------------+----------+| Host Name | Service | Zone |+------------+-------------+----------+| controller | consoleauth | internal || controller | scheduler | internal || controller | conductor | internal || compute4 | compute | nova || compute6 | compute | nova || compute5 | compute | nova |+------------+-------------+----------+ 1234567891011[root@controller ~]# nova service-list+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| Id | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | Forced down |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| 936a4177-d08d-4f62-bb8c-7da7047ab6f8 | nova-consoleauth | controller | internal | enabled | up | 2020-04-14T05:59:07.000000 | - | False || c1395bf8-47dd-47b0-bc8c-e10fc083ad40 | nova-scheduler | controller | internal | enabled | up | 2020-04-14T05:59:11.000000 | - | False || 28958175-5745-4b9f-b71d-e431168f6119 | nova-conductor | controller | internal | enabled | up | 2020-04-14T05:59:10.000000 | - | False || c586b1d2-f326-4e7e-8a3a-fead78a151c0 | nova-compute | compute4 | nova | enabled | up | 2020-04-14T05:59:11.000000 | - | False || b6f3a4e3-a0ec-4f41-b47d-976bd45581b6 | nova-compute | compute6 | nova | enabled | up | 2020-04-14T05:59:03.000000 | - | False || bb93240f-58f4-4d3c-a040-a66a9b2f0ea9 | nova-compute | compute5 | nova | enabled | down | 2020-04-14T05:59:12.000000 | - | False |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ 计算节点compute的State状态是down，但Status状态还是enabled可用。2.修改compute5为不可用状态。 1[root@controller ~]# nova service-disable bb93240f-58f4-4d3c-a040-a66a9b2f0ea9 查看是否修改成功 1234567891011[root@controller ~]# nova service-list+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| Id | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | Forced down |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| 936a4177-d08d-4f62-bb8c-7da7047ab6f8 | nova-consoleauth | controller | internal | enabled | up | 2020-04-14T05:59:07.000000 | - | False || c1395bf8-47dd-47b0-bc8c-e10fc083ad40 | nova-scheduler | controller | internal | enabled | up | 2020-04-14T05:59:11.000000 | - | False || 28958175-5745-4b9f-b71d-e431168f6119 | nova-conductor | controller | internal | enabled | up | 2020-04-14T05:59:10.000000 | - | False || c586b1d2-f326-4e7e-8a3a-fead78a151c0 | nova-compute | compute4 | nova | enabled | up | 2020-04-14T05:59:11.000000 | - | False || b6f3a4e3-a0ec-4f41-b47d-976bd45581b6 | nova-compute | compute6 | nova | enabled | up | 2020-04-14T05:59:03.000000 | - | False || bb93240f-58f4-4d3c-a040-a66a9b2f0ea9 | nova-compute | compute5 | nova | disabled| down | 2020-04-14T05:59:12.000000 | - | False |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ 3.在数据库（nova）中清理 12345678910111213141516171819[root@controller ~]# mysql -pEnter password:Welcome to the MariaDB monitor. Commands end with ; or g.Your MariaDB connection id is 980Server version: 10.1.20-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type 'help;' or 'h' for help. Type 'c' to clear the current input statement.MariaDB [(none)]&gt; use novaReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [nova]&gt; delete from nova.services where host="compute5";Query OK, 1 row affected (0.01 sec)MariaDB [nova]&gt; delete from compute_nodes where hypervisor_hostname="compute5";Query OK, 0 rows affected (0.00 sec)MariaDB [nova]&gt; select host from nova.services;MariaDB [nova]&gt; select hypervisor_hostname from compute_nodes; 4.校验 12[root@controller ~]# openstack host list[root@controller ~]# nova service-list 再次查看计算节点，就发现compute已经被删除了。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack创建实例报错：No valid host was found.]]></title>
    <url>%2F2020%2F04%2F14%2FOpenstack%2FOpenstackNoValidHost%2F</url>
    <content type="text"><![CDATA[错误原因：UUID冲突，nova_api数据库中resource_providers表与nova.compute_nodes表中host的UUID不一致引起的，导致原因可能为删除计算节点时没有清空resource_providers表中的数据。 解决办法：12345678[root@controller]# nova-manage cell_v2 list_hosts+-----------+--------------------------------------+----------+| Cell Name | Cell UUID | Hostname |+-----------+--------------------------------------+----------+| cell1 | 9abb6c5c-25e2-440c-8295-4826d055298c | compute4 || cell1 | 9abb6c5c-25e2-440c-8295-4826d055298c | compute5 || cell1 | 9abb6c5c-25e2-440c-8295-4826d055298c | compute6 |+-----------+--------------------------------------+----------+ 1234567891011121314151617181920MariaDB [(none)]&gt; use nova_api;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [nova_api]&gt; select uuid,name from resource_providers where name='compute5';+--------------------------------------+----------+| uuid | name |+--------------------------------------+----------+| 305cc2a4-75e8-496f-b843-152400257c35 | compute5 |+--------------------------------------+----------+1 row in set (0.00 sec)MariaDB [nova_api]&gt; select uuid,host from nova.compute_nodes where host='compute5';+--------------------------------------+----------+| uuid | host |+--------------------------------------+----------+| 924c0d27-1952-4663-8f01-e8cecc67f964 | compute5 |+--------------------------------------+----------+1 row in set (0.00 sec) 可以看到，UUID为compute5的计算节点在resource_providers表中与nova.compute_nodes表中数据不一致，将resource_providers表中数据修改： 123MariaDB [nova_api]&gt; update resource_providers set uuid='924c0d27-1952-4663-8f01-e8cecc67f964' where name='compute5' and uuid='305cc2a4-75e8-496f-b843-152400257c35';Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0 修改后，compute5上实例可以成功创建。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交换机端口开启巨帧功能]]></title>
    <url>%2F2020%2F04%2F14%2FOther%2FswitchJumbo%2F</url>
    <content type="text"><![CDATA[命令功能：开启/关闭端口巨帧功能。 命令模式：全局配置模式 命令格式：1set jumbo port &lt;portlist&gt;&#123;enable | disable&#125; 命令参数解释： 参数 | 描述 portlist | 端口列表 enable | 开启端口巨帧功能 disable | 关闭端口巨帧功能 使用说明：ZXR10 2950设备可以转发10k大小的巨帧。 缺省：巨帧功能默认为disable状态。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7断电导致generating /run/initramfs/rdsosreport.txt 问题]]></title>
    <url>%2F2020%2F04%2F14%2FLinux%2Frdsosreport%2F</url>
    <content type="text"><![CDATA[开机就进入命令窗口，窗口提示信息如下：1234generating "/run/initramfs/rdsosreport.txt"entering emergencymode. exit the shell to continuetype "journalctl" to view system logs.you might want to save "/run/initramfs/rdsosreport.txt" to a usb stick or /boot after mounting them and attach it to a bug report. 解决办法：1xfs_repair /dev/mapper/centos-root -L 1reboot]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack 安全组规则不生效]]></title>
    <url>%2F2020%2F02%2F14%2FOpenstack%2FOpenstackSecurityGroup%2F</url>
    <content type="text"><![CDATA[编辑 /etc/sysctl.conf 文件这里强调，安全组主要是依靠计算节点的iptables的forward链来生效的，每加一条规则就会根据网卡作为匹配条件，来生成一条iptables的规则。 如果没有任何规则，默认是丢弃所有的包。 猜测到的原因是因为，没有开启包转发功能，所以修改 12345net.ipv4.ip_forward=1net.ipv4.conf.default.rp_filter=1net.bridge.bridge-nf-call-ip6tables=1net.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-arptables=1 重启网络 1/etc/init.d/network restart 编辑 /etc/neutron/plugins/ml2/openvswitch_agent.ini 文件增加或修改项，包括控制节点和计算节点 123[securitygroup]enable_security_group = truefirewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver 控制节点重启所有网络服务，计算节点重启Openvswitch服务。 注：neutron 也提供两种安全组的实现：IptablesFirewallDriver 和 OVSHybridIptablesFirewallDriverneutron.agent.linux.iptables_firewall.IptablesFirewallDriver iptables-based FirewallDriver implementationneutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver: subclass of IptablesFirewallDriver with additional bridge默认值是 neutron.agent.firewall.NoopFirewallDriver，表示不使用 neutron security group。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMX开启kafka]]></title>
    <url>%2F2019%2F11%2F21%2FOther%2Fjmx_kafka%2F</url>
    <content type="text"><![CDATA[开启JMXkafka开启JMX的2种方式：1.启动kafka时增加JMX_PORT=9988，即 1JMX_PORT=9988 bin/kafka-server-start.sh -daemon config/server.properties 2.修改kafka-run-class.sh脚本，第一行增加JMX_PORT=9988即可。 事实上这两种配置方式背后的原理是一样的，我们看一下kafka的启动脚本kafka-server-start.sh的最后一行 1exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka"$@" 实际上就是调用kafka-run-class.sh脚本，其中有一段这样的内容： 1234# JMX port to useif [ $JMX_PORT ]; then KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT "fi 所以，本质是给参数JMX_PORT赋值，第二种方式在脚本的第一行增加JMX_PORT=9988，$JMX_PORT就能取到值；而第一种方式有点逼格，本质是设置环境变量然后执行启动脚本，类似下面这种方式给JMX_PORT赋值： 12[root@kafka]$ export JMX_PORT=9988[root@kafka]$ bin/kafka-server-start.sh -daemon config/server.properties jmx所有相关参数都在脚本kafka-run-class.sh中，如下所示： 123456789# JMX settingsif [ -z "$KAFKA_JMX_OPTS" ]; then KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=10.0.55.229 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false "fi# JMX port to useif [ $JMX_PORT ]; then KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT "fi 某些服务器可能无法正确绑定ip，这时候我们需要显示指定绑定的host：- 1Djava.rmi.server.hostname=192.100.200.46 jconsole连接配置好jmx并启动kafka后，可以启动jconsole验证jmx配置是否正确（连接远程进程的host就是参数java.rmi.server.hostname指定的值，port就是参数JMX_PORT指定的值）： JMX开启远程访问（包括kafka启动）： 1sudo KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=192.100.200.46 -Djava.net.preferIPv4Stack=true -Dcom.sun.management.jmxremote.port=9988" bin/kafka-server-start.sh config/server.properties]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka集群管理工具kafka-manager的安装使用]]></title>
    <url>%2F2019%2F11%2F21%2FOther%2Fkafka_manager%2F</url>
    <content type="text"><![CDATA[kafka-manager简介kafka-manager是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执行一些简单的集群管理操作。具体支持以下内容： 管理多个集群轻松检查集群状态（主题，消费者，偏移，代理，副本分发，分区分发）运行首选副本选举使用选项生成分区分配以选择要使用的代理运行分区重新分配（基于生成的分配）使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置）删除主题（仅支持0.8.2+并记住在代理配​​置中设置delete.topic.enable = true）主题列表现在指示标记为删除的主题（仅支持0.8.2+）批量生成多个主题的分区分配，并可选择要使用的代理批量运行重新分配多个主题的分区将分区添加到现有主题更新现有主题的配置kafka-manager 项目地址：https://github.com/yahoo/kafka-manager kafka-manager安装下载安装包使用Git或者直接从Releases中下载，这里我们下载 2.0.0.2版本：https://github.com/yahoo/kafka-manager/releases 1wget https://github.com/yahoo/kafka-manager/archive/2.0.0.2.tar.gz 解压安装包 12tar zxvf 2.0.0.2.tar.gzcd kafka-manager-2.0.0.2 sbt编译yum安装sbt(因为kafka-manager需要sbt编译) 123curl https://bintray.com/sbt/rpm/rpm &gt; bintray-sbt-rpm.repomv bintray-sbt-rpm.repo /etc/yum.repos.d/yum install sbt 验证：检查sbt是否安装成功 12sbt[info] [launcher] getting org.scala-sbt sbt 1.3.3 (this may take some time)... 编译kafka-manager 1./sbt clean dist 安装将编译好的/root/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.zip文件解压 1unzip /root/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.zip 启动服务启动zk集群，kafka集群，再启动kafka-manager服务。bin/kafka-manager 默认的端口是9000，可通过 -Dhttp.port，指定端口;-Dconfig.file=conf/application.conf指定配置文件: 1nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=9000 &amp; WebUI查看：http://KAFKA_IP:9000/ 出现如下界面则启动成功。]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装kafka]]></title>
    <url>%2F2019%2F11%2F19%2FOther%2Fcentos7_kdfka%2F</url>
    <content type="text"><![CDATA[安装准备：基于Centos7.5 1804 minimal安装JDK1.81yum -y install java-1.8.0-openjdk* 安装kafka下载kafka 1wget http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.3.0/kafka_2.12-2.3.0.tgz 解压 1tar -zxvf kafka_2.12-2.3.0.tgz 修改配置，使kafka远程访问 12345vi config/server.properties# listeners=PLAINTEXT://:9092-&gt;listeners=PLAINTEXT://KAFKA_IP:9092 启动kafka进入kafka目录 1cd kafka_2.12-2.3.0 启动zookeeper 1bin/zookeeper-server-start.sh -daemon config/zookeeper.properties 检查zookeeper端口2181是否正常监听 12netstat -an|grep 2181tcp6 0 0 :::2181 :::* LISTEN 检查kafka默认的JVM参数配置是否需要修改Kafka默认设置1G，即”-Xmx1G -Xms1G”。如果你的测试机内存较低，需要修改才能成功启动。参数配置位于：bin/kafka-server-start.sh 启动Kafka 1bin/kafka-server-start.sh config/server.properties 如果一切顺利，就会看到如下启动成功的日志： 1[2019-11-18 21:42:37,067] INFO [KafkaServer id=0] started (kafka.server.KafkaServer) 检查Kafka的端口9092监听是否正常 12[root@localhost kafka_2.12-2.3.0]# netstat -an|grep 9092tcp6 0 0 :::9092 :::* LISTEN 测试kafka创建一个测试主题 1234cd kafka_2.12-2.3.0bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testCreated topic "test". 查看刚刚创建的test主题 123bin/kafka-topics.sh --list --zookeeper localhost:2181test 向刚刚创建的test主题中写入数据 123bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test&gt;Hello, World!&gt; “Hello World!”为写入的数据。 查看刚刚写入的数据另外开一个ssh tab连接，然后执行如下命令 1234bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].Hello, World!]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS网卡配置文件设置为网桥模式]]></title>
    <url>%2F2019%2F11%2F08%2FOpenstack%2FOpenstackProviderBridge%2F</url>
    <content type="text"><![CDATA[原eth0配置文件/etc/sysconfig/network-scripts/ifcfg-eth0 12345678910111213TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=noIPV4_FAILURE_FATAL=noNAME=eth0UUID=63754cd8-9152-44a4-b051-ea88c0182bd4DEVICE=eth0ONBOOT=yesIPADDR=191.100.200.30NETMASK=255.255.255.0GATEWAY=192.100.10.161 改成网桥配置后,eth0配置文件及br-provider网桥配置文件/etc/sysconfig/network-scripts/ifcfg-eth0 123456789TYPE=OVSPortDEVICETYPE=ovsNAME=eth0UUID=63754cd8-9152-44a4-b051-ea88c0182bd4DEVICE=eth0ONBOOT=yesIPADDR=0.0.0.0NETMASK=255.255.255.0OVS_BRIDGE=br-provider /etc/sysconfig/network-scripts/ifcfg-br-provider 123456789DEVICE=br-providerDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=192.100.200.30NETMASK=255.255.255.0GATEWAY=192.100.10.161ONBOOT=yes]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建openstack Queens版本本地yum源]]></title>
    <url>%2F2019%2F10%2F24%2FOpenstack%2FYum_OpenstackQueens%2F</url>
    <content type="text"><![CDATA[选择一台CentOS服务器，安装以下软件：1yum install yum-utils createrepo yum-plugin-priorities httpd 开启httpd服务1systemctl start httpd 获取repo文件并使用reposync同步源1yum install -y https://repos.fedorapeople.org/repos/openstack/openstack-queens/rdo-release-queens-2.noarch.rpm 查看源ID列表 1yum repolist 同步openstack-queens这个repo12cd /var/www/html/reposync --repoid=openstack-queens 第一次同步时间较长，同步结束后，执行1createrepo –update /var/www/html/openstack-queens 创建完成后，就可以使用web测试：1http://[ip]/openstack-queens/ 选择另外一台服务器作为客户机12345678910cd /etc/yum.repos.dmv CentOS-Base.repo CentOS-Base.repo_bakcp CentOS-Media.repo CentOS-Media.repo_bakvim CentOS-Media.repo[openstack-queens]name=OpenStack Queens Repositorybaseurl=http://47.98.122.105/openstack-queens/enabled=1gpgcheck=0 配置完成，清除缓存并查看软件包12yum clean allyum list 问题客户端yum安装报错： 12345Error downloading packages: glusterfs-libs-7.5-1.el7.x86_64: failed to retrieve Packages/g/glusterfs-libs-7.5-1.el7.x86_64.rpm from centos7-glustererror was [Errno 2] Local file does not exist: /etc/yum.repos.d/pdate/Packages/g/glusterfs-libs-7.5-1.el7.x86_64.rpm glusterfs-7.5-1.el7.x86_64: failed to retrieve Packages/g/glusterfs-7.5-1.el7.x86_64.rpm from centos7-glustererror was [Errno 2] Local file does not exist: /etc/yum.repos.d/pdate/Packages/g/glusterfs-7.5-1.el7.x86_64.rpm 问题解决：YUM服务器删除对应的repodata文件夹，使用如下命令 1createrepo -pdo /var/www/html/kdpa/ /var/www/html/kdpa/ 重新生成repo链接，问题解决]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack 扩大 RabbitMQ Socket Limit 方法]]></title>
    <url>%2F2019%2F10%2F15%2FOther%2FrabbitmqSocket%2F</url>
    <content type="text"><![CDATA[在RabbitMQ中，Socket descriptors 是 File descriptors 的子集，它们也是一对此消彼长的关系。然而，它们的默认配额并不大，File descriptors 默认值为“1024”，而 Socket descriptors 的默认值也只有“829”，同时，File descriptors 所能打开的最大文件数也受限于操作系统的配额。因此，如果要调整 File descriptors 文件句柄数，就需要同时调整操作系统和RabbitMQ参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@controller ~]# rabbitmqctl statusStatus of node rabbit@controller[&#123;pid,3407&#125;,&#123;running_applications, [&#123;rabbit,"RabbitMQ","3.6.16"&#125;, &#123;rabbit_common, "Modules shared by rabbitmq-server and rabbitmq-erlang-client", "3.6.16"&#125;, &#123;xmerl,"XML parser","1.3.14"&#125;, &#123;ranch,"Socket acceptor pool for TCP protocols.","1.3.2"&#125;, &#123;mnesia,"MNESIA CXC 138 12","4.14.3"&#125;, &#123;syntax_tools,"Syntax tools","2.1.1"&#125;, &#123;ssl,"Erlang/OTP SSL application","8.1.3.1"&#125;, &#123;os_mon,"CPO CXC 138 46","2.4.2"&#125;, &#123;public_key,"Public key infrastructure","1.4"&#125;, &#123;crypto,"CRYPTO","3.7.4"&#125;, &#123;asn1,"The Erlang ASN1 compiler version 4.0.4","4.0.4"&#125;, &#123;recon,"Diagnostic tools for production use","2.3.2"&#125;, &#123;compiler,"ERTS CXC 138 10","7.0.4.1"&#125;, &#123;sasl,"SASL CXC 138 11","3.0.3"&#125;, &#123;stdlib,"ERTS CXC 138 10","3.3"&#125;, &#123;kernel,"ERTS CXC 138 10","5.2"&#125;]&#125;,&#123;os,&#123;unix,linux&#125;&#125;,&#123;erlang_version, "Erlang/OTP 19 [erts-8.3.5.3] [source] [64-bit] [smp:96:96] [async-threads:1024] [hipe] [kernel-poll:true]\n"&#125;,&#123;memory, [&#123;connection_readers,20241544&#125;, &#123;connection_writers,1200000&#125;, &#123;connection_channels,4846312&#125;, &#123;connection_other,53785896&#125;, &#123;queue_procs,6683888&#125;, &#123;queue_slave_procs,0&#125;, &#123;plugins,0&#125;, &#123;other_proc,23512680&#125;, &#123;metrics,2466240&#125;, &#123;mgmt_db,0&#125;, &#123;mnesia,847160&#125;, &#123;other_ets,3015688&#125;, &#123;binary,1999169528&#125;, &#123;msg_index,176072&#125;, &#123;code,21467691&#125;, &#123;atom,891849&#125;, &#123;other_system,75976100&#125;, &#123;allocated_unused,483082808&#125;, &#123;reserved_unallocated,0&#125;, &#123;total,766799872&#125;]&#125;,&#123;alarms,[]&#125;,&#123;listeners,[&#123;clustering,25672,"::"&#125;,&#123;amqp,5672,"::"&#125;]&#125;,&#123;vm_memory_calculation_strategy,rss&#125;,&#123;vm_memory_high_watermark,0.4&#125;,&#123;vm_memory_limit,53742133248&#125;,&#123;disk_free_limit,50000000&#125;,&#123;disk_free,996377710592&#125;,&#123;file_descriptors, [&#123;total_limit,878&#125;, &#123;total_used,776&#125;, &#123;sockets_limit,829&#125;, &#123;sockets_used,774&#125;]&#125;,&#123;processes,[&#123;limit,1048576&#125;,&#123;used,9483&#125;]&#125;,&#123;run_queue,0&#125;,&#123;uptime,161034&#125;,&#123;kernel,&#123;net_ticktime,60&#125;&#125;] 修改系统内核参数系统级别 123vim /etc/sysctl.conffs.file-max=655350 1sysctl -p | grep file-max 用户级别 123456vim /etc/security/limits.conf* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 修改rabbitmq配置如果是以systemd方式管理rabbitmq服务，则需要修改rabbitmq的service文件。 1vim /usr/lib/systemd/system/rabbitmq-server.service 添加如下参数，其值请根据实际情况进行调整： 12[Service]LimitNOFILE=16384 重启rabbitmq即可： 12systemctl daemon-reloadsystemctl restart rabbitmq-server]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrony - 一步搞定NTP时间同步问题]]></title>
    <url>%2F2019%2F09%2F24%2FLinux%2Fchrony%2F</url>
    <content type="text"><![CDATA[什么是chrony？A client/server for the Network Time Protocol, this program keeps your computer’s clock accurate. It was specially designed to support systems with intermittent internet connections, but it also works well in permanently connected environments. It can use also hardware reference clocks, system real-time clock or manual input as time references.chrony是一个ntp协议的实现程序，既可以当做服务端，也可以充当客户端；它专为间歇性互联网连接的系统而设计，当然也能良好应用于持久互联网连接的环境；chrony有三个时间参考：硬件时钟、实时时钟以及手动同步。 chrony的程序环境主配置文件：/etc/chrony.conf客户端程序：/usr/bin/chronyc服务端程序：/usr/sbin/chronyd 为本地服务器配置一个时间服务器环境时间服务器：192.168.1.10允许本网段192.168.1.0/24同步时间。 配置服务端在编辑配置文件之前，我一般习惯于备份一下，以备重新调整。网络时间服务器可以自行查找，网上很多资料，下边配置两个个国内常用的时间服务器： ]# cd /etc/etc]# cp chrony.conf{,.bak}etc]# vim chrony.conf … # iburst为固定格式，记住就可以，没有深究。 server cn.pool.ntp.org iburst server tw.pool.ntp.org iburst ... # 允许指定网络的主机同步时间，不指定就是允许所有，默认不开启。 allow 192.168.1.0/24 ... # 还有一个默认不开启的选项，意思是，即使服务端没有同步到精确的网络时间，也允许向客户端同步不精确的时间。可以视情况而定。 # Serve time even if not synchronized to any NTP server. #local stratum 10~]# systemctl start chronyd.service~]# systemctl enable chronyd.service 客户端同步配置192.168.1.10作为时间服务器 etc]# vim chrony.conf … server 192.168.1.10 iburst …~]# systemctl start chronyd.service~]# systemctl enable chronyd.service 进入chronyc客户端交互式模式：~]# chronyc 查看现有的时间服务器 chronyc&gt; sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 192.168.1.10 10 6 377 53 -4546ns[-5000ns] +/- 234us查看时间服务器状态 chronyc&gt; sourcestats 210 Number of sources = 1 Name/IP Address NP NR Span Frequency Freq Skew Offset Std Dev ============================================================================== 192.168.1.10 10 6 584 +0.001 0.828 +35ns 74us chronyc&gt;exit也可以直接在命令行使用：~]# chronyc sources~]# chronyc sourcestats chrony兼容ntpdate，客户端可以使用ntpdate手动同步时间 12~]# ntpdate 192.168.1.10 9 Nov 02:54:30 ntpdate[39551]: adjust time server 192.168.43.101 offset -0.000003 sec]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[collectd + influxDB + Grafana 搭建监控平台]]></title>
    <url>%2F2019%2F08%2F06%2FOther%2Fmonitor%2F</url>
    <content type="text"><![CDATA[概述常用配置： influxdb + grafana安装在一台机器负责监控数据收集及展示collectd安装在一台或多台被监控服务端,跟监控端的25826端口对接，上传本地监控的数据influxdb监控25826端口以获得数据，自身处于8086端口，grafana从8086获得数据进行展示 InfluxDB 是 Go 语言开发的一个开源分布式时序数据库，非常适合存储指标、事件、分析等数据 collectd C 语言写的一个系统性能采集工具 Grafana 是纯 Javascript 开发的前端工具，用于访问 InfluxDB，自定义报表、显示图表等 本次安装版本 collectd 5.8.1 influxDB 1.7.7 Grafana 6.2.5 Collectdcollectd是一个守护(daemon)进程，用来收集系统性能和提供各种存储方式来存储不同值的机制。比如以RRD 文件形式，当系统运行和存储信息的时候，Collectd会周期性统计系统的相关统计信息。那些信息可以用来找到当前系统性能瓶颈。（如作为性能分析 performance analysis）和预测系统未来的load（如能力部署capacity planning） 安装1# yum install -y collectd 修改配置123456789101112131415161718192021222324252627# vim /etc/collectd.conf#更改以下内容，前面的#记得删除掉 没有就使用find / -name collectd.conf 查找在哪里 FQDNLookup true Hostname "localhost" #直接使用hostname命令查看 BaseDir "/var/lib/collectd" PIDFile "/var/run/collectd.pid" PluginDir "/usr/lib64/collectd" TypesDB "/usr/share/collectd/types.db" LoadPlugin syslog LoadPlugin rrdtool LoadPlugin disk LoadPlugin interface LoadPlugin load LoadPlugin memory LoadPlugin network LoadPlugin processes LoadPlugin users &lt;Plugin interface&gt; Interface "eth0" IgnoreSelected false &lt;/Plugin&gt; &lt;Plugin network&gt; Server "127.0.0.1" "25826" #这里填写的是influxDB安装的服务器ip &lt;Plugin rrdtool&gt; DataDir "/usr/var/lib/collectd/rrd" #如果你是使用下载安装前面应该会多出一个$&#123;prefix&#125;,未尝试是否有影响 &lt;/Plugin&gt; 安装rrdtool插及依赖包1# yum install collectd-rrdtool rrdtool rrdtool-devel 启动collectd12# systemctl start collectd.service #启动# systemctl enable collectd.service #配置开机自启 确认配置是否成功123# cd /var/lib/collectd# lsrrd 如果/var/lib/collectd目录下生成rrd文件，说明有数据了，如果没有应该是配置问题 Influxdb配置yum源配置yum(此方法为最新版本InfluxDB) 12345678# cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo&gt;[influxdb]&gt;name = InfluxDB Repository - RHEL \$releasever&gt;baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable&gt;enabled = 1&gt;gpgcheck = 1&gt;gpgkey = https://repos.influxdata.com/influxdb.key&gt;EOF 安装1# yum install -y influxdb 启动InfluxDB12# systemctl start influxdb.service#启动# systemctl enable influxdb.service #配置influxdb开机自启 启动后TCP端口:8083 为InfluxDB 管理控制台 TCP端口:8086 为客户端和InfluxDB通信时的HTTP API启动后InfluxDB用户认证默认是关闭的，先创建用户:geekwolf geekwolf命令行输入influx 配置数据库12345678910111213141516171819202122232425262728293031323334# influx #进入InfluxDBConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; create database collectdb #创建数据库&gt; show databases #查看数据库name: databases\------namecollectdb&gt; create user matianxin with password &apos;matianxin&apos; #创建一个用户和密码&gt; show users #查看所有用户user adminmatianxin false&gt; grant all on collectdb to matianxin #把上面创建的数据库的所有权限赋给geekwolf用户&gt; help showUsage: connect &lt;host:port&gt; connects to another node specified by host:port auth prompts for username and password pretty toggles pretty print for the json format use &lt;db_name&gt; sets current database format &lt;format&gt; specifies the format of the server responses: json, csv, or column precision &lt;/format&gt;&lt;format&gt; specifies the format of the timestamp: rfc3339, h, m, s, ms, u or ns consistency &lt;level&gt; sets write consistency level: any, one, quorum, or all history displays command history settings outputs the current settings for the shell exit/quit/ctrl+d quits the influx shell show databases show database names show series show series information show measurements show measurement information show tag keys show tag key information show field keys show field key information A full list of influxql commands can be found at: https://docs.influxdata.com/influxdb/v0.10/query_language/spec&gt; quit #退出 启用认证修改配置文件启用认证 12# sed -i 's#auth-enabled = false#auth-enabled = true#g' /etc/influxdb/influxdb.conf# systemctl restart influxdb.service #重启influxdb 配置InfluxDB支持Collectd12345678910# vim /etc/influxdb/influxdb.conf [collectd] enabled = true bind-address = "127.0.0.1:25826" database = "collectdb" typesdb = "/usr/share/collectd/types.db" #查找一下types.db文件不一定在这个路径，如果路径配置错误就不能监听成功 batch-size = 5000 batch-pending = 10 batch-timeout = "10s" read-buffer = 0 1# systemctl restart influxdb.service #重启influxdb 查看25826这个端口是否已经监听，如果有，则代表启动正常 12# netstat -anp| grep 25826udp 0 0 127.0.0.1:25826 0.0.0.0:* 2950/influxd 确认数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990[root@localhost ~]# influxConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; use collectdbUsing database collectdb&gt; show field keysname: cpu_valuefieldKey fieldType-------- ---------value floatname: disk_io_timefieldKey fieldType-------- ---------value floatname: disk_readfieldKey fieldType-------- ---------value floatname: disk_valuefieldKey fieldType-------- ---------value floatname: disk_weighted_io_timefieldKey fieldType-------- ---------value floatname: disk_writefieldKey fieldType-------- ---------value floatname: interface_rxfieldKey fieldType-------- ---------value floatname: interface_txfieldKey fieldType-------- ---------value floatname: load_longtermfieldKey fieldType-------- ---------value floatname: load_midtermfieldKey fieldType-------- ---------value floatname: load_shorttermfieldKey fieldType-------- ---------value floatname: memory_valuefieldKey fieldType-------- ---------value floatname: processes_valuefieldKey fieldType-------- ---------value floatname: users_valuefieldKey fieldType-------- ---------value float&gt; select * from cpu_value limit 10;name: cpu_valuetime host instance type type_instance value---- ---- -------- ---- ------------- -----1565060949576064259 localhost 0 cpu user 26631565060949576080440 localhost 0 cpu system 29521565060949576087737 localhost 0 cpu wait 891565060949576094319 localhost 0 cpu nice 01565060949576100786 localhost 0 cpu interrupt 01565060949576106664 localhost 0 cpu softirq 1601565060949576108568 localhost 0 cpu steal 01565060949576110126 localhost 0 cpu idle 2480671565060959576531164 localhost 0 cpu user 26641565060959576547037 localhost 0 cpu system 2955&gt; Grafana安装12# wget https://dl.grafana.com/oss/release/grafana-6.2.5-1.x86_64.rpm# yum localinstall grafana-6.2.5-1.x86_64.rpm 启动grafana12# systemctl start grafana-server.service #启动# systemctl enable grafana-server.service #配置开机自启 配置Grafana访问地址:http://127.0.0.1:3000 默认账号为admin 密码 admin 配置Data Source Name: InfluxDB -&gt; default URL: http://localhost:8086 Access: Server(Default) Basic Auth: √ Basic Auth Details User: matianxin Password: matianxin InfluxDB Details Database: collectdb …]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（十）Ceilometer + Gnocchi]]></title>
    <url>%2F2019%2F08%2F02%2FOpenstack%2FOpenstackQueens10%2F</url>
    <content type="text"><![CDATA[ceilometer概述什么是ceilometerCeilometer是OpenStack中的一个子项目，它像一个漏斗一样，能把OpenStack内部发生的几乎所有的事件都收集起来，然后为计费和监控以及其它服务提供数据支撑。 Ceilometer服务主要功能： 有效地轮询与OpenStack服务相关的计量数据。 通过监视从服务发送的通知来收集事件和计量数据。 将收集的数据发布到各种目标，包括数据存储和消息队列。 ceilometer如何进行监控Ceilometer监控通过在计算节点部署Compute服务，轮询其计算节点上的instance，获取各自的CPU、网络、磁盘等监控信息，发送到RabbitMQ，Collector服务负责接收信息进行持久化存储，也可通过libvirt和openstack服务的API采集数据。 监控信息存储Ceilometer以前提供了存储和API解决方案。截至N版本，此功能已被正式弃用并且不鼓励。为了有效存储和统计分析ceilometer数据，建议使用Gnocchi。采集信息的存储可以有多种，如文件，数据库等，openstack queens版本默认采用gnocchi+文件形式存储。 gnocchi概述gnocchi是什么Gnocchi是一个多租户时间序列，计量和资源数据库。提供了HTTP REST接口来创建和操作数据。Gnocchi设计用于超大规模计量数据的存储，同时向操作者和用户提供对度量和资源信息的访问。Gnocchi是OpenStack项目的一部分。因此它支持OpenStack，但也能完全独立的工作。 gnocchi项目起源早期的openstack各类资源的计量数据(measurement) 存储在SQL数据库中的sample表中。随着云环境中需要被监控的资源增多和时间的推移，计量数据的增长变得难以预测；计量数据的使用方面，查询操作首先要从巨大的sample单表中过滤所需条目，然后还会涉及到相关的聚合计算；可想而知，由此带来的性能开销绝对是无法忍受的，并且随着时间的推移这个瓶颈会愈加明显直至奔溃。要解决上述问题方法有很多，比如分表：每个监控指标（Metirc）一张表，那么一个资源可能会有多张表（比如一个instance至少会有cpu，cpu.util，memory，memory.usage，disk.* 等监控指标metrics）；这似乎有点夸张，即使这样都可以接受的话，那么查询时对计量数据的聚合操作也还是个问题。为解决以上问题，红帽的Julien Danjou，发起了Gnocchi项目来解决这类问题。其总体思路是：把各个计量指标Metric的计量数据measurement直接写入后端存储中；并在measurement写入之前根据预先设定的归档策略进行聚合操作；查询时直接读取对应的文件即可获得聚合后的监控信息点；gnocchi提供资源索引，这样能更快的找到每个资源的基础信息metadata和其相关的metrics信息。注：数据存储分级：(资源项)resource-&gt;(资源指标条目)metric-&gt;(实际数据)measure 为什么使用gnocchiGnocchi已能够具备在云计算环境中提供可用的时间序列数据库的需要，提供存储大量度量数据并且易于扩展的能力。Gnocchi项目于2014年开始，作为OpenStack Ceilometer项目的分支，以解决Ceilometer在将标准数据库用作计量数据的存储后端时遇到的性能问题。Gnocchi使用各种技术压缩存储数据，降低了数据存储的空间。 ceilometer+gnocchi环境搭建安装部署ceilometer服务前，主机必须已经正确安装keystone、nova、neutron、image服务。部署过程须用到uwsgi和redis。 Compute节点安装安装ceilometer相关包：12# yum install openstack-ceilometer-compute# yum install openstack-ceilometer-ipmi (optional) 编辑/etc/ceilometer/ceilometer.conf文件并完成以下操作 在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问 123[DEFAULT]...transport_url = rabbit://openstack:123456@controller 在该[service_credentials]部分中，配置服务凭据： 12345678910[service_credentials]auth_url = http://controller:5000project_domain_id = defaultuser_domain_id = defaultauth_type = passwordusername = ceilometerproject_name = servicepassword = 123456interface = internalURLregion_name = RegionOne 配置计算服务，编辑/etc/nova/nova.conf文件并在以下[DEFAULT]部分配置通知： 12345678[DEFAULT]...instance_usage_audit = Trueinstance_usage_audit_period = hournotify_on_state_change = vm_and_task_state[oslo_messaging_notifications]...driver = messagingv2 配置计算以轮询IPMI，编辑/etc/sudoers文件并添加包含： 1ceilometer ALL = (root) NOPASSWD: /usr/bin/ceilometer-rootwrap /etc/ceilometer/rootwrap.conf * 编辑/etc/ceilometer/polling.yaml以包含所需： 1234- name: ipmi interval: 300 meters: - hardware.ipmi.temperature 完成安装 启动代理并将其配置为在系统引导时启动： 1234# systemctl enable openstack-ceilometer-compute.service# systemctl start openstack-ceilometer-compute.service# systemctl enable openstack-ceilometer-ipmi.service (optional)# systemctl start openstack-ceilometer-ipmi.service (optional) 重新启动Compute服务： 1# systemctl restart openstack-nova-compute.service Controller节点安装获取admin凭据来访问仅管理员CLI命令1$ . admin-openrc 要创建服务凭据，请完成以下步骤： 创建ceilometer用户： 1234567891011openstack user create --domain default --password-prompt ceilometerUser Password:123456Repeat User Password:123456+-----------+----------------------------------+| Field | Value |+-----------+----------------------------------+| domain_id | e0353a670a9e496da891347c589539e9 || enabled | True || id | c859c96f57bd4989a8ea1a0b1d8ff7cd || name | ceilometer |+-----------+----------------------------------+ 将admin角色添加到ceilometer用户。 1$ openstack role add --project service --user ceilometer admin 在Keystone注册Gnocchi服务 创建gnocchi用户： 1234567891011$ openstack user create --domain default --password-prompt gnocchiUser Password:123456Repeat User Password:123456+-----------+----------------------------------+| Field | Value |+-----------+----------------------------------+| domain_id | e0353a670a9e496da891347c589539e9 || enabled | True || id | 8bacd064f6434ef2b6bbfbedb79b0318 || name | gnocchi |+-----------+----------------------------------+ 创建gnocchi服务实体 1234567891011$ openstack service create --name gnocchi \ --description "Metric Service" metric+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Metric Service || enabled | True || id | 205978b411674e5a9990428f81d69384 || name | gnocchi || type | metric |+-------------+----------------------------------+ 将admin角色添加到gnocchi用户 1$ openstack role add --project service --user gnocchi admin 创建Ceilometer服务API端点 123456789101112131415$ openstack endpoint create --region RegionOne \ metric public http://controller:8041+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b808b67b848d443e9eaaa5e5d796970c || interface | public || region | RegionOne || region_id | RegionOne || service_id | 205978b411674e5a9990428f81d69384 || service_name | gnocchi || service_type | metric || url | http://controller:8041 |+--------------+----------------------------------+ 123456789101112131415$ openstack endpoint create --region RegionOne \ metric internal http://controller:8041+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | c7009b1c2ee54b71b771fa3d0ae4f948 || interface | internal || region | RegionOne || region_id | RegionOne || service_id | 205978b411674e5a9990428f81d69384 || service_name | gnocchi || service_type | metric || url | http://controller:8041 |+--------------+----------------------------------+ 123456789101112131415$ openstack endpoint create --region RegionOne \ metric admin http://controller:8041+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b2c00566d0604551b5fe1540c699db3d || interface | admin || region | RegionOne || region_id | RegionOne || service_id | 205978b411674e5a9990428f81d69384 || service_name | gnocchi || service_type | metric || url | http://controller:8041 |+--------------+----------------------------------+ 安装Gnocchi 安装服务组件 1# yum install openstack-gnocchi-api openstack-gnocchi-metricd python-gnocchiclient 新建文件 /etc/httpd/conf.d/10-gnocchi_wsgi.conf 123456789101112131415161718192021Listen 8041&lt;VirtualHost *:8041&gt; ServerName controller ## Vhost docroot DocumentRoot "/var/www/cgi-bin/gnocchi" ## Directories, there should at least be a declaration for /var/www/cgi-bin/gnocchi &lt;Directory "/var/www/cgi-bin/gnocchi"&gt; Options Indexes FollowSymLinks MultiViews AllowOverride None Require all granted &lt;/Directory&gt; ## Logging ErrorLog "/var/log/httpd/gnocchi_wsgi_error.log" ServerSignature Off CustomLog "/var/log/httpd/gnocchi_wsgi_access.log" combined SetEnvIf X-Forwarded-Proto https HTTPS=1 WSGIApplicationGroup %&#123;GLOBAL&#125; WSGIDaemonProcess gnocchi display-name=gnocchi_wsgi group=gnocchi processes=8 threads=8 user=gnocchi WSGIProcessGroup gnocchi WSGIScriptAlias / "/var/www/cgi-bin/gnocchi/app"&lt;/VirtualHost&gt; 创建文件夹路径下app文件 12mkdir /var/www/cgi-bin/gnocchi/vim /var/www/cgi-bin/gnocchi/app app文件如下： 123456789101112131415161718192021#!/usr/bin/python# Licensed under the Apache License, Version 2.0 (the "License");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or# implied.# See the License for the specific language governing permissions and# limitations under the License.if __name__ == '__main__': import sys from gnocchi.cli import api sys.exit(api.api())else: from gnocchi.cli import api from gnocchi.rest import app application = app.load_app(api.prepare_service()) 文件夹修改权限 12# chown -R gnocchi.gnocchi /var/www/cgi-bin/gnocchi# chmod +777 /var/www/cgi-bin/gnocchi 重启httpd服务 1# systemctl restart httpd 为Gnocchi的索引器创建数据库 使用数据库访问客户端以root用户身份连接到数据库服务器 1234$ mysql -u root -pCREATE DATABASE gnocchi;GRANT ALL PRIVILEGES ON gnocchi.* TO &apos;gnocchi&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;;GRANT ALL PRIVILEGES ON gnocchi.* TO &apos;gnocchi&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; 编辑/etc/gnocchi/gnocchi.conf文件并添加Keystone选项 在[api]中，配置gnocchi以使用keystone： 12[api]auth_mode = keystone 在[keystone_authtoken]部分中，配置keystone身份验证： 12345678910111213[keystone_authtoken]...auth_type = passwordauth_url = http://controller:5000/v3project_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = gnocchipassword = 123456interface = internalURLregion_name = RegionOne[indexer]url = mysql+pymysql://gnocchi:GNOCCHI_DBPASS@controller/gnocchi 在[storage]部分中，配置位置以存储度量标准数据。在这种情况下，我们将它存储到本地文件系统。有关更耐用和高性能驱动程序的列表，请参阅Gnocchi文档： 123456[storage]# coordination_url is not required but specifying one will improve# performance with better workload division across workers.coordination_url = redis://controller:6379file_basepath = /var/lib/gnocchidriver = file 初始化Gnocchi： 1gnocchi-upgrade 完成Gnocchi安装启动Gnocchi服务并将其配置为在系统引导时启动 12# systemctl enable openstack-gnocchi-api.service openstack-gnocchi-metricd.service# systemctl start openstack-gnocchi-api.service openstack-gnocchi-metricd.service 安装Ceilometer包1# yum install openstack-ceilometer-notification openstack-ceilometer-central 编辑/etc/ceilometer/pipeline.yaml文件并完成以下部分，配置Gnocchi连接： 12345publishers: # set address of Gnocchi # + filter out Gnocchi-related activity meters (Swift driver) # + set default archive policy - gnocchi://?filter_project=service&amp;archive_policy=low 编辑/etc/ceilometer/ceilometer.conf文件并完成以下操作 在该[DEFAULT]部分中，配置RabbitMQ消息队列访问： 123[DEFAULT]...transport_url = rabbit://openstack:123456@controller 在该[service_credentials]部分中，配置服务凭据： 1234567891011[service_credentials]...auth_type = passwordauth_url = http://controller:5000/v3project_domain_id = defaultuser_domain_id = defaultproject_name = serviceusername = ceilometerpassword = 123456interface = internalURLregion_name = RegionOne 在Gnocchi创建Ceilometer资源。Gnocchi应该在这个阶段运行： 1# ceilometer-upgrade 完成安装启动Ceilometer服务并将其配置为在系统引导时启动： 1234# systemctl enable openstack-ceilometer-notification.service \ openstack-ceilometer-central.service# systemctl start openstack-ceilometer-notification.service \ openstack-ceilometer-central.service glance neutron服务配置Image 编辑/etc/glance/glance-api.conf文件并完成以下操作：在[DEFAULT]，[oslo_messaging_notifications]部分中，配置通知和RabbitMQ消息代理访问： 1234[DEFAULT]transport_url = rabbit://openstack:123456@controller[oslo_messaging_notifications]driver = messagingv2 编辑/etc/glance/glance-registry.conf文件并完成以下操作：在[DEFAULT]，[oslo_messaging_notifications]部分中，配置通知和RabbitMQ消息代理访问： 1234[DEFAULT]transport_url = rabbit://openstack:123456@controller[oslo_messaging_notifications]driver = messagingv2 完成安装重新启动Image服务： 1# systemctl restart openstack-glance-api.service openstack-glance-registry.service Neutron 配置网络服务以使用Ceilometer 编辑/etc/neutron/neutron.conf并完成以下操作：在这些[oslo_messaging_notifications]部分中，启用通知：123[oslo_messaging_notifications]...driver = messagingv2 完成安装 重启网络服务：1# systemctl restart neutron-server.service 配置环境变量及gnocchi文件夹权限更改目录权限，否则gnocchi存储文件数据时报错，没有权限 1# chmod +777 /var/lib/gnocchi /root/admin-openrc添加gnocchi相关环境变量 1# export OS_AUTH_TYPE=password 监控项列表注意：使用ceilometer监控虚拟机的memory.usage，要求libvirt版本1.1.1+，qemu版本1.5+。并且需要镜像支持balloon，即镜像中安装有balloon的driver。（一般linux镜像都默认包含，但是windows镜像需要另行安装）虚拟机的Cpu：使用时间（cpu）,使用率（cpu_util），分配vcpu个数（vcpus）虚拟机的硬盘：分配总大小（disk.root.size），占用宿主机大小（disk.usage）虚拟机的内存：总大小（memory），使用大小（memory.usage）虚拟机的网络：网络流量（bandwidth），网络下ip个数（ip.floating）虚拟机的镜像：镜像大小（image.download）节点的cpu、硬盘、内存等使用信息可通过linux常用命令监视 nova实例监控项 Name Type Unit Resource Origin Support Note 翻译 memory Gauge MB instance ID Notification Libvirt, Hyper-V Volume of RAM allocated to the instance 分配给实例的RAM量 memory.usage Gauge MB instance ID Pollster Libvirt, Hyper-V, vSphere, XenAPI Volume of RAM used by the instance from the amount of its allocated memory 实例从其分配的内存量中使用的RAM量 … 参考：https://docs.openstack.org/ceilometer/latest/admin/telemetry-measurements.html 详细监控方法介绍采集信息查询方法此方案中采集信息以gnocchi+文件方式存储。获取采集信息有两种方式，分别为 gnocchi-api和gnocchi 命令。以下采用gnocchi命令做详细介绍：注：数据存储分级：(资源项)resource-&gt;(资源指标条目)metric-&gt;(实际数据)measure 获取权限 1# . admin-openrc 获取监控资源列表 1# gnocchi resource list 获取实例监控资源对象信息列表获取某一instance下所有监控条目 12345678910111213141516171819202122232425[root@controller ~]# gnocchi resource show 8bb00e90-7e3f-5ef6-bee5-00e7c6bbc5fc+-----------------------+-------------------------------------------------------------------+| Field | Value |+-----------------------+-------------------------------------------------------------------+| created_by_project_id | e06fb4ce67a24aa687dffb9d8dcc6b1e || created_by_user_id | 4895e340408e42c383ea8d82e459b182 || creator | 4895e340408e42c383ea8d82e459b182:e06fb4ce67a24aa687dffb9d8dcc6b1e || ended_at | None || id | 8bb00e90-7e3f-5ef6-bee5-00e7c6bbc5fc || metrics | disk.device.allocation: 427a316e-1ef9-4054-8253-604b80e8f003 || | disk.device.capacity: 6915cd9b-1346-46db-8e86-438fd1884b49 || | disk.device.latency: fcfbc2ae-eddf-4ff9-bda9-33b9a2ba9c3d || | disk.device.read.bytes: 6df3416c-ad02-401e-84e4-5ac0b75febf2 || | disk.device.read.latency: 4014d3c6-51ea-4e24-b8e6-649ed6ee896d || | disk.device.usage: 7cd08e21-a0e1-4fce-8dc8-0e8b96d711d4 || | disk.device.write.bytes: b29abf7c-a9c4-4afc-89a5-ef766739028b || | disk.device.write.latency: f82d69ec-98d6-45e8-bc13-cd040f8cc2ef || original_resource_id | 86d618b5-aadc-4346-b620-7f44fc35c7ad-vda || project_id | 40026f6973464ee9a19ad04f6221e213 || revision_end | None || revision_start | 2019-05-07T05:08:10.450142+00:00 || started_at | 2019-05-07T05:08:10.450123+00:00 || type | instance_disk || user_id | 5a4da861d8e84cbdabd98b9804bc1547 |+-----------------------+-------------------------------------------------------------------+ 获取实例监控条目详细信息 1# gnocchi measures show 897356e6-d0bb-43cd-9cbd-43ab2808384d]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（九）Cinder服务]]></title>
    <url>%2F2019%2F08%2F01%2FOpenstack%2FOpenstackQueens9%2F</url>
    <content type="text"><![CDATA[存储服务概念OpenStack块存储服务(Cinder)将持久性存储添加到一个虚拟机。块存储提供了管理卷的基础设施，并与OpenStack计算交互，为实例提供卷。该服务还支持卷快照和卷类型的管理。块存储服务由以下组件组成:cinder-api接收API请求，并将其路由到cinders -volume以进行操作。cinder-volume直接与块存储服务和进程(如cinders -scheduler)交互。它还可以通过消息队列与这些进程进行交互。cinders -volume服务响应发送到块存储服务的读写请求，以维护状态。它可以通过驱动程序体系结构与各种存储提供者交互。cinder-scheduler daemon选择要在其上创建卷的最佳存储提供程序节点。与nova-scheduler类似的组件。cinder-backup daemonCinder-backup服务向备份存储提供程序提供任何类型的备份卷。与cinders -volume服务一样，它可以通过驱动程序体系结构与各种存储提供者交互。Messaging queue在块存储进程之间路由信息。 Controller节点：基础配置在安装和配置块存储服务之前，必须创建数据库、服务凭据和API端点。 创建数据库，为cinder数据库授权1234# mysql -uroot -p123456MariaDB [(none)]&gt; create database cinder;MariaDB [(none)]&gt; grant all privileges on cinder.* to 'cinder'@'localhost' identified by '123456';MariaDB [(none)]&gt; grant all privileges on cinder.* to 'cinder'@'%' identified by '123456'; 创建服务凭据生成管理凭证，以获得访问只有管理CLI命令: 1# . admin-openrc 创建cinder用户： 1# openstack user create --domain default --password-prompt cinder 添加admin角色到cinder用户中： （无返回值） 1# openstack role add --project service --user cinder admin 创建cinder2和cinderv3服务实体:注：块存储服务需要两个服务实体。 1234# openstack service create --name cinderv2 \ --description "OpenStack Block Storage" volumev2# openstack service create --name cinderv3 \ --description "OpenStack Block Storage" volumev3 123456# openstack endpoint create --region RegionOne \ volumev3 public http://controller:8776/v3/%\(project_id\)s# openstack endpoint create --region RegionOne \ volumev3 internal http://controller:8776/v3/%\(project_id\)s# openstack endpoint create --region RegionOne \ volumev3 admin http://controller:8776/v3/%\(project_id\)s 安装配置组件1# yum install -y openstack-cinder 编辑 /etc/cinder/cinder.conf文件1# vi /etc/cinder/cinder.conf 在[database]选项，配置数据库访问:12[database]connection = mysql+pymysql://cinder:123456@controller/cinder 在[DEFAULT]部分，配置RabbitMQ消息队列访问: 12[DEFAULT]transport_url = rabbit://openstack:123456@controller 在[DEFAULT]和[keystone_authtoken]选项，配置身份服务访问: 123456789101112[DEFAULT]auth_strategy = keystone[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_id = defaultuser_domain_id = defaultproject_name = serviceusername = cinderpassword = 123456 在[DEFAULT]选项，配置my_ip选项，使用Controller节点的管理接口IP地址: 12[DEFAULT]my_ip = 192.100.200.68 在[oslo_concurrency]选项，配置lock路径: 12[oslo_concurrency]lock_path = /var/lib/cinder/tmp 同步块存储数据（忽略此输出中的任何弃用消息。） 1# su -s /bin//sh -c "cinder-manage db sync" cinder 配置计算服务以使用块存储编辑 /etc/nova/nova.conf 文件 123# vi /etc/nova/nova.conf[cinder]os_regioon_name = RegionOne 启动服务123# systemctl restart openstack-nova-api.service# systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service# systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service 存储节点：安装LVM包:1# yum install -y lvm2 启动LVM元数据服务，并将其配置为在系统启动时启动:注：一些发行版默认安装LVM。 12# systemctl enable lvm2-lvmetad.service# systemctl start lvm2-lvmetad.service 创建LVM物理卷/dev/sdb:12# pvcreate /dev/sdb Physical volume "/dev/sdb" successfully created. 创建LVM卷组cinder-volmes:注：块存储服务在此卷组中创建逻辑卷。 12# vgcreate cinder-volumes /dev/sdb Volume group "cinder-volumes" successfully created 只有实例可以访问块存储卷。然而，底层操作系统管理与卷相关联的设备。默认情况下，LVM卷扫描工具扫描/dev目录中包含卷的块存储设备。如果项目在其卷上使用LVM，那么扫描工具将检测这些卷并试图缓存它们，这会导致底层操作系统和项目卷出现各种问题。必须重新配置LVM，以便只扫描包含cinder-volume卷组的设备。 编辑 /etc/lvm/lvm.conf文件在devices选项，添加一个接受/dev/sdb设备并拒绝所有其他设备的过滤器:注：filter数组中的每个项都以for accept或r for reject开头，并包含一个用于设备名称的正则表达式。数组必须以r/结束。*/ 拒绝任何剩余设备。您可以使用vgs -vvvv命令来测试过滤器。 1234devices &#123;...filter = [ "a/sdb/", "r/.*/"]...&#125; 安装配置组件1# yum install -y openstack-cinder targetcli python-keystone 编辑/etc/cinder/cinder.conf 文件1# vi /etc/cinder/cinder.conf 在[database]选项，配置数据库访问 12[database]connection = mysql+pymysql://cinder:123456@controller/cinder 在[DEFAULT]选项，配置RabbitMQ消息队列访问: 12[DEFAULT]transport_url = rabbit://openstack:123456@controller 在[DEFAULT]和[keystone_authtoken]选项，配置身份服务访问: 123456789101112[DEFAULT]auth_strategy = keystone[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_id = defaultuser_domain_id = defaultproject_name = serviceusername = cinderpassword = 123456 在[DEFAULT]部分，配置my_ip选项: 1my_ip = 192.168.100.69 在[DEFAULT]选项，配置映像服务API的位置: 1glance_api_servers = http://controller:9292 在[lvm]选项，使用lvm驱动程序、Cinder卷组、iSCSI协议和iSCSI服务配置lvm后端。如果[lvm]部分不存在，则添加它: 12345[lvm]volume_driver = cinder.volume.drivers.lvm.LVMVolumeDrivervolume_group = cinder-volumesiscsi_protocol = iscsiiscsi_helper = lioadm 在[DEFAULT]部分，启用LVM后端: 12[DEFAULT]enabled_backends = lvm 在[oslo_concurrency]节中，配置lock路径 12[oslo_concurrency]lock_path = /var/lib/cinder/tmp 开启服务启动块存储卷服务，包括它的依赖项，并配置它们在系统启动时启动: 12# systemctl enable openstack-cinder-volume.service target.service# systemctl restart openstack-cinder-volume.service target.service 校验操作生成临时环境变量 1# . admin-openrc 列出服务组件以验证每个流程的成功启动: 1# openstack volume service list 创建一个1G的卷，并查看其状态 12# cinder create --display-name myVolume 1# cinder list]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（八）计算节点实例首次孵化优化]]></title>
    <url>%2F2019%2F07%2F29%2FOpenstack%2FOpenstackQueens8%2F</url>
    <content type="text"><![CDATA[Controller节点：创建镜像缓存目录，并调整权限123# mkdir -p /var/lib/glance/imagecache# chmod -R 777 /var/lib/glance/images# chmod -R 777 /var/lib/glance/imagecache 配置共享文件夹，将与控制节点管理网卡同网段的CIDR配置入文件，并赋读写权限123# vim /etc/exports/var/lib/glance/imagecache 192.100.10.0/24(rw) 加载刚才的配置文件1# exportfs -e 注意控制节点的iptables，要放开111（rpc）、2049(nfs)和892(nfs挂载)端口，一般在OpenStack中这几个端口都是默认放开的。设置nfs服务开机启动，并启动nfs1234# systemctl enable rpcbind# systemctl enable nfs# systemctl restart rpcbind# systemctl restart nfs 确认本地共享目录是否正确（showmount -e）计算节点计算节点配置nfs挂载以及系统开机自动挂载有脚本实现在计算节点创建文件夹，并将项目源码中的脚本拷贝上去1# mkdir -p /var/www/kdpa/bin 将项目源码中/kdpa/bin/目录下的sed_rclocal.sh、mount_nfs.sh脚本拷贝到计算节点新创建的目录下1234567891011121314151617sed_rclocal.sh#!/usr/bin/env bashrc_local_file="/etc/rc.d/rc.local"chmod 755 $&#123;rc_local_file&#125;# add mount nfs shell in rc.localmount_nfs_sh="/var/www/kdpa/bin/mount_nfs.sh"chmod 755 $&#123;mount_nfs_sh&#125;echo "/usr/bin/sh $&#123;mount_nfs_sh&#125;"&gt;&gt;$&#123;rc_local_file&#125;# add ovs set-manager shell in rc.localovs_set_manager_sh="/var/www/kdpa/bin/ovs_set_manager.sh"chmod 755 $&#123;ovs_set_manager_sh&#125;echo "/usr/bin/sh $&#123;ovs_set_manager_sh&#125;"&gt;&gt;$&#123;rc_local_file&#125; 123456789101112mount_nfs.sh#!/usr/bin/env bashnfs_service_image_cache_path="/var/lib/glance/imagecache"local_image_cache_path="/var/lib/nova/instances/_base"controller_host=$(cat /etc/hosts | grep controller | awk '&#123;print $1&#125;')mkdir -p $&#123;local_image_cache_path&#125;chmod -R 777 $&#123;local_image_cache_path&#125;mount -t nfs4 $&#123;controller_host&#125;:$&#123;nfs_service_image_cache_path&#125; $&#123;local_image_cache_path&#125; 执行脚本mount_nfs.sh挂载控制节点nfs共享目录1# sh /var/www/kdpa/bin/mount_nfs.sh 验证挂载是否成功1# mount -l | grep 服务端IP 执行脚本sed_rclocal.sh调整系统开机启动脚本1# sh /var/www/kdpa/bin/sed_rclocal.sh 最终查看/etc/rc.d/rc.local文件是否添加成功]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAlchemy 中的 Engine 是什么]]></title>
    <url>%2F2019%2F07%2F17%2FMysql%2FSQLAlchemyEngine%2F</url>
    <content type="text"><![CDATA[连接池很重要，因为每次发送sql查询的时候都需要先建立连接，如果程序启动的时候事先就初始化一批连接放在连接池，每次用完后又放回连接池给其它请求使用，就能大大提高查询的效率。 Engine 初始化Engine 的初始化非常简单，通过工厂函数 create_engine 就可以创建。 123from sqlalchemy import create_engineengine = create_engine('mysql://user:password@localhost:3306/test?charset=utf8') 构建好 Engine 对象的同时，连接池和Dialect也创建好了，但是这时候并不会立马与数据库建立真正的连接，只有你调用 Engine.connect() 或者 Engine.execute(sql) 执行SQL请求的时候，才会建立真正的连接。因此 Engine 和 Pool 的行为称之为延迟初始化，等真正要派上用场的时候才去建立连接。 需要注意的是，创建引擎时，如果数据库的密码含有特殊字符，需要先编码处理 123&gt;&gt;&gt; import urllib.parse&gt;&gt;&gt; urllib.parse.quote_plus("kx%jj5/g")'kx%25jj5%2Fg' 其它数据库方言初始化 engine 的方式可参考官方文档： https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls create_engine 还有很多可选参数，这里介绍几个重要的参数。 12345engine = create_engine('mysql://user:password@localhost:3306/test?charset=utf8', echo=False pool_size=100, pool_recycle=3600, pool_pre_ping=True) echo ：为 True 时候会把sql语句打印出来，当然，你可以通过配置logger来控制输出，这里不做讨论。 pool_size： 是连接池的大小，默认为5个，0表示连接数无限制 pool_recycle： MySQL 默认情况下如果一个连接8小时内容没有任何动作（查询请求）就会自动断开链接，出现 MySQL has gone away的错误。设置了 pool_recycle 后 SQLAlchemy 就会在指定时间内回收连接。如果设置为3600 就表示 1小时后该连接会被自动回收。 pool_pre_ping ： 这是1.2新增的参数，如果值为True，那么每次从连接池中拿连接的时候，都会向数据库发送一个类似 select 1 的测试查询语句来判断服务器是否正常运行。当该连接出现 disconnect 的情况时，该连接连同pool中的其它连接都会被回收。 参考链接： https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls https://stackoverflow.com/questions/34322471/sqlalchemy-engine-connection-and-session-difference https://docs.sqlalchemy.org/en/13/core/pooling.html#dealing-with-disconnects]]></content>
      <categories>
        <category>SQLAlchemy</category>
      </categories>
      <tags>
        <tag>sqlalchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux top 命令详解]]></title>
    <url>%2F2019%2F07%2F12%2FLinux%2Ftop%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425$ toptop - 10:14:44 up 15 days, 20:18, 8 users, load average: 6.99, 3.36, 2.62Tasks: 985 total, 2 running, 983 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.7 us, 13.2 sy, 7.2 ni, 78.7 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16142800 total, 1201456 free, 14020500 used, 920844 buff/cacheKiB Swap: 8191996 total, 6339272 free, 1852724 used. 1396492 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND22195 root 20 0 4995348 264576 18712 S 7.9 1.6 26:02.20 gnome-shell28393 root 26 6 438932 95064 6416 S 3.3 0.6 16:52.90 python25155 root 20 0 163096 3436 1684 S 1.7 0.0 0:22.93 top 4092 root 20 0 413152 96096 4812 S 1.3 0.6 33:59.19 Xvnc23570 nova 26 6 456196 29632 4524 S 1.3 0.2 131:28.54 nova-conductor23724 nova 26 6 513364 42712 4908 S 1.3 0.3 135:03.59 nova-api12833 neutron 26 6 497996 135052 4608 S 1.0 0.8 59:59.61 neutron-dhcp-ag20537 nobody 20 0 254952 10144 4152 S 1.0 0.1 0:01.45 php-fpm28987 root 20 0 162940 3248 1620 R 1.0 0.0 0:00.22 top 5016 root 20 0 527732 3760 1500 S 0.7 0.0 0:34.49 ibus-daemon 7012 root 20 0 928104 26384 8988 S 0.7 0.2 9:19.03 gnome-terminal- 8040 openvsw+ 26 6 1316280 160352 12192 S 0.7 1.0 170:13.54 ovs-vswitchd 9408 etcd 26 6 11.6g 9896 2052 S 0.7 0.1 176:00.49 etcd23586 glance 26 6 502376 13540 4984 R 0.7 0.1 99:49.88 glance-api 1 root 26 6 201696 5700 2100 S 0.3 0.0 5:16.81 systemd 3 root 20 0 0 0 0 S 0.3 0.0 1:49.34 ksoftirqd/0 统计信息区前五行是系统整体的统计信息。 第一行是任务队列信息，同 uptime。 命令的执行结果。其内容如下： 10:14:44 系统当前时间 up 15 days, 20:18 系统运行时间，格式为时:分 8 users 当前登录用户数 load average: 6.99, 3.36, 2.62 系统负载，即任务队列的平均长度。 三个数值分别为1分钟、5分钟、15分钟前到现在的平均值。 第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下： Tasks: 985 total 进程总数 2 running 正在运行的进程数 983 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s): 0.7% us 用户空间占用CPU百分比 13.2% sy 内核空间占用CPU百分比 7.2% ni 用户进程空间内改变过优先级的进程占用CPU百分比 78.7% id 空闲CPU百分比 0.1% wa 等待输入输出的CPU时间百分比 0.0% hi 0.0% si 最后两行为内存信息。内容如下： Mem: 16142800 total 物理内存总量 14020500 used 使用的物理内存总量 1201456 free 空闲内存总量 920844 buff/cache 用作内核缓存的内存量 Swap: 8191996 total 交换区总量 1852724k used 使用的交换区总量 6339272 free 空闲交换区总量 1396492 avail Mem 统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态。 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 默认情况下仅显示比较重要的PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND列。可以通过下面的快捷键来更改显示内容。更改显示内容通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z可以将相应的列向左移动。最后按回车键确定。按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转。 命令使用1．工具（命令）名称top 2．工具（命令）作用显示系统当前的进程和其他状况；top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定. 3．环境设置在Linux下使用。 4．使用方法4．1使用格式top [-][d][p][q][c][C][S][s][n] 4．2参数说明 d 指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。 p 通过指定监控进程ID来仅仅监控某个进程的状态。 q 该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。 S 指定累计模式 s 使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。 i 使top不显示任何闲置或者僵死进程。 c 显示整个命令行而不只是显示命令名 4.3其他下面介绍在top命令执行过程中可以使用的一些交互命令。从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。 Ctrl+L 擦除并且重写屏幕。 h或者? 显示帮助画面，给出一些简短的命令总结说明。 k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。 i 忽略闲置和僵死进程。这是一个开关式命令。 q 退出程序。 r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。 S 切换到累计模式。 s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成ms。输入0值则系统将不断刷新，默认值是5s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。 f或者F 从当前显示中添加或者删除项目。 o或者O 改变显示项目的顺序。 l 切换显示平均负载和启动时间信息。 m 切换显示内存信息。 t 切换显示进程和CPU状态信息。 c 切换显示命令名称和完整命令行。 M 根据驻留内存大小进行排序。 P 根据CPU使用百分比大小进行排序。 T 根据时间/累计时间进行排序。 W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack命令行]]></title>
    <url>%2F2019%2F07%2F11%2FOpenstack%2FOpenstackTerminal%2F</url>
    <content type="text"><![CDATA[Keystone列出所有的用户123456789101112$ openstack user list+----------------------------------+-----------+| ID | Name |+----------------------------------+-----------+| 2ac5fe07105a43518ae444a37640222b | demo || 5bc73e84451b4e71906232bd3849422d | neutron || 84b0b75df69f4413a1380c9efc249b2d | placement || 87bf7fb4671f4524a6fa64ad75856594 | admin || 9aaa5aa26b414d35b37b851ccf749a55 | nova || eee2818e703e47c5a434e5926c90e7fb | glance |+----------------------------------+-----------+ 列出认证服务目录1234567891011121314151617181920212223242526272829303132333435363738394041$ openstack catalog list+-----------+-----------+-----------------------------------------+| Name | Type | Endpoints |+-----------+-----------+-----------------------------------------+| placement | placement | RegionOne || | | internal: http://controller:8778 || | | RegionOne || | | public: http://controller:8778 || | | RegionOne || | | admin: http://controller:8778 || | | || keystone | identity | RegionOne || | | internal: http://controller:5000/v3/ || | | RegionOne || | | public: http://controller:5000/v3/ || | | RegionOne || | | admin: http://controller:5000/v3/ || | | || neutron | network | RegionOne || | | public: http://controller:9696 || | | RegionOne || | | admin: http://controller:9696 || | | RegionOne || | | internal: http://controller:9696 || | | || glance | image | RegionOne || | | admin: http://controller:9292 || | | RegionOne || | | internal: http://controller:9292 || | | RegionOne || | | public: http://controller:9292 || | | || nova | compute | RegionOne || | | internal: http://controller:8774/v2.1 || | | RegionOne || | | admin: http://controller:8774/v2.1 || | | RegionOne || | | public: http://controller:8774/v2.1 || | | |+-----------+-----------+-----------------------------------------+ Glance列出您可以访问的镜像123456789101112131415161718$ openstack image list+--------------------------------------+---------------------+--------+| ID | Name | Status |+--------------------------------------+---------------------+--------+| 70d455f6-1a00-48f5-9b21-5f8fca019014 | centos7-mini | active || 1a7e4d60-3c26-41bb-be0c-34c467b2d3c3 | pstunnel | active || b2464312-8acb-4ff9-ba20-75560e5577f4 | pstunnelA | active || 705c7007-8a28-49e8-8df7-61bbfbf41bbd | pstunnelB | active || ad02946e-9c1f-42f0-9a9e-235ae7012bc3 | router | active || ae8c618d-3c6e-449c-9d2a-3f08bf84cc5e | router22 | active || b54361d4-bc24-46cb-94b2-b1f672b01c2a | sw-f-in-centos7_ext | active || 3a1adf75-c82e-4540-91e0-2167cb921612 | sw-f-in-centos7_int | active || ebfc7c40-4ac3-42ab-96ae-65e3c17af194 | sw-z-in-centos7_ext | active || 7355a66c-3f05-4ed5-9088-540faf71ebf8 | sw-z-in-centos7_int | active || 3b19c8ad-6012-406a-9e7f-e66416deeb1e | testforimage | active || 436c5ab5-14e7-4eb8-95b9-e47d85e60e83 | win7 | active |+--------------------------------------+---------------------+--------+ 查看一个指定的镜像12345678910111213141516171819202122232425$ openstack image show [IMAGE-ID/IMAGE-Name]$ openstack image show 70d455f6-1a00-48f5-9b21-5f8fca019014+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | f3ab346b3ca2b88d1347c24adf0b234b || container_format | bare || created_at | 2019-06-26T09:08:51Z || disk_format | qcow2 || file | /v2/images/70d455f6-1a00-48f5-9b21-5f8fca019014/file || id | 70d455f6-1a00-48f5-9b21-5f8fca019014 || min_disk | 0 || min_ram | 0 || name | centos7-mini || owner | 2e69bc10ab5f427bbbd6d40148d96309 || protected | False || schema | /v2/schemas/image || size | 3758882816 || status | active || tags | || updated_at | 2019-06-26T09:09:32Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 上传QCOW2镜像123456789101112131415161718192021222324$ openstack image create "centos7-mini2" --file centos7-mini.qcow2 --disk-format qcow2 --container-format bare --public+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | f3ab346b3ca2b88d1347c24adf0b234b || container_format | bare || created_at | 2019-07-11T07:56:51Z || disk_format | qcow2 || file | /v2/images/4072bdfb-f727-4e3f-a1f5-c3467b12a15e/file || id | 4072bdfb-f727-4e3f-a1f5-c3467b12a15e || min_disk | 0 || min_ram | 0 || name | centos7-mini2 || owner | 2e69bc10ab5f427bbbd6d40148d96309 || protected | False || schema | /v2/schemas/image || size | 3758882816 || status | active || tags | || updated_at | 2019-07-11T07:57:54Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 删除指定的镜像123$ openstack image delete [IMAGE-ID/IMAGE-Name]$ openstack image delete 4072bdfb-f727-4e3f-a1f5-c3467b12a15e Nova列出实例1234567891011121314$ openstack server list+--------------------------------------+-------------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+---------------------+| ID | Name | Status | Networks | Image | Flavor |+--------------------------------------+-------------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+---------------------+| 2ec1ace1-ef83-4d30-837e-f7f2df344a6c | n-UDYIQCS6 | SHUTOFF | network_5261=192.168.1.3 | win7 | win7 || 88a7d91d-3c29-461e-8d07-a0d272697a61 | n-L9QGOHRE | SHUTOFF | network_12177=192.168.1.19 | win7 | win7 || 274543b3-7890-4446-a5d0-1c6acfb9e1f4 | vm_n-4ejn7bk2c9o@28 | ACTIVE | network_10888=192.168.1.18 | win7 | win7 || c2cb7d6c-4f3e-4f32-bbd5-19639d415481 | sw_n-pf6p66vh4f_ext@33 | SHUTOFF | network_10360=192.168.1.3; n-XH29F3CG-net=8.8.8.9; network_21065=192.168.1.6; network_16174=192.168.1.5 | sw-z-in-centos7_ext | sw-z-in-centos7_ext || 5e009b71-4a8b-478a-9f17-349153a26ad4 | n-UE0N48YS | SHUTOFF | network_11645=192.168.1.4; network_14835=192.168.1.13; network_20101=192.168.1.9; internal=20.0.0.23, 192.100.200.225; network_18377=192.168.1.3; network_8075=192.168.1.10 | pstunnel | pstunnel || 374aedbe-d7c3-4f89-a66d-020401a257dc | n-MF9XYLTQ_int | SHUTOFF | network_23143=192.168.1.7; network_14693=192.168.1.7; network_13651=192.168.1.11 | sw-z-in-centos7_int | sw-z-in-centos7_int || acd8efcb-9350-4e19-a105-a1bcfb529697 | rt_n-une1ph6cts@20 | SHUTOFF | Rnet_n-une1ph6cts_0=192.168.3.1; Rnet_n-une1ph6cts_1=192.168.2.1 | router | router || 1efe6a9a-d005-4b32-926f-bb94fb702a05 | vm_n-vp0eo8lm0c@20 | SHUTOFF | network_14083=192.168.1.10 | | |+--------------------------------------+-------------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+---------------------+ 显示实例详细信息1234567891011121314151617181920212223242526272829303132333435$ openstack server show [SERVER-ID/SERVER-Name]$ openstack server show 2ec1ace1-ef83-4d30-837e-f7f2df344a6c+-------------------------------------+----------------------------------------------------------+| Field | Value |+-------------------------------------+----------------------------------------------------------+| OS-DCF:diskConfig | MANUAL || OS-EXT-AZ:availability_zone | nova || OS-EXT-SRV-ATTR:host | compute || OS-EXT-SRV-ATTR:hypervisor_hostname | compute || OS-EXT-SRV-ATTR:instance_name | instance-00000294 || OS-EXT-STS:power_state | Shutdown || OS-EXT-STS:task_state | None || OS-EXT-STS:vm_state | stopped || OS-SRV-USG:launched_at | 2019-07-11T06:30:19.000000 || OS-SRV-USG:terminated_at | None || accessIPv4 | || accessIPv6 | || addresses | network_5261=192.168.1.3 || config_drive | || created | 2019-07-11T06:30:12Z || flavor | win7 (fd8297ef-d7ac-4b4f-8c1e-1c90fcce488c) || hostId | 37f71a5ebb11ac3ed0f0496a313bb9246829f1da1839c8fd3dc4f98b || id | 2ec1ace1-ef83-4d30-837e-f7f2df344a6c || image | win7 (436c5ab5-14e7-4eb8-95b9-e47d85e60e83) || key_name | None || name | n-UDYIQCS6 || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || properties | || security_groups | name='default' || status | SHUTOFF || updated | 2019-07-11T06:31:30Z || user_id | 87bf7fb4671f4524a6fa64ad75856594 || volumes_attached | |+-------------------------------------+----------------------------------------------------------+ Neutron列出所有网络12345678$ openstack network list+--------------------------------------+----------------------+--------------------------------------+| ID | Name | Subnets |+--------------------------------------+----------------------+--------------------------------------+| 01e6c390-1d5e-4140-9ea3-98754bd0c58f | network_29287 | 8ed09dee-0e16-4514-8821-9a8e1f77c43a || 030f303e-e3d3-46e1-a85a-5ea6cea4d3ba | n-69PSABRW-net | e2ea53d0-1b29-43d3-910b-3296d96d004f |+--------------------------------------+----------------------+--------------------------------------+ 查看网络12345678910111213141516171819202122232425262728293031323334$ openstack network show NETWORK-ID$ openstack network show 01e6c390-1d5e-4140-9ea3-98754bd0c58f+---------------------------+--------------------------------------+| Field | Value |+---------------------------+--------------------------------------+| admin_state_up | UP || availability_zone_hints | || availability_zones | nova || created_at | 2019-06-19T02:16:06Z || description | || dns_domain | None || id | 01e6c390-1d5e-4140-9ea3-98754bd0c58f || ipv4_address_scope | None || ipv6_address_scope | None || is_default | None || is_vlan_transparent | None || mtu | 1500 || name | network_29287 || port_security_enabled | True || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || provider:network_type | vxlan || provider:physical_network | None || provider:segmentation_id | 29287 || qos_policy_id | None || revision_number | 3 || router:external | Internal || segments | None || shared | True || status | ACTIVE || subnets | 8ed09dee-0e16-4514-8821-9a8e1f77c43a || tags | || updated_at | 2019-06-19T02:16:07Z |+---------------------------+--------------------------------------+ 列出所有子网12345678$ openstack subnet list+--------------------------------------+-----------------------+--------------------------------------+------------------+| ID | Name | Network | Subnet |+--------------------------------------+-----------------------+--------------------------------------+------------------+| 00414731-ab21-4ee8-8bf2-86d960cc4339 | network_sub_18721 | 84d6ee39-77b3-4a0b-80f8-67922b63079a | 192.168.1.0/24 || 014cb2e2-bdbe-4849-aec7-5fe0581e3b67 | network_sub_20494 | 6eb235c5-798c-49de-8fd3-08aa64f9abaa | 192.168.1.0/24 |+--------------------------------------+-----------------------+--------------------------------------+------------------+ 查看子网12345678910111213141516171819202122232425262728$ openstack subnet show SUBNET-ID$ openstack subnet show 00414731-ab21-4ee8-8bf2-86d960cc4339+-------------------+--------------------------------------+| Field | Value |+-------------------+--------------------------------------+| allocation_pools | 192.168.1.2-192.168.1.254 || cidr | 192.168.1.0/24 || created_at | 2019-07-11T02:09:49Z || description | || dns_nameservers | || enable_dhcp | True || gateway_ip | 192.168.1.1 || host_routes | || id | 00414731-ab21-4ee8-8bf2-86d960cc4339 || ip_version | 4 || ipv6_address_mode | None || ipv6_ra_mode | None || name | network_sub_18721 || network_id | 84d6ee39-77b3-4a0b-80f8-67922b63079a || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || revision_number | 0 || segment_id | None || service_types | || subnetpool_id | None || tags | || updated_at | 2019-07-11T02:09:49Z |+-------------------+--------------------------------------+ 列出所有port12345678$ openstack port list+--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+| ID | Name | MAC Address | Fixed IP Addresses | Status |+--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+| 01f86921-016b-4df8-b526-ec81418b5df5 | | fa:16:3e:b9:c8:a8 | ip_address='20.0.0.2', subnet_id='c00a64e4-8921-427c-aa71-74f7a2c55954' | ACTIVE || 0280ba23-7a51-483c-a7a4-2351f277f739 | | fa:16:3e:ab:63:69 | ip_address='192.168.2.1', subnet_id='c4b84a4b-ce15-49e8-ae6b-72566224682c' | DOWN |+--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+ 查看port12345678910111213141516171819202122232425262728293031323334353637383940$ openstack port show PORT-ID$ openstack port show 01f86921-016b-4df8-b526-ec81418b5df5+-----------------------+-------------------------------------------------------------------------------+| Field | Value |+-----------------------+-------------------------------------------------------------------------------+| admin_state_up | UP || allowed_address_pairs | || binding_host_id | controller || binding_profile | || binding_vif_details | datapath_type='system', ovs_hybrid_plug='True', port_filter='True' || binding_vif_type | ovs || binding_vnic_type | normal || created_at | 2019-06-19T01:41:33Z || data_plane_status | None || description | || device_id | dhcpd3377d3c-a0d1-5d71-9947-f17125c357bb-361f196b-154a-4e51-bc34-7162d043be1b || device_owner | network:dhcp || dns_assignment | None || dns_name | None || extra_dhcp_opts | || fixed_ips | ip_address='20.0.0.2', subnet_id='c00a64e4-8921-427c-aa71-74f7a2c55954' || id | 01f86921-016b-4df8-b526-ec81418b5df5 || ip_address | None || mac_address | fa:16:3e:b9:c8:a8 || name | || network_id | 361f196b-154a-4e51-bc34-7162d043be1b || option_name | None || option_value | None || port_security_enabled | False || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || qos_policy_id | None || revision_number | 6 || security_group_ids | || status | ACTIVE || subnet_id | None || tags | || trunk_details | None || updated_at | 2019-06-19T01:41:35Z |+-----------------------+-------------------------------------------------------------------------------+ 摘自：Openstack官方文档 https://docs.openstack.org/zh_CN/user-guide/cli-cheat-sheet.html]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack修改系统网络配额]]></title>
    <url>%2F2019%2F07%2F11%2FOpenstack%2FOpenstackNeutronQuotas%2F</url>
    <content type="text"><![CDATA[前言neutron在安装配置完成之后，openstack为了实现对所有tenant对网络资源的使用，针对neutron设置有专门的配额，以防止租户使用过多的资源，而对其他的tenant造成影响。和nova的quota相类似，neutron也使用单独的一个驱动来实现网络neutron的配额控制。 neutron默认的配额neutron默认的配额针对network，port，router，subnet，floatingip做了配额方面的限定，参考neutron的配置文件，获取quota的配额内容为: 12345678910111213141516[root@controller ~]# vim /etc/neutron/neutron.conf[quotas]quota_driver = neutron.db.quota_db.DbQuotaDriver 配额驱动quota_items = network,subnet,port quota限定的范畴default_quota = -1 默认的quota，-1表示没有限制(未启用)quota_network = 10 建立的network个数quota_subnet = 10 建立的subnet个数quota_port = 50 允许的port个数quota_security_group = 10 安全组的个数quota_security_group_rule = 100 安全组规规则条数quota_vip = 10 vip个数，以下的quota_member和quota_health_monitors 都用于LBaaS场景quota_pool = 10 pool个数quota_member = -1 member个数quota_health_monitors = -1 monitor个数quota_router = 10 router的个数quota_floatingip = 50 floating-ip个数 修改neutron的配额查看neutron默认的配额 123456789[root@controller ~]# keystone tenant-list+----------------------------------+----------+---------+| id | name | enabled |+----------------------------------+----------+---------+| 842ab3268a2c47e6a4b0d8774de805ae | admin | True || 7ff1dfb5a6f349958c3a949248e56236 | companyA | True | #得到tenant的uuid号| 10d1465c00d049fab88dec1af0f56b1b | demo | True || 3b57a14f7c354a979c9f62b60f31a331 | service | True |+----------------------------------+----------+---------+ 12345678910111213141516[root@controller ~]# neutron quota-show --tenant-id 7ff1dfb5a6f349958c3a949248e56236+---------------------+-------+| Field | Value |+---------------------+-------+| floatingip | 50 || health_monitor | -1 || member | -1 || network | 10 || pool | 10 || port | 50 | #port，每台虚拟机都需要一个ip，即一个port，很容易就超过配额| router | 10 || security_group | 10 || security_group_rule | 100 || subnet | 10 || vip | 10 |+---------------------+-------+ 修改neutron配额 12345678910111213141516[root@controller ~]# neutron quota-update --network 20 --subnet 20 --port 100 --router 5 --floatingip 100 --security-group 10 --security-group-rule 100 --tenant-id 7ff1dfb5a6f349958c3a949248e56236+---------------------+-------+| Field | Value |+---------------------+-------+| floatingip | 100 || health_monitor | -1 || member | -1 || network | 20 || pool | 10 || port | 100 || router | 5 || security_group | 10 || security_group_rule | 100 || subnet | 20 || vip | 10 |+---------------------+-------+ 校验neutron的quota配置 12345678910111213141516[root@controller ~]# neutron quota-show --tenant-id 7ff1dfb5a6f349958c3a949248e56236+---------------------+-------+| Field | Value |+---------------------+-------+| floatingip | 100 || health_monitor | -1 || member | -1 || network | 20 || pool | 10 || port | 100 || router | 5 || security_group | 10 || security_group_rule | 100 || subnet | 20 || vip | 10 |+---------------------+-------+ 统计port的个数1234567891011[root@controller ~]# neutron port-list+--------------------------------------+------+-------------------+---------------------------------------------------------------------------------------+| id | name | mac_address | fixed_ips |+--------------------------------------+------+-------------------+---------------------------------------------------------------------------------------+| 0060ec4a-957d-4571-b730-6b4a9bb3baf8 | | fa:16:3e:48:42:3d | &#123;"subnet_id": "9654a807-d4fa-49f1-abb6-2e45d776c69f", "ip_address": "10.16.4.19"&#125; || 00942be0-a3a9-471d-a4ba-336db0ee1539 | | fa:16:3e:73:75:03 | &#123;"subnet_id": "ad4a5ffc-3ccc-42c4-89a1-61e7b18632a3", "ip_address": "10.16.6.96"&#125; || 0119045c-8219-4744-bd58-a7e77294832c | | fa:16:3e:10:ed:7f | &#123;"subnet_id": "9654a807-d4fa-49f1-abb6-2e45d776c69f", "ip_address": "10.16.4.71"&#125; || 04f7d8ea-1849-4938-9ef7-e8114893132f | | fa:16:3e:50:86:1b | &#123;"subnet_id": "ad4a5ffc-3ccc-42c4-89a1-61e7b18632a3", "ip_address": "10.16.6.27"&#125; |[root@controller ~]# neutron port-list |wc -l #超过配额时，需要修改194 总结随着时间的推移，当越来越多的instance加入到openstack中，port也会相应增加，一个ip对应一个port，所以当port达到配额时，openstack会组织用户继续分配虚拟机，此时，就需要修改neutron的配额了，关于neutron配额的报错，可以参考neutron的日志/var/log/neutron/neutron-server.log，可以根据日志的信息，定位到报错的原因，具体不赘述。 附录neutron实现quota的代码解读 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197[root@controller ~]# vim /usr/lib/python2.6/site-packages/neutron/db/quota_db.pyimport sqlalchemy as safrom neutron.common import exceptionsfrom neutron.db import model_basefrom neutron.db import models_v2'''quota数据库表的表结构，tenant默认集成的配额从这里获取mysql&gt; desc quotas;+-----------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-----------+--------------+------+-----+---------+-------+| id | varchar(36) | NO | PRI | NULL | || tenant_id | varchar(255) | YES | MUL | NULL | || resource | varchar(255) | YES | | NULL | || limit | int(11) | YES | | NULL | |+-----------+--------------+------+-----+---------+-------+'''class Quota(model_base.BASEV2, models_v2.HasId): """Represent a single quota override for a tenant. If there is no row for a given tenant id and resource, then the default for the quota class is used. """ tenant_id = sa.Column(sa.String(255), index=True) resource = sa.Column(sa.String(255)) limit = sa.Column(sa.Integer)'''quota配额的具体实现，根据数据库的配置内容，实现quota的控制，即quota的增删改查方法'''class DbQuotaDriver(object): """Driver to perform necessary checks to enforce quotas and obtain quota information. The default driver utilizes the local database. """ ''' 得到租户tenant的quota，执行neutron quota-show --tenant-id uuid时调用的方法 ''' @staticmethod def get_tenant_quotas(context, resources, tenant_id): """Given a list of resources, retrieve the quotas for the given tenant. :param context: The request context, for access checks. :param resources: A dictionary of the registered resource keys. :param tenant_id: The ID of the tenant to return quotas for. :return dict: from resource name to dict of name and limit """ # init with defaults 得到quota默认的配额项item，即所谓的network，subnet，port和router等，以及对应的值 tenant_quota = dict((key, resource.default) for key, resource in resources.items()) # update with tenant specific limits 从数据库中获取最新的quota配置信息，并更新 q_qry = context.session.query(Quota).filter_by(tenant_id=tenant_id) tenant_quota.update((q['resource'], q['limit']) for q in q_qry) return tenant_quota ''' quota的删除，即执行neutron quota-delete 的方法，删除之后，tenant将会集成默认的的quota配置 ''' @staticmethod def delete_tenant_quota(context, tenant_id): """Delete the quota entries for a given tenant_id. Atfer deletion, this tenant will use default quota values in conf. """ #从neutron。quotas数据库中查询到所有的quota配置之后，过略某个具体的tenant的quota，之后执行delete()方法将其删除 with context.session.begin(): tenant_quotas = context.session.query(Quota) tenant_quotas = tenant_quotas.filter_by(tenant_id=tenant_id) tenant_quotas.delete() ''' 得到所有租户tenant的配额资源，即执行neutron quota-list所查看的内容 ''' @staticmethod def get_all_quotas(context, resources): """Given a list of resources, retrieve the quotas for the all tenants. :param context: The request context, for access checks. :param resources: A dictionary of the registered resource keys. :return quotas: list of dict of tenant_id:, resourcekey1: resourcekey2: ... """ tenant_default = dict((key, resource.default) for key, resource in resources.items()) all_tenant_quotas = &#123;&#125; for quota in context.session.query(Quota): tenant_id = quota['tenant_id'] # avoid setdefault() because only want to copy when actually req'd #如果quotas表中，没有找到配置选项，说明使用默认的quota配置，直接用默认的copy过来即可，有配置则继承quotas表中的配置 tenant_quota = all_tenant_quotas.get(tenant_id) if tenant_quota is None: tenant_quota = tenant_default.copy() tenant_quota['tenant_id'] = tenant_id all_tenant_quotas[tenant_id] = tenant_quota tenant_quota[quota['resource']] = quota['limit'] return all_tenant_quotas.values() ''' 更新quota的配置，即执行neutron quota-update命令的具体实现 ''' @staticmethod def update_quota_limit(context, tenant_id, resource, limit): with context.session.begin(): tenant_quota = context.session.query(Quota).filter_by( tenant_id=tenant_id, resource=resource).first() #有配置内容，则更新，没有则根据资源的配置内容，在数据库中添加对应的条目 if tenant_quota: tenant_quota.update(&#123;'limit': limit&#125;) else: tenant_quota = Quota(tenant_id=tenant_id, resource=resource, limit=limit) context.session.add(tenant_quota) def _get_quotas(self, context, tenant_id, resources, keys): """Retrieves the quotas for specific resources. A helper method which retrieves the quotas for the specific resources identified by keys, and which apply to the current context. :param context: The request context, for access checks. :param tenant_id: the tenant_id to check quota. :param resources: A dictionary of the registered resources. :param keys: A list of the desired quotas to retrieve. """ desired = set(keys) sub_resources = dict((k, v) for k, v in resources.items() if k in desired) # Make sure we accounted for all of them... if len(keys) != len(sub_resources): unknown = desired - set(sub_resources.keys()) raise exceptions.QuotaResourceUnknown(unknown=sorted(unknown)) # Grab and return the quotas (without usages) quotas = DbQuotaDriver.get_tenant_quotas( context, sub_resources, tenant_id) return dict((k, v) for k, v in quotas.items()) ''' neutron quota的校验，即在执行过程中，调用该方法，确认tenant的quota是否在合理的范围内 ''' def limit_check(self, context, tenant_id, resources, values): """Check simple quota limits. For limits--those quotas for which there is no usage synchronization function--this method checks that a set of proposed values are permitted by the limit restriction. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it is not a simple limit resource. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns nothing. :param context: The request context, for access checks. :param tenant_id: The tenant_id to check the quota. :param resources: A dictionary of the registered resources. :param values: A dictionary of the values to check against the quota. """ # Ensure no value is less than zero quota的配置值不能为负数 unders = [key for key, val in values.items() if val &lt; 0] if unders: raise exceptions.InvalidQuotaValue(unders=sorted(unders)) # Get the applicable quotas quotas = self._get_quotas(context, tenant_id, resources, values.keys()) # Check the quotas and construct a list of the resources that # would be put over limit by the desired values overs = [key for key, val in values.items() if quotas[key] &gt;= 0 and quotas[key] &lt; val] if overs: raise exceptions.OverQuota(overs=sorted(overs)) 摘自：https://segmentfault.com/a/1190000018750816]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中InnoDB和MyISAM的存储引擎区别]]></title>
    <url>%2F2019%2F07%2F10%2FMysql%2FMysqlEngine%2F</url>
    <content type="text"><![CDATA[InnoDB存储引擎：InnoDB存储引擎支持事务，其设计目标主要就是面向OLTP（On Line Transaction Processing 在线事务处理）的应用。特点为行锁设计、支持外键，并支持非锁定读。从5.5.8版本开始，InnoDB成为了MySQL的默认存储引擎。 InnoDB存储引擎采用聚集索引（clustered）的方式来存储数据，因此每个表都是按照主键的顺序进行存放，如果没有指定主键，InnoDB会为每行自动生成一个6字节的ROWID作为主键。 MyISAM存储引擎：MyISAM存储引擎不支持事务、表锁设计，支持全文索引，主要面向OLAP（On Line Analytical Processing 联机分析处理）应用，适用于数据仓库等查询频繁的场景。在5.5.8版本之前，MyISAM是MySQL的默认存储引擎。该引擎代表着对海量数据进行查询和分析的需求。它强调性能，因此在查询的执行速度比InnoDB更快。 MyISAM存储引擎还有一个特点是只缓存索引文件，而不缓存数据文件，这点非常独特。 InnoDB和MyISAM的区别:事务为了数据库操作的原子性，我们需要事务。保证一组操作要么都成功，要么都失败，比如转账的功能。我们通常将多条SQL语句放在begin和commit之间，组成一个事务。 InnoDB支持，MyISAM不支持。 主键由于InnoDB的聚集索引，其如果没有指定主键，就会自动生成主键。MyISAM支持没有主键的表存在。 外键为了解决复杂逻辑的依赖，我们需要外键。比如高考成绩的录入，必须归属于某位同学，我们就需要高考成绩数据库里有准考证号的外键。 InnoDB支持，MyISAM不支持。 索引为了优化查询的速度，进行排序和匹配查找，我们需要索引。比如所有人的姓名从a-z首字母进行顺序存储，当我们查找zhangsan或者第44位的时候就可以很快的定位到我们想要的位置进行查找。 InnoDB是聚集索引，数据和主键的聚集索引绑定在一起，通过主键索引效率很高。如果通过其他列的辅助索引来进行查找，需要先查找到聚集索引，再查询到所有数据，需要两次查询。 MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据的指针。 从InnoDB 1.2.x版本，MySQL5.6版本后，两者都支持全文索引。 auto_increment对于自增数的字段，InnoDB要求必须有只有该字段的索引。但MyISAM可以将该字段与其他字段组成联合索引。 表行数很常见的需求是看表中有多少条数据，此时我们需要 1select count(*) from table_name; InnoDB不保存表行数，需要进行全表扫描。MyISAM用一个变量保存，直接读取该值，更快。当时当带有where查询的时候，两者一样。 存储数据库的文件都是需要在磁盘中进行存储，当应用需要时再读取到内存中。一般包含数据文件、索引文件。 InnoDB分为：.frm表结构文件.ibdata1共享表空间.ibd表独占空间.redo日志文件 MyISAM分为三个文件：.frm存储表定义.MYD存储表数据.MYI存储表索引 执行速度如果你的操作是大量的查询操作，如SELECT，使用MyISAM性能会更好。如果大部分是删除和更改的操作，使用InnoDB。 delete调用delete from table时，MyISAM会直接重建表，InnoDB会一行一行的删除，但是可以用truncate table代替。 锁MyISAM仅支持表锁，每次操作锁定整张表。InnoDB支持行锁，每次操作锁住最小数量的行数据。 表锁相比于行锁消耗的资源更少，且不会出现死锁，但同时并发性能差。行锁消耗更多的资源，速度较慢，且可能发生死锁，但是因为锁定的粒度小、数据少，并发性能好。如果InnoDB的一条语句无法确定要扫描的范围，也会锁定整张表。 当行锁发生死锁的时候，会计算每个事务影响的行数，然后回滚行数较少的事务。 数据恢复MyISAM崩溃后无法快速的安全恢复。InnoDB有一套完善的恢复机制。 数据缓存MyISAM仅缓存索引数据，通过索引查询数据。InnoDB不仅缓存索引数据，同时缓存数据信息，将数据按页读取到缓存池，按LRU（Latest Rare Use 最近最少使用）算法来进行更新。 如何选择存储引擎创建表的语句都是相同的，只有最后的type来指定存储引擎。 MyISAM1.大量查询总count2.查询频繁，插入不频繁3.没有事务操作 InnoDB1.需要高可用性，或者需要事务2.表更新频繁 摘自：https://segmentfault.com/a/1190000019713794]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 1040 Too many connections 错误与解决办法]]></title>
    <url>%2F2019%2F07%2F01%2FMysql%2FTooManyConnections%2F</url>
    <content type="text"><![CDATA[日志报如下错误: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364Traceback (most recent call last): File &quot;/var/www/kdpa/project/api/host.py&quot;, line 339, in showInstanceConsole File &quot;/var/www/kdpa/project/api/hostImpl.py&quot;, line 500, in showInstanceConsoleImpl opsVmId = self.hostDao.getOpsVmIdByUuid(uuid) File &quot;/var/www/kdpa/project/core/modifier.py&quot;, line 46, in _dao return daoFn(*args, **kwargs) File &quot;/var/www/kdpa/project/dao/host/hostDao.py&quot;, line 168, in getOpsVmIdByUuid host = session.query(Host).filter(Host.uuid == str(uuid)).first() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3222, in first ret = list(self[0:1]) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3012, in __getitem__ return list(res) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3324, in __iter__ return self._execute_and_instances(context) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3346, in _execute_and_instances querycontext, self._connection_from_session, close_with_result=True File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3361, in _get_bind_args mapper=self._bind_mapper(), clause=querycontext.statement, **kw File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3339, in _connection_from_session conn = self.session.connection(**kw) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/session.py&quot;, line 1124, in connection execution_options=execution_options, File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/session.py&quot;, line 1130, in _connection_for_bind engine, execution_options File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/session.py&quot;, line 431, in _connection_for_bind conn = bind._contextual_connect() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 2226, in _contextual_connect self._wrap_pool_connect(self.pool.connect, None), File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 2266, in _wrap_pool_connect e, dialect, self File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 1536, in _handle_dbapi_exception_noconnection util.raise_from_cause(sqlalchemy_exception, exc_info) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/util/compat.py&quot;, line 399, in raise_from_cause reraise(type(exception), exception, tb=exc_tb, cause=cause) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 2262, in _wrap_pool_connect return fn() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 363, in connect return _ConnectionFairy._checkout(self) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 760, in _checkout fairy = _ConnectionRecord.checkout(pool) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 492, in checkout rec = pool._do_get() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/impl.py&quot;, line 139, in _do_get self._dec_overflow() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/util/langhelpers.py&quot;, line 68, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/impl.py&quot;, line 136, in _do_get return self._create_connection() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 308, in _create_connection return _ConnectionRecord(self) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 437, in __init__ self.__connect(first_connect_check=True) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 639, in __connect connection = pool._invoke_creator(self) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/strategies.py&quot;, line 114, in connect return dialect.connect(*cargs, **cparams) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/default.py&quot;, line 451, in connect return self.dbapi.connect(*cargs, **cparams) File &quot;build/bdist.linux-x86_64/egg/MySQLdb/__init__.py&quot;, line 81, in Connect return Connection(*args, **kwargs) File &quot;build/bdist.linux-x86_64/egg/MySQLdb/connections.py&quot;, line 187, in __init__ super(Connection, self).__init__(*args, **kwargs2)OperationalError: (_mysql_exceptions.OperationalError) (1040, &apos;Too many connections&apos;)(Background on this error at: http://sqlalche.me/e/e3q8) 解决方式： 查看当前数据库最大连接数： 1234567MariaDB [(none)]&gt; select VARIABLE_VALUE from information_schema.GLOBAL_VARIABLES where VARIABLE_NAME='MAX_CONNECTIONS';+----------------+| VARIABLE_VALUE |+----------------+| 214 |+----------------+1 row in set (0.00 sec) 12345vi /etc/systemd/system/mariadb.service.d/limits.conf[Service]LimitNOFILE=65535LimitNPROC=65535 保存，退出。 12systemctl daemon-reloadsystemctl restart mariadb.service 重启后查看： 1234567MariaDB [(none)]&gt; select VARIABLE_VALUE from information_schema.GLOBAL_VARIABLES where VARIABLE_NAME='MAX_CONNECTIONS';+----------------+| VARIABLE_VALUE |+----------------+| 4096 |+----------------+1 row in set (0.00 sec) 4096配置在Openstack的mysql配置 /etc/my.cnf.d/openstack.cnf中max_connections = 4096。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[压力测试工具ab使用方法]]></title>
    <url>%2F2019%2F06%2F28%2FLinux%2Fab%2F</url>
    <content type="text"><![CDATA[安装在CentOS7-mini环境下，ab运行需要依赖apr-util，httpd-tools包，安装命令为： 1yum install apr-util httpd-tools -y 执行测试12#vi post.txtuuid=n-vp0eo8lm0c&amp; 1ab -c 10 -n 10 -p 'post.txt' -T 'application/x-www-form-urlencoded' http://192.100.200.140:8000/api/instance/show 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.100.200.140 (be patient).....doneServer Software: nginx/1.9.9Server Hostname: 192.100.200.140Server Port: 8000Document Path: /api/instance/showDocument Length: 23 bytesConcurrency Level: 10Time taken for tests: 1.378 secondsComplete requests: 10Failed requests: 6 (Connect: 0, Receive: 0, Length: 6, Exceptions: 0)Write errors: 0Non-2xx responses: 3Total transferred: 3398 bytesTotal body sent: 1940HTML transferred: 1787 bytesRequests per second: 7.26 [#/sec] (mean)Time per request: 1377.853 [ms] (mean)Time per request: 137.785 [ms] (mean, across all concurrent requests)Transfer rate: 2.41 [Kbytes/sec] received 1.37 kb/s sent 3.78 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.1 0 1Processing: 68 543 548.0 246 1256Waiting: 68 543 548.0 246 1256Total: 69 544 548.0 247 1257Percentage of the requests served within a certain time (ms) 50% 247 66% 1095 75% 1157 80% 1196 90% 1257 95% 1257 98% 1257 99% 1257 100% 1257 (longest request) 参数说明：-n 10 表示请求总数为10 -c 10 表示并发用户数为10 http://192.100.200.140:8000/api/instance/show 表示这写请求的目标URL 测试结果也一目了然，测试出的吞吐率为：Requests per second: 2015.93 [#/sec] (mean) 初次之外还有其他一些信息。 Server Software 表示被测试的Web服务器软件名称 Server Hostname 表示请求的URL主机名 Server Port 表示被测试的Web服务器软件的监听端口 Document Path 表示请求的URL中的根绝对路径，通过该文件的后缀名，我们一般可以了解该请求的类型 Document Length 表示HTTP响应数据的正文长度 Concurrency Level 表示并发用户数，这是我们设置的参数之一 Time taken for tests 表示所有这些请求被处理完成所花费的总时间 Complete requests 表示总请求数量，这是我们设置的参数之一 Failed requests 表示失败的请求数量，这里的失败是指请求在连接服务器、发送数据等环节发生异常，以及无响应后超时的情况。如果接收到的HTTP响应数据的头信息中含有2XX以外的状态码，则会在测试结果中显示另一个名为 “Non-2xx responses”的统计项，用于统计这部分请求数，这些请求并不算在失败的请求中。 Total transferred 表示所有请求的响应数据长度总和，包括每个HTTP响应数据的头信息和正文数据的长度。注意这里不包括HTTP请求数据的长度，仅仅为web服务器流向用户PC的应用层数据总长度。 HTML transferred 表示所有请求的响应数据中正文数据的总和，也就是减去了Total transferred中HTTP响应数据中的头信息的长度。 Requests per second 吞吐率，计算公式：Complete requests / Time taken for tests Time per request 用户平均请求等待时间，计算公式：Time token for tests/（Complete requests/Concurrency Level） Time per requet(across all concurrent request) 服务器平均请求等待时间，计算公式：Time taken for tests/Complete requests，正好是吞吐率的倒数。也可以这么统计：Time per request/Concurrency Level Transfer rate 表示这些请求在单位时间内从服务器获取的数据长度，计算公式：Total trnasferred/ Time taken for tests，这个统计很好的说明服务器的处理能力达到极限时，其出口宽带的需求量。 Percentage of requests served within a certain time（ms） 这部分数据用于描述每个请求处理时间的分布情况，比如以上测试，80%的请求处理时间都不超过6ms，这个处理时间是指前面的Time per request，即对于单个用户而言，平均每个请求的处理时间。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验室虚拟化主站厂站拓扑搭建]]></title>
    <url>%2F2019%2F06%2F25%2FOther%2FkdpaTopo%2F</url>
    <content type="text"><![CDATA[虚拟化正向隔离①创建虚拟化正向隔离组件 SW_1，开机②创建虚拟交换机 Switch_2，开机③创建虚拟交换机 Switch_3，开机④创建虚拟主机[win7-2-ok]-主站PC PC_4，开机⑤创建虚拟主机[win7-2-ok]-安全三区PC PC_5，开机⑥创建虚拟主机[win7-2-ok]-隔离SW_1管理工具 PC_6，开机⑦配置PC_4IP地址：192.168.1.10 255.255.255.0 192.168.1.1⑧配置PC_5IP地址：192.168.1.20 255.255.255.0 192.168.1.1⑨配置Switch_2：1-4口配置VLAN1001⑩配置Switch_3：1-4口配置VLAN1002⑪创建串口线，连接SW_1串口（内）与PC_6⑫创建网线，连接SW_1网卡0（内）与Switch_2网口1⑬创建网线，连接SW_1网卡0（外）与Switch_3网口1⑭创建网线，连接PC_4网卡0与Switch_2网口2⑮创建网线，连接PC_5网卡0与Switch_3网口2⑯配置正向隔离管理工具PC_6：配置管理工具。 PC_6右键 -&gt; 上传/下载 -&gt; 传入vc_redist.2015.x64与全QT界面隔离管理工具中包含vcruntime140.dll，libcrypto-1_1.dll。 -&gt; 关闭 安装vc_redist.2015.x64 打开全QT界面隔离管理工具Stonewall.exe 屏幕分辨率 -&gt; 1024×768 用户名：admin 密码：111111 串口登录。 串口：COM1。 频率：115200。 权限：管理员。 √ 正向隔离。 设备配置 -&gt; 基本配置 管理IP： 无 -&gt; 不填 设备名称： zsw -&gt; 自定义 点击写入 规则配置 -&gt; 主机信息1 -&gt; 添加 SW_1 -&gt; 进入内网隔离系统 -&gt; 清除主机信息与连接信息 -&gt; 删除/etc/mac.conf 和 /etc/rules √ IP和MAC地址绑定 主机名： PC_4 -&gt; 自定义 MAC1： FA:16:3E:40:11:01 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.10 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.11 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 主机信息2 -&gt; 添加 √ IP和MAC地址绑定 主机名： PC_5 -&gt; 自定义 MAC1： FA:16:3E:40:11:02 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.20 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.21 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 连接信息 规则名： rule -&gt; 自定义 (内网)IP地址： 192.100.1.10 (内网)虚拟IP： 192.100.1.11 (内网)网口号： ETH0/网口0 (外网)IP地址： 192.100.1.20 (外网)虚拟IP： 192.100.1.21 (外网)网口号： ETH0/网口0 协议： TCP ⑰配置后查看SW_1 /etc/mac.conf和/etc/rules是否与配置相同。重启SW_1内网隔离与外网隔离。 正向隔离： 发送端为内网 接收端为外网 sender：PC_4 receiver：PC_5 ⑱配置及启动正向隔离外网接收端工具。 PC_5 -&gt; 进入系统 -&gt; 右键 -&gt; Terminal -&gt; 以管理员身份运行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\正向\receive 以jar包方式运行 java -jar StoneWall-recv.jar ⑲配置及启动正向隔离内网发送端工具。 PC_4 -&gt; 进入系统 -&gt; 右键 -&gt; Terminal -&gt; 以管理员身份运行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\send 以jar包方式运行 java -jar StoneWall-send.jar 待发送的文件（任何类型）-&gt; 右键 -&gt; 发送 任务名称： task √ 主任务 目的IP地址： 192.168.1.21 -&gt; 接收端虚拟IP地址 目的端口号： 7777 目的文件夹： d:/test -&gt; 自定义 √ 立即发送 查看日志及接收端是否发送成功。 虚拟化反向隔离⑳创建虚拟化反向隔离组件 SW_2，开机㉑创建虚拟主机[win7-2-ok]-隔离SW_2管理工具 PC_7，开机㉒创建串口线，连接SW_2串口（外）与PC_7㉓创建网线，连接SW_2网卡0（内）与Switch_2网口3㉔创建网线，连接SW_2网卡0（外）与Switch_3网口3㉕⑯配置反向隔离管理工具PC_7：配置管理工具。 PC_7右键 -&gt; 上传/下载 -&gt; 传入vc_redist.2015.x64与全QT界面隔离管理工具中包含vcruntime140.dll，libcrypto-1_1.dll。 -&gt; 关闭 安装vc_redist.2015.x64 打开全QT界面隔离管理工具Stonewall.exe 屏幕分辨率 -&gt; 1024×768 用户名：admin 密码：111111 串口登录。 串口：COM1。 频率：115200。 权限：管理员。 √ 反向隔离。 设备配置 -&gt; 基本配置 管理IP： 无 -&gt; 不填 设备名称： fsw -&gt; 自定义 ETH0协商IP： 192.168.1.200 -&gt; 与发送端须配置成相同网段 ETH1协商IP： 0.0.0.0 -&gt; 可不做配置 规则配置 -&gt; 主机信息1 -&gt; 添加 SW_2 -&gt; 进入外网隔离系统 -&gt; 清除主机信息与连接信息 -&gt; 删除/etc/mac.conf 和 /etc/rules √ IP和MAC地址绑定 主机名： PC_5 -&gt; 自定义 MAC1： FA:16:3E:40:11:02 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.20 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.22 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 主机信息2 -&gt; 添加 √ IP和MAC地址绑定 主机名： PC_4 -&gt; 自定义 MAC1： FA:16:3E:40:11:01 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.10 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.12 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 连接信息 规则名： rule -&gt; 自定义 (内网)IP地址： 192.100.1.10 (内网)虚拟IP： 192.100.1.12 (内网)网口号： ETH0/网口0 (外网)IP地址： 192.100.1.20 (外网)虚拟IP： 192.100.1.22 (外网)网口号： ETH0/网口0 协议： UDP 证书秘钥 -&gt; 设备秘钥 设备密钥 √ RSA -&gt; 导出设备证书文件 -&gt; fsw.cer 上传/下载 -&gt; fsw.cer导出到本地 ㉖配置及启动反向隔离内网接收端工具。 上传/下载 -&gt; 新的隔离接收端工具new_udp_recv_4.2.2.jar -&gt; 复制到目录D:\software\隔离传输软件\反向\receive\下 右键 -&gt; Terminal -&gt; 以管理员身份运行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\反向\receive 以jar包方式运行 java -jar new_udp_recv_4.2.2.jar ㉗配置及启动反向隔离外网发送端工具。 上传/下载 -&gt; 新的隔离接收端工具new_udp_send_4.2.2.jar -&gt; 复制到目录D:\software\隔离传输软件\反向\send\下 上传/下载 -&gt; 反向隔离端证书 fsw.cer 检查config目录下是否有**.p12文件，若存在，则删除。 启动传输软件。 new_udp_recv_4.2.2.jar 右键 -&gt; 以管理员身份运行 -&gt; 命令行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\反向\send 12java -jar new_udp_recv_4.2.2.jar设置密码口令保护窗口如果报错，需先运行jreUpdate1.8.jar 出现提示：系统检测到密钥尚未存在，是否需要生成密钥？ -&gt; 是 创建登录口令：123456。 确定，提示操作成功。 登录窗口： 操作员名称： administrator 操作员密码： 12345678 密钥保护口令： 123456 管理 -&gt; 密钥管理 -&gt; 导出密钥。 -&gt; sender.cer 上传/下载 -&gt; 反向隔离发送端证书 sender.cer 设定 -&gt; 配置加密隧道 隧道名称： Tunnel-1 隧道的协商IP地址： 192.168.1.200 -&gt; 设备ETH0协商IP 隧道的协商端口： 4558 隧道每次通过的文件数： 100 隔离设备证书路径： ../.. fsw.cer 设定 -&gt; 配置链路信息 链路名称： Link-1 目的IP地址： 192.168.1.12 -&gt; 接收端IP地址，正反向隔离在相同环境的情况下，配置虚拟IP。 目的端口： 7777 发送失败等待周期(秒)： 30 使用隧道： Tunnel-1 ㉘PC_7导入发送端证书。 发送端证书 -&gt; 删除其他 发送端证书 -&gt; 添加 发送端IP： 192.168.1.20 -&gt; 此处为发送端IP，不为虚拟IP 证书标识： sender.cer ㉙重启SW_2内网隔离与外网隔离。㉚PC_5发送E文本。 待发送的文件（E文本）-&gt; 右键 -&gt; 发送 任务名称： task1 目的文件夹： d:/test -&gt; 自定义 选择链路 -&gt; Link-1 -&gt; 添加 不符合发送条件的文件备份至 -&gt; 当前文档目录 查看日志及接收端是否发送成功。 如果发现隔离发送进行中一直在校验E文本规范，不发送的情况，重新打开发送端工具。 虚拟化纵向㉛创建虚拟化纵向[电力纵向]PS_1，开机㉜创建虚拟化纵向[电力纵向]PS_2，开机㉝创建虚拟路由器R，配置：网卡1：192.168.1.0/24 网卡2：192.168.2.0/24，开机㉞创建虚拟交换机 Switch_1，开机㉟创建虚拟主机[win7-2]PC_3，开机㊱创建虚拟主机[win7-2]PC_2，开机㊲创建虚拟主机[win7-2]PC_1，开机㊳创建虚拟USB-KEY UK_1，插入PS_1㊴创建虚拟USB-KEY UK_2，插入PS_2㊵配置Switch_1：1-2口配置VLAN1003㊶配置PC_3IP地址：169.254.200.201 255.255.255.0 169.254.200.1㊷配置PC_2IP地址：169.254.200.201 255.255.255.0 169.254.200.1㊸配置PC_1IP地址：192.168.2.20 255.255.255.0 192.168.2.1㊹创建网线，连接PS_1网口0与Switch_2网口4㊺创建网线，连接PS_1网口1与R网口1㊻创建网线，连接PS_2网口1与R网口2㊼创建网线，连接PS_2网口0与Switch_1网口1㊽创建网线，连接PC_1网卡0与Switch_1网口2㊾创建网线，连接PC_2网卡0与PS_2网卡4㊿创建网线，连接PC_3网卡0与PS_1网卡4(51)PC_3本地安装及配置纵向PS_1：安装纵向管理工具： 目录地址：d:/software/PSTunnel2000加密装置千兆管理工具.exe 屏幕分辨率 -&gt; 1024×768添加新操作员： 管理工具 -&gt; 右键 -&gt; 以管理员身份运行 操作员：init 密码：Tun-2000 设备IP：169.254.200.200 -&gt; 操作员 -&gt; 操作员管理 -&gt; 添加：+操作员： user -&gt; 确定导出导入证书： 初始化 -&gt; 生成设备密钥及证书请求 -&gt; 下一步 -&gt; 填写省/市/设备名 -&gt; 下一步 -&gt; 生成.csr证书 证书转换。使用证书工具2.0将.csr证书转换为.cer证书。传入对端。 证书 -&gt; 证书导入 -&gt; 远程设备证书 -&gt; 选择证书 -&gt; 确定VLAN配置： 本地ETH1：192.168.1.50 255.255.255.0 VLAN：0 远程ETH1：192.168.2.50 255.255.255.0 VLAN：0路由配置： 目的地址：192.168.2.50 子网掩码：255.255.255.0 网关地址：192.168.1.1安全隧道: -&gt; 恢复隧道配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改隧道 -&gt; 确定 隧道名标识： 11 -&gt; 不支持修改 本地IP： 192.168.1.50 -&gt; 本地ETH1 远程IP： 192.168.2.50 -&gt; 远程ETH1 255.255.255.0 0.0.0.0 0.0.0.0 MTU： 1500安全策略： -&gt; 恢复策略配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改策略 -&gt; 确定 标识id：0 本地IP： 192.168.1.50 -&gt; 本地ETH1 远程IP： 192.168.2.50 -&gt; 远程ETH1 本地起始IP：192.168.1.1 本地终止IP：192.168.1.254 远程起始IP：192.168.2.1 远程终止IP：192.168.2.254 方向：双向 重置隧道： -&gt; 管理 -&gt; 重置隧道 -&gt; OPENED 注意： *新纵向的用户名,密码：root, Tun-2000 纵向内部查询路由命令：1$ monipead.arm -all (52)PC_2本地安装及配置纵向PS_2：配置与以上相同，反向。 (53)PC_4配置静态路由：1route add -p 192.168.2.0 mask 255.255.255.0 192.168.1.1 (54)PC_1配置静态路由：1route add -p 192.168.1.0 mask 255.255.255.0 192.168.2.1 (55)验证纵向的功能：使用PC_4 ping PC_1 1ping 192.168.2.50 查看PS_2的eth1口是否抓到ESP报文包。]]></content>
      <categories>
        <category>Kedong</category>
      </categories>
      <tags>
        <tag>kedong</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化隔离安装配置说明]]></title>
    <url>%2F2019%2F06%2F21%2FOther%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E9%9A%94%E7%A6%BB%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[虚拟化隔离安装配置说明创建纵向隔离组件[反向隔离] SW。创建主机组件[win7] PC。SW与PC通过串口线连接。 配置管理工具。打开QT界面隔离管理工具。 前提：windows虚拟机已经安装vc_redist.2015.x64 且QT管理工具中包含vcruntime140.dll，libcrypto-1_1.dll。 用户名：admin 密码：111111 串口登录。 串口：COM1。 频率：115200。 √ 反向隔离。 设备配置 -&gt; 基本配置 管理IP： 无 -&gt; 不填 设备名称： dev -&gt; 自定义 ETH0协商IP： 192.168.1.100 -&gt; 与发送端须配置成相同网段 ETH1协商IP： 0.0.0.0 -&gt; 可不做配置 规则配置 -&gt; 主机信息1 -&gt; 添加 √ IP和MAC地址绑定 主机名： sender -&gt; 自定义 MAC1： FA:16:3E:40:11:01 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.10 -&gt; 主机网卡ip地址 主机虚拟IP1：ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 主机信息2 -&gt; 添加 √ IP和MAC地址绑定 主机名： receiver -&gt; 自定义 MAC1： FA:16:3E:40:11:02 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.20 -&gt; 主机网卡ip地址 主机虚拟IP1：ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 连接信息 规则名： rule -&gt; 自定义 (内网)IP地址： 192.100.1.10 (内网)虚拟IP： 192.100.1.10 (内网)网口号： ETH0/网口0 (外网)IP地址： 192.100.1.20 (外网)虚拟IP： 192.100.1.20 (外网)网口号： ETH0/网口0 协议： UDP（反向） TCP正向 证书互导 设备密钥 √ RSA -&gt; 导出设备证书文件 -&gt; dev.cer 发送端证书 -&gt; 添加 发送端IP： 192.168.1.14 -&gt; 此处为发送端IP，不为虚拟IP 证书标识： sender.cer 管理工具配置好隔离之后，正反向隔离需重启生效。主机信息位置：/etc/mac.conf连接信息位置：/etc/rules 传输软件配置 检查config目录下是否有**.p12文件，若存在，则删除。 启动传输软件。 Stonewall-2000-Send.jar 右键 -&gt; 以管理员身份运行 -&gt; 命令行 -&gt; 12java -jar Stonewall-2000-Send.jar设置密码口令保护窗口如果报错，需先运行jreUpdate1.8.jar 出现提示：系统检测到密钥尚未存在，是否需要生成密钥？ -&gt; 是 创建登录口令：123456。 确定，提示操作成功。 登录窗口： 操作员名称： administrator 操作员密码： 12345678 密钥保护口令： 123456 管理 -&gt; 密钥管理 -&gt; 导出密钥。 -&gt; sender.cer 设定 -&gt; 配置加密隧道 隧道名称： Tunnel-1 隧道的协商IP地址： 192.168.1.100 -&gt; 设备ETH0协商IP 隧道的协商端口： 4558 隧道每次通过的文件数： 100 隔离设备证书路径： ../.. dev.cer 设定 -&gt; 配置链路信息 链路名称： Link-1 目的IP地址： 192.168.1.13 -&gt; 接收端IP地址，正反向隔离在相同环境的情况下，配置虚拟IP。 目的端口： 7777 发送失败等待周期(秒)： 30 使用隧道： Tunnel-1]]></content>
      <categories>
        <category>Eletric Power</category>
      </categories>
      <tags>
        <tag>eletric power</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Too many open files 错误与解决办法]]></title>
    <url>%2F2019%2F06%2F20%2FOpenstack%2FTooManyFiles%2F</url>
    <content type="text"><![CDATA[Openstack WebUI页面无法打开，页面报500错误，查看httpd-&gt;error_log日志报如下错误: 1234567891011[Tue Apr 02 14:01:05.658276 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/sessions.py&quot;, line 518, in request[Tue Apr 02 14:01:05.658280 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/sessions.py&quot;, line 639, in send[Tue Apr 02 14:01:05.658284 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/adapters.py&quot;, line 438, in send[Tue Apr 02 14:01:05.658287 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py&quot;, line 588, in urlopen[Tue Apr 02 14:01:05.658291 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py&quot;, line 241, in _get_conn[Tue Apr 02 14:01:05.658296 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/connection.py&quot;, line 27, in is_connection_dropped[Tue Apr 02 14:01:05.658300 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.py&quot;, line 33, in wait_for_read[Tue Apr 02 14:01:05.658304 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.py&quot;, line 22, in _wait_for_io_events[Tue Apr 02 14:01:05.658308 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.py&quot;, line 581, in DefaultSelector[Tue Apr 02 14:01:05.658312 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.py&quot;, line 394, in __init__[Tue Apr 02 14:01:05.658316 2019] [:error] [pid 9245] IOError: [Errno 24] Too many open files 解决方式：修改操作系统打开的文件数；登录到Controller节点，执行: 1234567891011121314151617[root@controller ~]# ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 60587max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 60587virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 系统默认设置为1024。 使用命令查看当前打开文件数: 12[root@controller ~]# lsof | wc -l174911 修改vim /etc/security/limits.conf，在文件最后加入如下信息： 12* soft nofile 1024000* hard nofile 1024000 *表示所有用户，修改后重启服务器，配置生效。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化纵向安装配置说明]]></title>
    <url>%2F2019%2F06%2F20%2FOther%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E7%BA%B5%E5%90%91%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[虚拟化纵向安装配置说明创建纵向组件[电力纵向] PS。创建主机组件[win7] PC。创建UKey组件 UKey。UKey插入PS。 配置PC。 IP地址：169.254.200.201 掩码：255.255.255.0 网关：169.254.200.1 PC网卡0与PS网卡4连接网线。PC本地安装纵向管理工具。 目录地址：d:/software/PSTunnel2000加密装置千兆管理工具.exe 添加新操作员。 右键 -&gt; 以管理员身份运行 -&gt; 操作员 -&gt; 操作员管理 -&gt; 添加：+操作员： user -&gt; 确定 导出导入证书。 -&gt; 初始化 -&gt; 生成设备密钥及证书请求 -&gt; 下一步 -&gt; 填写省/市/设备名 -&gt; 下一步 -&gt; 生成.csr证书 证书转换。使用证书工具2.0将.csr证书转换为.cer证书。传入对端。 -&gt; 证书 -&gt; 证书导入 -&gt; 远程设备证书 -&gt; 选择证书 -&gt; 确定 VLAN配置。 本地ETH1：192.168.1.100 255.255.255.0 VLAN：0 远程ETH1：192.168.1.200 255.255.255.0 VLAN：0 安全隧道。 -&gt; 恢复隧道配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改隧道 -&gt; 确定 隧道名标识： 11 -&gt; 不支持修改 本地IP： 192.168.1.100 -&gt; 本地ETH1 远程IP： 192.168.1.200 -&gt; 远程ETH1 255.255.255.0 0.0.0.0 0.0.0.0 MTU： 1500 安全策略。 -&gt; 恢复策略配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改策略 -&gt; 确定 标识id：0 本地IP： 192.168.1.100 -&gt; 本地ETH1 远程IP： 192.168.1.200 -&gt; 远程ETH1 本地起始IP：192.168.1.1 本地终止IP：192.168.1.254 远程起始IP：192.168.1.1 远程终止IP：192.168.1.254 方向：双向 重置隧道。 -&gt; 管理 -&gt; 重置隧道 -&gt; OPENED 注意： *新纵向的用户名,密码：root, Tun-2000 纵向内部查询路由命令：1$ monipead.arm -all]]></content>
      <categories>
        <category>Eletric Power</category>
      </categories>
      <tags>
        <tag>eletric power</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（七）Horizon服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens7%2F</url>
    <content type="text"><![CDATA[Controller节点：安装及配置：12345678910111213141516171819202122# yum install openstack-dashboard# vi /etc/openstack-dashboard/local_settingsOPENSTACK_HOST = "controller"ALLOWED_HOSTS = ['*']SESSION_ENGINE = 'django.contrib.sessions.backends.cache'CACHES = &#123; 'default': &#123; 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', &#125;&#125;OPENSTACK_KEYSTONE_URL = "http://%s:5000/v3" % OPENSTACK_HOSTOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = TrueOPENSTACK_API_VERSIONS = &#123; "identity": 3, "image": 2, "volume": 2,&#125;OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = "Default"OPENSTACK_KEYSTONE_DEFAULT_ROLE = "user"TIME_ZONE = "Asia/Shanghai" 123# vi /etc/httpd/conf.d/openstack-dashboard.conf 在文件开头添加WSGIApplicationGroup %&#123;GLOBAL&#125;... 完成安装：1# systemctl restart httpd.service memcached.service 使用 http://controller/dashboard 上的Web浏览器访问Dashboard。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（六）Neutron服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens6%2F</url>
    <content type="text"><![CDATA[Controller节点：Neutron服务安装网络类型：vxlanLayer2 二层插件采用：openvswitch 创建neutron数据库，授予权限：123456$ mysql -u root -pMariaDB [(none)] CREATE DATABASE neutron;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 创建neutron用户：1234567891011121314151617$ . admin-openrc$ openstack user create --domain default --password-prompt neutronUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 463fd14bf95b4cc49c0378623de56ffa || name | neutron || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user neutron admin 创建neutron服务实体：12345678910$ openstack service create --name neutron --description "OpenStack Networking" network+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Networking || enabled | True || id | e10e48790ede425ea81e1a62250f124a || name | neutron || type | network |+-------------+----------------------------------+ 创建网络服务API端点：1234567891011121314$ openstack endpoint create --region RegionOne network public http://controller:9696+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | f688ed8f1bf340d78794b600fa512145 || interface | public || region | RegionOne || region_id | RegionOne || service_id | e10e48790ede425ea81e1a62250f124a || service_name | neutron || service_type | network || url | http://controller:9696 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne network internal http://controller:9696+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 571a008230c54cf8bcb1e38a75787c3f || interface | internal || region | RegionOne || region_id | RegionOne || service_id | e10e48790ede425ea81e1a62250f124a || service_name | neutron || service_type | network || url | http://controller:9696 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne network admin http://controller:9696+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | a8d654c1c878423789aab3fa7cf634cb || interface | admin || region | RegionOne || region_id | RegionOne || service_id | e10e48790ede425ea81e1a62250f124a || service_name | neutron || service_type | network || url | http://controller:9696 |+--------------+----------------------------------+ 安装及配置：12345678910111213141516171819202122232425262728293031323334# yum install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch ebtables# vi /etc/neutron/neutron.conf[DEFAULT]auth_strategy = keystonecore_plugin = ml2service_plugins = routerallow_overlapping_ips = Truetransport_url = rabbit://openstack:123456@controllernotify_nova_on_port_status_changes = truenotify_nova_on_port_data_changes = true[database]connection = mysql+pymysql://neutron:123456@controller/neutron[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:35357memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = 123456[nova]auth_url = http://controller:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = novapassword = 123456[oslo_concurrency]lock_path = /var/lib/neutron/tmp 1234567891011121314# vi /etc/neutron/plugins/ml2/ml2_conf.ini[ml2]type_drivers = flat,vlan,vxlantenant_network_types = vxlanmechanism_drivers = openvswitch,l2populationextension_drivers = port_security[ml2_type_flat]flat_networks = provider[ml2_type_vlan]#network_vlan_ranges = provider:1:1000[ml2_type_vxlan]vni_ranges = 1:1000[securitygroup]enable_ipset = true 123# vi /etc/sysctl.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1 1234# vi /etc/neutron/l3_agent.ini[DEFAULT]interface_driver = openvswitchexternal_network_bridge = 12345# vi /etc/neutron/dhcp_agent.ini[DEFAULT]interface_driver = openvswitchdhcp_driver = neutron.agent.linux.dhcp.Dnsmasqenable_isolated_metadata = true 1234# vi /etc/neutron/metadata_agent.ini[DEFAULT]nova_metadata_host = controllermetadata_proxy_shared_secret = 123456 123456789# vi /etc/neutron/plugins/ml2/openvswitch_agent.ini[agent]tunnel_types = vxlanl2_population = True[ovs]bridge_mappings = provider:br-providerlocal_ip = 10.0.0.11[securitygroup]firewall_driver = iptables_hybrid 完成安装：123456789101112131415161718# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini# su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron# systemctl restart openstack-nova-api.service# systemctl start neutron-server.service# systemctl start neutron-openvswitch-agent.service# ovs-vsctl add-br br-provider# ifconfig eth0 0.0.0.0# ifconfig br-provider 192.100.10.160/24# route add default gw 192.100.10.1# systemctl restart neutron-server.service# systemctl restart neutron-openvswitch-agent.service# systemctl enable neutron-server.service neutron-openvswitch-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service# systemctl start neutron-dhcp-agent.service neutron-metadata-agent.service# systemctl enable neutron-l3-agent.service# systemctl start neutron-l3-agent.service Compute节点：安装及配置：123456789101112131415161718# yum install openstack-neutron-openvswitch ebtables ipset# vi /etc/neutron/neutron.conf[DEFAULT]transport_url = rabbit://openstack:123456@controllerauth_strategy = keystone[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:35357memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = 123456[oslo_concurrency]lock_path = /var/lib/neutron/tmp 12345678# vi /etc/neutron/plugins/ml2/openvswitch_agent.ini[ovs]local_ip = 10.0.0.21[agent]tunnel_types = vxlanl2_population = True# systemctl restart neutron-openvswitch-agent.service 123456789101112# vi /etc/nova/nova.conf...[neutron]url = http://controller:9696auth_url = http://controller:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = 123456 完成安装：123# systemctl restart openstack-nova-compute.service# systemctl enable neutron-openvswitch-agent.service# systemctl start neutron-openvswitch-agent.service Controller节点：验证操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ . admin-openrc$ openstack extension list --network+----------------------------------------------------------------------------------------------+---------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Name | Alias | Description |+----------------------------------------------------------------------------------------------+---------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Default Subnetpools | default-subnetpools | Provides ability to mark and use a subnetpool as the default. || Availability Zone | availability_zone | The availability zone extension. || Network Availability Zone | network_availability_zone | Availability zone support for network. || Auto Allocated Topology Services | auto-allocated-topology | Auto Allocated Topology Services. || Neutron L3 Configurable external gateway mode | ext-gw-mode | Extension of the router abstraction for specifying whether SNAT should occur on the external gateway || Port Binding | binding | Expose port bindings of a virtual port to external application || agent | agent | The agent management extension. || Subnet Allocation | subnet_allocation | Enables allocation of subnets from a subnet pool || L3 Agent Scheduler | l3_agent_scheduler | Schedule routers among l3 agents || Tag support | tag | Enables to set tag on resources. || Neutron external network | external-net | Adds external network attribute to network resource. || Tag support for resources with standard attribute: trunk, policy, security_group, floatingip | standard-attr-tag | Enables to set tag on resources with standard attribute. || Neutron Service Flavors | flavors | Flavor specification for Neutron advanced services. || Network MTU | net-mtu | Provides MTU attribute for a network resource. || Network IP Availability | network-ip-availability | Provides IP availability data for each network and subnet. || Quota management support | quotas | Expose functions for quotas management per tenant || If-Match constraints based on revision_number | revision-if-match | Extension indicating that If-Match based on revision_number is supported. || HA Router extension | l3-ha | Adds HA capability to routers. || Provider Network | provider | Expose mapping of virtual networks to physical networks || Multi Provider Network | multi-provider | Expose mapping of virtual networks to multiple physical networks || Quota details management support | quota_details | Expose functions for quotas usage statistics per project || Address scope | address-scope | Address scopes extension. || Neutron Extra Route | extraroute | Extra routes configuration for L3 router || Network MTU (writable) | net-mtu-writable | Provides a writable MTU attribute for a network resource. || Subnet service types | subnet-service-types | Provides ability to set the subnet service_types field || Resource timestamps | standard-attr-timestamp | Adds created_at and updated_at fields to all Neutron resources that have Neutron standard attributes. || Neutron 服务类型管理 | service-type | 用于为 Neutron 高级服务检索服务提供程序的 API || Router Flavor Extension | l3-flavors | Flavor support for routers. || Port Security | port-security | Provides port security || Neutron Extra DHCP options | extra_dhcp_opt | Extra options configuration for DHCP. For example PXE boot options to DHCP clients can be specified (e.g. tftp-server, server-ip-address, bootfile-name) || Resource revision numbers | standard-attr-revisions | This extension will display the revision number of neutron resources. || Pagination support | pagination | Extension that indicates that pagination is enabled. || Sorting support | sorting | Extension that indicates that sorting is enabled. || security-group | security-group | The security groups extension. || DHCP Agent Scheduler | dhcp_agent_scheduler | Schedule networks among dhcp agents || Router Availability Zone | router_availability_zone | Availability zone support for router. || RBAC Policies | rbac-policies | Allows creation and modification of policies that control tenant access to resources. || Tag support for resources: subnet, subnetpool, port, router | tag-ext | Extends tag support to more L2 and L3 resources. || standard-attr-description | standard-attr-description | Extension to add descriptions to standard attributes || IP address substring filtering | ip-substring-filtering | Provides IP address substring filtering when listing ports || Neutron L3 Router | router | Router abstraction for basic L3 forwarding between L2 Neutron networks and access to external networks via a NAT gateway. || Allowed Address Pairs | allowed-address-pairs | Provides allowed address pairs || project_id field enabled | project-id | Extension that indicates that project_id field is enabled. || Distributed Virtual Router | dvr | Enables configuration of Distributed Virtual Routers. |+----------------------------------------------------------------------------------------------+---------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ 12345678910$ openstack network agent list+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+| ID | Agent Type | Host | Availability Zone | Alive | State | Binary |+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+| 0fcf4aa9-3592-4552-9b4c-f2b55e23ef6b | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent || 1a08e5eb-d867-4697-850d-bd2400134162 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent || 9a33be1e-61bd-4d6b-9ee1-bda6dc7b44cd | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent || bfdb443d-feee-4006-8618-558b73c3c4a2 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent || ce5abc8d-504a-4164-ae0f-801e56a06653 | Linux bridge agent | compute | None | :-) | UP | neutron-linuxbridge-agent |+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（五）Nova服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens5%2F</url>
    <content type="text"><![CDATA[Controller节点：创建 nova_api, nova,和 nova_cell0 的数据库，授予权限：1234567891011121314$ mysql -u root -pMariaDB [(none)]&gt;CREATE DATABASE nova_api;MariaDB [(none)]&gt; CREATE DATABASE nova;MariaDB [(none)]&gt; CREATE DATABASE nova_cell0;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 创建nova用户：1234567891011121314151617$ . admin-openrc$ openstack user create --domain default --password-prompt novaUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 81f1d5dfad5a42bb806d197ceb9881ce || name | nova || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user nova admin 创建nova服务实体：12345678910$ openstack service create --name nova --description "OpenStack Compute" compute+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Compute || enabled | True || id | 3e011d345e4442fe8a232ab5ab1f8323 || name | nova || type | compute |+-------------+----------------------------------+ 创建Compute API服务端点：1234567891011121314$ openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 343b6a8fc9564623aca0097b2383650d || interface | public || region | RegionOne || region_id | RegionOne || service_id | 3e011d345e4442fe8a232ab5ab1f8323 || service_name | nova || service_type | compute || url | http://controller:8774/v2.1 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 3458cf55ac8b44d58c949fe88bf9afe3 || interface | internal || region | RegionOne || region_id | RegionOne || service_id | 3e011d345e4442fe8a232ab5ab1f8323 || service_name | nova || service_type | compute || url | http://controller:8774/v2.1 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 9f9115389c2a49a2874761b92c849bb0 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | 3e011d345e4442fe8a232ab5ab1f8323 || service_name | nova || service_type | compute || url | http://controller:8774/v2.1 |+--------------+----------------------------------+ 创建Placement服务相关：123456789101112131415$ openstack user create --domain default --password-prompt placementUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 74870bc86a7c4108869c620099bffc30 || name | placement || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user placement admin 12345678910$ openstack service create --name placement --description "Placement API" placement+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Placement API || enabled | True || id | bbd270a97c3a499fb73765120094e9da || name | placement || type | placement |+-------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne placement public http://controller:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | d79b3b62302a4055924762ac676fc9b4 || interface | public || region | RegionOne || region_id | RegionOne || service_id | bbd270a97c3a499fb73765120094e9da || service_name | placement || service_type | placement || url | http://controller:8778 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne placement internal http://controller:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 5424919fbee34a7a92946c607706b38a || interface | internal || region | RegionOne || region_id | RegionOne || service_id | bbd270a97c3a499fb73765120094e9da || service_name | placement || service_type | placement || url | http://controller:8778 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne placement admin http://controller:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | d9d5626cdb5442ac91dff8c1588f4726 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | bbd270a97c3a499fb73765120094e9da || service_name | placement || service_type | placement || url | http://controller:8778 |+--------------+----------------------------------+ 安装和配置：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# yum install openstack-nova-api openstack-nova-conductor openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler openstack-nova-placement-api# vi /etc/nova/nova.conf[DEFAULT]my_ip=192.100.10.160use_neutron=truefirewall_driver=nova.virt.firewall.NoopFirewallDriverenabled_apis=osapi_compute,metadatatransport_url=rabbit://openstack:123456@controller[api]auth_strategy=keystone[api_database]connection = mysql+pymysql://nova:123456@controller/nova_api[database]connection = mysql+pymysql://nova:123456@controller/nova[glance]api_servers = http://controller:9292[keystone_authtoken]auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = 123456[libvirt]#virt_type=kvm[neutron]url = http://controller:9696auth_url = http://controller:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = 123456service_metadata_proxy = truemetadata_proxy_shared_secret = 123456[oslo_concurrency]lock_path=/var/lib/nova/tmp[placement]os_region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://controller:5000/v3username = placementpassword = 123456[vnc]enabled=trueserver_listen=$my_ipserver_proxyclient_address=$my_ip#novncproxy_base_url=http://127.0.0.1:6080/vnc_auto.html 12345678910# vi /etc/httpd/conf.d/00-nova-placement-api.conf 在最下方加入&lt;Directory /usr/bin&gt; &lt;IfVersion &gt;= 2.4&gt; Require all granted &lt;/IfVersion&gt; &lt;IfVersion &lt; 2.4&gt; Order allow,deny Allow from all &lt;/IfVersion&gt;&lt;/Directory&gt; 完成安装：1234567891011121314# systemctl restart httpd# su -s /bin/sh -c "nova-manage api_db sync" nova# su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova# su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova# su -s /bin/sh -c "nova-manage db sync" nova# nova-manage cell_v2 list_cells+-------+--------------------------------------+------------------------------------+-------------------------------------------------+| 名称 | UUID | Transport URL | 数据库连接 |+-------+--------------------------------------+------------------------------------+-------------------------------------------------+| cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@controller/nova_cell0 || cell1 | c795b2eb-4814-4fe7-b9ff-090a1b1b2be5 | rabbit://openstack:****@controller | mysql+pymysql://nova:****@controller/nova |+-------+--------------------------------------+------------------------------------+-------------------------------------------------+ 12# systemctl enable openstack-nova-api.service openstack-nova-consoleauth.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service# systemctl start openstack-nova-api.service openstack-nova-consoleauth.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service Compute节点：安装和配置：1234567891011121314151617181920212223242526272829303132333435363738# yum install openstack-nova-compute# vi /etc/nova/nova.conf[DEFAULT]my_ip = 192.100.10.161enabled_apis = osapi_compute,metadatause_neutron = Truefirewall_driver = nova.virt.firewall.NoopFirewallDrivertransport_url = rabbit://openstack:123456@controller[api]auth_strategy = keystone[vnc]enabled = Trueserver_listen = 0.0.0.0server_proxyclient_address = $my_ipnovncproxy_base_url = http://controller:6080/vnc_auto.html[glance]api_servers = http://controller:9292[oslo_concurrency]lock_path = /var/lib/nova/tmp[placement]os_region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://controller:5000/v3username = placementpassword = 123456[keystone_authtoken]auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = 123456 完成安装12# systemctl enable libvirtd.service openstack-nova-compute.service# systemctl start libvirtd.service openstack-nova-compute.service Controller节点：将计算节点添加到cell数据库：12345678$ . admin-openrc$ openstack compute service list --service nova-compute+----+--------------+-----------------------+------+---------+-------+----------------------------+| ID | Binary | Host | Zone | Status | State | Updated At |+----+--------------+-----------------------+------+---------+-------+----------------------------+| 9 | nova-compute | localhost.localdomain | nova | enabled | up | 2018-09-13T02:59:06.000000 |+----+--------------+-----------------------+------+---------+-------+----------------------------+ 发现计算主机：123456789101112131415# su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWarning: Configuration option(s) ['use_tpool'] not supported exception.NotSupportedWarningFound 2 cell mappings.Skipping cell0 since it does not contain hosts.Getting computes from cell 'cell1': c795b2eb-4814-4fe7-b9ff-090a1b1b2be5Checking host mapping for compute host 'localhost.localdomain': 58be78ad-5220-4869-ab31-33c9674ecfd1Creating host mapping for compute host 'localhost.localdomain': 58be78ad-5220-4869-ab31-33c9674ecfd1Found 1 unmapped computes in cell: c795b2eb-4814-4fe7-b9ff-090a1b1b2be5注意：添加新计算节点时，必须在控制器节点上运行nova-manage cell_v2 discover_hosts以注册这些新计算节点。或者，您可以在 /etc/nova/nova.conf 中设置适当的间隔：[scheduler]discover_hosts_in_cells_interval = 300 验证：1234567891011$ . admin-openrc$ openstack compute service list+----+------------------+-----------------------+----------+---------+-------+----------------------------+| ID | Binary | Host | Zone | Status | State | Updated At |+----+------------------+-----------------------+----------+---------+-------+----------------------------+| 1 | nova-conductor | controller | internal | enabled | up | 2018-09-13T03:00:28.000000 || 3 | nova-consoleauth | controller | internal | enabled | up | 2018-09-13T03:00:29.000000 || 4 | nova-scheduler | controller | internal | enabled | up | 2018-09-13T03:00:29.000000 || 9 | nova-compute | localhost.localdomain | nova | enabled | up | 2018-09-13T03:00:26.000000 |+----+------------------+-----------------------+----------+---------+-------+----------------------------+ 123456789101112131415161718192021222324252627282930313233$ openstack catalog list+-----------+-----------+-----------------------------------------+| Name | Type | Endpoints |+-----------+-----------+-----------------------------------------+| keystone | identity | RegionOne || | | public: http://controller:5000/v3/ || | | RegionOne || | | internal: http://controller:5000/v3/ || | | RegionOne || | | admin: http://controller:5000/v3/ || | | || nova | compute | RegionOne || | | public: http://controller:8774/v2.1 || | | RegionOne || | | internal: http://controller:8774/v2.1 || | | RegionOne || | | admin: http://controller:8774/v2.1 || | | || glance | image | RegionOne || | | internal: http://controller:9292 || | | RegionOne || | | admin: http://controller:9292 || | | RegionOne || | | public: http://controller:9292 || | | || placement | placement | RegionOne || | | internal: http://controller:8778 || | | RegionOne || | | public: http://controller:8778 || | | RegionOne || | | admin: http://controller:8778 || | | |+-----------+-----------+-----------------------------------------+ 123456$ openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| ad7da2d4-cb83-4a41-836f-e58e47e899f5 | cirros | active |+--------------------------------------+--------+--------+ 123456789101112131415161718192021222324252627# nova-status upgrade check/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWarning: Configuration option(s) ['use_tpool'] not supported exception.NotSupportedWarningOption "os_region_name" from group "placement" is deprecated. Use option "region-name" from group "placement".+-------------------------------+| 升级检查结果 |+-------------------------------+| 检查: Cells v2 || 结果: 成功 || 详情: None |+-------------------------------+| 检查: Placement API || 结果: 成功 || 详情: None |+-------------------------------+| 检查: Resource Providers || 结果: 成功 || 详情: None |+-------------------------------+| 检查: Ironic Flavor Migration || 结果: 成功 || 详情: None |+-------------------------------+| 检查: API Service Version || 结果: 成功 || 详情: None |+-------------------------------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（四）Glance服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens4%2F</url>
    <content type="text"><![CDATA[Controller节点：创建glance数据库，授予权限：12345$ mysql -u root -pMariaDB [(none)]&gt; CREATE DATABASE glance;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 创建glance用户：1234567891011121314151617$ . admin-openrc$ openstack user create --domain default --password-prompt glanceUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 5b7e76213b4b4945b7c702be5b595c0e || name | glance || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user glance admin 创建glance服务实体：12345678910$ openstack service create --name glance --description "OpenStack Image" image+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Image || enabled | True || id | b9cfd97d134e4ec2bf19d78306e85a5a || name | glance || type | image |+-------------+----------------------------------+ 创建API端点：1234567891011121314$ openstack endpoint create --region RegionOne image public http://controller:9292+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b9c90172de704ea4a867190ba44fc931 || interface | public || region | RegionOne || region_id | RegionOne || service_id | b9cfd97d134e4ec2bf19d78306e85a5a || service_name | glance || service_type | image || url | http://controller:9292 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne image internal http://controller:9292+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 074bde7662044e93830f4eca15d9c887 || interface | internal || region | RegionOne || region_id | RegionOne || service_id | b9cfd97d134e4ec2bf19d78306e85a5a || service_name | glance || service_type | image || url | http://controller:9292 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne image admin http://controller:9292+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 17030061f9b84301ac515765706933b2 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | b9cfd97d134e4ec2bf19d78306e85a5a || service_name | glance || service_type | image || url | http://controller:9292 |+--------------+----------------------------------+ 安装和配置：12345678910111213141516171819202122232425262728293031323334353637383940# yum install openstack-glance# vi /etc/glance/glance-api.conf[database]connection = mysql+pymysql://glance:123456@controller/glance[glance_store]stores = file,httpdefault_store = filefilesystem_store_datadir = /var/lib/glance/images/[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = glancepassword = 123456[paste_deploy]flavor = keystone# vi /etc/glance/glance-registry.conf[database]connection = mysql+pymysql://glance:123456@controller/glance[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = glancepassword = 123456[paste_deploy]flavor = keystone# su -s /bin/sh -c "glance-manage db_sync" glance 完成安装12# systemctl enable openstack-glance-api.service openstack-glance-registry.service# systemctl start openstack-glance-api.service openstack-glance-registry.service 验证操作123456789101112131415161718192021222324252627282930$ . admin-openrc$ wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img$ openstack image create "cirros" \ --file cirros-0.3.5-x86_64-disk.img \ --disk-format qcow2 --container-format bare \ --public+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | f8ab98ff5e73ebab884d80c9dc9c7290 || container_format | bare || created_at | 2018-09-13T00:55:04Z || disk_format | qcow2 || file | /v2/images/ad7da2d4-cb83-4a41-836f-e58e47e899f5/file || id | ad7da2d4-cb83-4a41-836f-e58e47e899f5 || min_disk | 0 || min_ram | 0 || name | cirros || owner | 4a5e42dd8cbf410f85a5f145039d69a6 || protected | False || schema | /v2/schemas/image || size | 13267968 || status | active || tags | || updated_at | 2018-09-13T00:55:04Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 123456$ openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| ad7da2d4-cb83-4a41-836f-e58e47e899f5 | cirros | active |+--------------------------------------+--------+--------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（三）Keystone服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens3%2F</url>
    <content type="text"><![CDATA[Controller节点：创建keystone数据库，授予权限：12345678$ mysql -u root -p密码：123456MariaDB [(none)]&gt; CREATE DATABASE keystone;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 安装及配置组件12345678910111213141516# yum install openstack-keystone httpd mod_wsgi# vi /etc/keystone/keystone.conf[database]connection = mysql+pymysql://keystone:123456@controller/keystone[token]provider = fernet# su -s /bin/sh -c "keystone-manage db_sync" keystone# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone# keystone-manage bootstrap --bootstrap-password 123456 \ --bootstrap-admin-url http://controller:5000/v3/ \ --bootstrap-internal-url http://controller:5000/v3/ \ --bootstrap-public-url http://controller:5000/v3/ \ --bootstrap-region-id RegionOne 配置Apache HTTP Server1234# vi /etc/httpd/conf/httpd.confServerName controller# ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ 完成安装：12# systemctl enable httpd.service# systemctl start httpd.service 配置管理帐户1234567$ export OS_USERNAME=admin$ export OS_PASSWORD=123456$ export OS_PROJECT_NAME=admin$ export OS_USER_DOMAIN_NAME=Default$ export OS_PROJECT_DOMAIN_NAME=Default$ export OS_AUTH_URL=http://controller:35357/v3$ export OS_IDENTITY_API_VERSION=3 创建域、项目、用户和角色：12345678910$ openstack domain create --description "An Example Domain" example+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | An Example Domain || enabled | True || id | 2f338489f6c64472a0b2b6db54ecc2df || name | example || tags | [] |+-------------+----------------------------------+ 12345678910111213$ openstack project create --domain default --description "Service Project" service+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Service Project || domain_id | default || enabled | True || id | 84218999229845e2ad7f4e88208b3bee || is_domain | False || name | service || parent_id | default || tags | [] |+-------------+----------------------------------+ 12345678910111213$ openstack project create --domain default --description "Demo Project" demo+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Demo Project || domain_id | default || enabled | True || id | 5c4692ce6659454eb830e7e9633a09f1 || is_domain | False || name | demo || parent_id | default || tags | [] |+-------------+----------------------------------+ 12345678910111213$ openstack user create --domain default --password-prompt demoUser Password:123456Repeat User Password:123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 803e7ad2e94b4af39f9be9e0742b45fd || name | demo || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+ 12345678910$ openstack role create user+-----------+----------------------------------+| Field | Value |+-----------+----------------------------------+| domain_id | None || id | cbe4799bac204eacbf0012a77dc349c4 || name | user |+-----------+----------------------------------+$ openstack role add --project demo --user demo user 验证操作：123456789101112131415161718192021222324252627$ unset OS_AUTH_URL OS_PASSWORD$ openstack --os-auth-url http://controller:35357/v3 \ --os-project-domain-name Default --os-user-domain-name Default \ --os-project-name admin --os-username admin token issuePassword: 123456+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| expires | 2018-09-12T09:43:34+0000 || id | gAAAAABbmNG25wIya-0xFYb3zCW3ljtDTWnr8ZCpB4iAZPMfQnP-62EGiIr6aKEjO847h6jH5nNONRqeLXO2BC_bJ0O-b5Fwj2GZpYGWRSSucAU4Mh6MqLQzetbOsRCv9-ZGO6VQYkmr0cPTEm7kzuzUL2bwTcUCbAVCpuFvCnRUZ7Hu4FE5bAI || project_id | 4a5e42dd8cbf410f85a5f145039d69a6 || user_id | 2ffffa1e6cbe4d239bdacc9760a54dd5 |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+$ openstack --os-auth-url http://controller:5000/v3 \ --os-project-domain-name Default --os-user-domain-name Default \ --os-project-name demo --os-username demo token issuePassword: 123456+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| expires | 2018-09-12T09:45:20+0000 || id | gAAAAABbmNIgtMBObdQXwOlGu-HMLvKNTBZuYvVizTCn3aDJLMvqzQRTyjhfm5RjEkAgIWcYfal9TrjZan2VWL_AZ8cASpkBwoa0TQn_rWlZw1wh8xcDeb5XNES3jMNxhtZA87peDCnMkGJoMaJVhvkR4gsDQiIUmCImzjYv6ZvJjLgGEotBszY || project_id | 5c4692ce6659454eb830e7e9633a09f1 || user_id | 803e7ad2e94b4af39f9be9e0742b45fd |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 创建OpenStack客户端环境脚本：12345678910111213141516171819# vi /root/admin-openrcexport OS_PROJECT_DOMAIN_NAME=Defaultexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=123456export OS_AUTH_URL=http://controller:5000/v3export OS_IDENTITY_API_VERSION=3export OS_IMAGE_API_VERSION=2# vi /root/demo-openrcexport OS_PROJECT_DOMAIN_NAME=Defaultexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_NAME=demoexport OS_USERNAME=demoexport OS_PASSWORD=123456export OS_AUTH_URL=http://controller:5000/v3export OS_IDENTITY_API_VERSION=3export OS_IMAGE_API_VERSION=2 使用脚本验证：1234567891011$ . admin-openrc$ openstack token issue+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| expires | 2018-09-12T09:55:59+0000 || id | gAAAAABbmNSfM00gw3qvJi-U8ytTcBxfuVhgNkETRa-gh3PqLp6Md9cW_5FfbkUL1nyQGW4Bg_XvvdIhSBv7fXRnbfyqGxTxOUloe7BmnWgM9LqLn8Fm2FLQp8qcuFamyW-9_FZA5SPqxbYS1Ozk6fO7TRDWAIWdzy5i0-qqB4Ypt6vQOyW-pqk || project_id | 4a5e42dd8cbf410f85a5f145039d69a6 || user_id | 2ffffa1e6cbe4d239bdacc9760a54dd5 |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（二）环境相关服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens2%2F</url>
    <content type="text"><![CDATA[Controller节点：安装NTP服务1234567891011121314# yum install chrony# vi /etc/chrony.confserver 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst...allow 192.100.10.0/24...# systemctl enable chronyd.service 开机启用NTP# systemctl start chronyd.service 开启NTP服务 验证NTP服务： 1234567# chronyc sources 210 Number of sources = 2 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^- 192.0.2.11 2 7 12 137 -2814us[-3000us] +/- 43ms ^* 192.0.2.12 2 6 177 46 +17us[ -23us] +/- 68ms 安装Openstack相关库1234# yum install centos-release-openstack-queens 安装Openstack库# yum upgrade 更新包# yum install python-openstackclient 安装Openstack客户端# yum install openstack-selinux 安装openstack-selinux用来管理Openstack服务的安全策略 关闭防火墙12# systemctl stop firewalld 关闭防火墙服务# systemctl disable firewalld 永久防火墙开机自启动 关闭SELINUX服务123# setenforce 0 关闭selinux服务# vi /etc/selinux/config 永久关闭selinux服务 SELINUX=disabled 安装数据库服务12345678910111213141516# yum install mariadb mariadb-server python2-PyMySQL# vi /etc/my.cnf.d/openstack.cnf[mysqld]bind-address = 192.100.10.160default-storage-engine = innodbinnodb_file_per_table = onmax_connections = 4096collation-server = utf8_general_cicharacter-set-server = utf8# systemctl enable mariadb.service 开机启用Mysql服务# systemctl start mariadb.service 开启Mysql服务# mysql_secure_installation 设置Mysql密码-&gt;123456 安装消息队列1234567# yum install rabbitmq-server# systemctl enable rabbitmq-server.service# systemctl start rabbitmq-server.service# rabbitmqctl add_user openstack 123456# rabbitmqctl set_permissions openstack ".*" ".*" ".*" 安装Memcached缓存1234567# yum install memcached python-memcached# vi /etc/sysconfig/memcachedOPTIONS="-l 127.0.0.1,::1,controller"# systemctl enable memcached.service# systemctl start memcached.service 安装Etcd1234567891011121314151617# yum install etcd# vi /etc/etcd/etcd.conf#[Member]ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="http://192.100.10.160:2380"ETCD_LISTEN_CLIENT_URLS="http://192.100.10.160:2379"ETCD_NAME="controller"#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS="http://192.100.10.160:2380"ETCD_ADVERTISE_CLIENT_URLS="http://192.100.10.160:2379"ETCD_INITIAL_CLUSTER="controller=http://192.100.10.160:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster-01"ETCD_INITIAL_CLUSTER_STATE="new"# systemctl enable etcd# systemctl start etcd Compute节点：安装NTP服务1234567891011# yum install chrony# vi /etc/chrony.confserver controller iburst...allow 192.100.10.0/24...# systemctl enable chronyd.service 开机启用NTP# systemctl start chronyd.service 开启NTP服务 安装Openstack相关库1234# yum install centos-release-openstack-queens 安装Openstack库# yum upgrade 更新包# yum install python-openstackclient 安装Openstack客户端# yum install openstack-selinux 安装openstack-selinux用来管理Openstack服务的安全策略 关闭防火墙12# systemctl stop firewalld 关闭防火墙服务# systemctl disable firewalld 永久防火墙开机自启动 关闭SELINUX服务123# setenforce 0 关闭selinux服务# vi /etc/selinux/config 永久关闭selinux服务 SELINUX=disabled]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（一）环境准备]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens1%2F</url>
    <content type="text"><![CDATA[环境准备：基于CentOS Linux release 7.6.1810 (Core) 控制节点（Controller）：eth0：192.100.10.160/24eth1：10.0.0.11/24eth2：预留 计算节点（Compute):eth0：192.100.10.161/24eth1：10.0.0.12/24eth2：预留 网卡0接口为管理网络 -&gt; 交换机 + 路由器网卡1接口为Overlay网络 -&gt; 目前直连 / 交换机连接网卡2接口为外部网络 -&gt; 路由器 -（可以先使用eth1作为外部网络下载Openstack安装所需资源，后修改） 通用密码： 123456 Controller节点：配置网卡信息： 12345# vi /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=staticIPADDR=192.100.10.160NETMASK=255.255.255.0GATEWAY=192.100.10.1 1234# vi /etc/sysconfig/network-scripts/ifcfg-eth1BOOTPROTO=staticIPADDR=10.0.0.11NETMASK=255.255.255.0 配置主机信息： 12345# vi /etc/hosts# controller192.100.10.160 controller# compute192.100.10.161 compute 配置主机名：控制节点的主机名为controller，设置如下： 1~# hostnamectl set-hostname controller 对主机名进行验证： 1~# hostname 看到输出为controller即可 配置DNS： 12# vi /etc/resolv.confnameserver 114.114.114.114 Compute节点：配置管理网络： 12345# vi /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=staticIPADDR=192.100.10.161NETMASK=255.255.255.0GATEWAY=192.100.10.1 1234# vi /etc/sysconfig/network-scripts/ifcfg-eth1BOOTPROTO=staticIPADDR=10.0.0.21NETMASK=255.255.255.0 配置主机信息： 12345# vi /etc/hosts# controller192.100.10.160 controller# compute192.100.10.161 compute 配置主机名：计算节点的主机名为compute，设置如下： 1~# hostnamectl set-hostname compute 对主机名进行验证： 1~# hostname 看到输出为compute即可 配置DNS： 12# vi /etc/resolv.confnameserver 114.114.114.114]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KDPA RestAPI]]></title>
    <url>%2F2019%2F03%2F10%2FOther%2FKDPA%20RestAPI%2F</url>
    <content type="text"><![CDATA[KDPA RestAPI定义及说明 1 主机实例 1-1 创建主机实例 1-2 删除主机实例 1-3 配置主机实例 1-4 启动主机实例 1-5 关闭主机实例 1-6 挂起主机实例 1-7 恢复主机实例 1-8 获取主机实例基本信息 1-9 主机实例控制台 1-10 重命名主机实例 1-11 创建浮动IP 1-12 删除浮动IP 1-13 获取浮动IP信息 1-14 批量关闭实例组件 1-15 获取所有组件的状态 2 网线 2-1 创建网线 2-2 删除网线 3 通用 3-1 清除当前用户的实验室环境 3-2 设置实训平台系统配置 3-3 获取系统网卡信息及预留网段信息 3-4 用户实验室环境未保存退出 3-5 获取系统资源 3-6 获取系统资源使用率 3-7 按日期获取系统资源使用率 4 系统 4-1 创建镜像 4-2 删除镜像 5 纵向 5-1 创建纵向 5-2 删除纵向 6 串口线 6-1 创建串口线连接 6-2 删除串口线连接 7 UKEY 7-1 创建UKEY 7-2 删除UKEY 7-3 创建UKEY与纵向实例的连接 7-4 删除UKEY与纵向实例的连接 8 隔离 8-1 创建隔离 8-2 删除隔离 8-3 启动隔离 8-4 关闭隔离 8-5 挂起隔离 8-6 恢复隔离 8-7 隔离控制台 8-8 隔离创建浮动IP 8-9 隔离删除浮动IP 8-10 创建隔离镜像 8-11 删除隔离镜像 6-2 删除串口线连接 9 虚拟交换机 9-1 创建Untag虚拟交换机 9-2 删除Untag虚拟交换机 9-3 创建虚拟交换机 9-4 删除虚拟交换机 9-5 启动虚拟交换机 9-6 关闭虚拟交换机 9-7 设置虚拟交换机端口 9-8 获取被占用vlan 10 虚拟路由器 10-1 创建虚拟路由器 10-2 删除虚拟路由器 10-3 查看虚拟路由器配置 10-4 虚拟路由器上传镜像 10-5 虚拟路由器删除镜像 Notice: 1.以下所有API的方法都为POST 2.传参及返回值都为json格式，通用返回值格式为: {“code”: 状态码, “data”: 数据 }。 状态码为 0 代表操作成功，其他代表操作失败 3.api地址中，controller为计算节点的IP地址（已配置在主机配置文件中。8000为系统默认提供服务的端口号。 4.*参数为必填参数，其余为非必填，非必填参数系统传参默认值。 限制: 1.所有组件: 所有组件在关机状态下不能连接网线，不能删除网线。 实验室环境在未点击保存时会被清理，如有需要，手动点击保存按钮。 2.主机: 处于有网线连接或者关机状态下的主机不能修改配置。 处于挂起状态下的主机只能执行恢复操作，不能执行其他操作。 3.纵向: UKEY与纵向连接后，不能直接删除纵向，必须先拔出UKEY。 纵向与纵向之间通过网卡1连接，处理业务，如果纵向与纵向之间通过其他网卡连接，不予处理。 4.串口线: 串口线目前仅支持主机、隔离。 5.虚拟路由器: 虚拟路由器定义的配置在初始化后不能修改。 虚拟路由器与主机通过网线连接两端的网段必须相同。 6.虚拟交换机: 虚拟交换机与虚拟交换机不能通过网线连接。 虚拟交换机VLAN接口只能连接虚拟组件，虚实接口只能连接实体组件。 不同虚拟交换机中的VLAN ID不能重复。 在接口有连接的情况下，不能修改虚拟交换机端口的类型（VLAN接口/虚实接口）。 7.其他问题: 虚拟路由器与虚拟交换机网线连接后，目前虚拟路由器重启DHCP获取不到IP，导致虚拟路由器不可用。 虚拟路由器与主机组件之间有其他组件的情况下，需要手动为主机配置远端静态路由。 1主机实例1-1创建主机实例Request Method: POST API: 123456789101112- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63 - **name**(str.)*: 主机名称，必填，长度1~63 - **imageName**(str.)*: 镜像名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - template(int.): 模板类型，非必填， - 1代表 1 vcpu, 1G ram, 10G disk - 2代表 2 vcpu, 2G ram, 20G disk### 1-2删除主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/delete Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-3配置主机实例Request Method: POST API: 1234567891011- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63 - **ipAddr**(str.)*: IPv4地址，必填，例如:192.168.1.100 - netmask(str.): 掩码地址，非必填，默认值为”255.255.255.0” - gateway(str.): 网关地址，非必填 - number(int.): 网卡编号，非必填，默认值为1，表示主机目前都为1块网卡### 1-4启动主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/start Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-5关闭主机实例Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63### 1-6挂起主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/suspend Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-7恢复主机实例Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63### 1-8获取主机实例基本信息#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/show Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 Response Body123456789101112131415&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;name&quot;: &quot;HOST_1&quot;, &quot;state&quot;: &quot;Up&quot;, &quot;interface&quot;: [&#123; &quot;macAddr&quot;: &quot;fa:16:3e:62:7b:cb&quot;, // MAC地址 &quot;ipAddr&quot;: &quot;192.168.1.5&quot;, // IP地址 &quot;number&quot;: 0, // 网卡编号 &quot;netmask&quot;: &quot;255.255.255.0&quot;, // 掩码地址 &quot;cidr&quot;: &quot;192.168.1.0/24&quot;, // 网段地址 &quot;gateway&quot;: &quot;192.168.1.1&quot; // 网关地址 &#125;] &#125;&#125; 1-9主机实例控制台Request Method: POST API: 12345- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63#### Response- Body { “code”: 0, “data”: { “console”: { “url”: “http://controller:6080/vnc_auto.html?token=aca31aec-fd05-46e4-9618-0e409c1e8b1e&quot;, “type”: “novnc” } }} 12345### 1-10重命名主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/rename Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 currentName(str.)*: 修改后主机名称，必填，长度1~63 1-11创建浮动IPRequest Method: POST API: 1234567- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63 ### 1-12删除主机浮动IP#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/deleteFIP Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-13获取浮动IP信息Request Method: POST API: 12345- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63#### Response- Body { “code”: 0, “data”: { “ftpHost”: “192.100.10.146”, “ftpPath”: ftp://192.100.10.146/ “username”: “ftpuser”, “passwd”: “ftpuser123”, “windowsPath”: “c:\ftpuser\“, “linuxPath”: “/home/ftpuser/“, }} 12345### 1-14批量关闭实例组件#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/batchStop Params: userId(int.)*: 用户ID，必填 1-15获取所有组件的状态Request Method: POST API: 12345- Params: - **userId**(int.)*: 用户ID，必填#### Response- Body { “code”: 0, “data”: { “lineList”: [], “instanceList”: [{ “state”: “Up”, “uuid”: “n-djsgs10124o”, “ukeyid”: “n-fds52326574vf” }] }} 12345678state: 包括 ”UP”: 开机，”Down”：关机，“Suspend”：挂起。## 2网线### 2-1创建网线#### Request- Method: **POST**- API: ```http://controller:8000/api/netline/create Params: uuid(str.)*: 源组件UUID，唯一标识，必填，长度1~63 dstUuid(str.)*: 网线对端组件UUID，必填，长度1~63 netlineUuid(int.)*: 网线UUID，必填，网线的唯一标识 userId(int.)*: 用户ID，必填 number(int.): 网卡编号，非必填，默认值为1，表示主机的第1块网卡 dstNumber(int.): 网线对端网设备卡编号，非必填，默认值为1 vlan(int.): 连接网线时所占用的vlan标签，非必填，默认值为0 0: 默认值，表示当前连接的网线为常规网线，即虚拟组件与虚拟组件连接 14094: 当vlan为14094之前的正整数时，表示此网线为虚实连线，vlan标签表示外部实体设备实际的vlan标签，此标签每个实体设备间不能相同。 2-2删除网线Request Method: POST API: 12345678910- Params: - **uuid**(str.)*: 网线UUID，唯一标识，必填，长度1~63 - **userId**(int.)*: 用户ID，必填## 3通用### 3-1清除当前用户的实验室环境#### Request- Method: **POST**- API: ```http://controller:8000/api/env/clear Params: userId(int.)*: 用户ID，必填 3-2设置实训平台系统配置Request Method: POST API: 1234567- Params: - **maxVmNumber**(str.)*: 用户最大创建虚拟机数量，默认值为10### 3-3获取系统网卡信息及预留网段信息#### Request- Method: **POST**- API: ```http://controller:8000/api/system/info Params: 无 Response Body12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;networkParameters&quot;: [&#123; &quot;nodeType&quot;: &quot;控制节点&quot;, &quot;nodeName&quot;: &quot;controller&quot;, &quot;interfaceInfo&quot;: [&#123; &quot;ethName&quot;: &quot;enp2s0&quot;, &quot;ipAddr&quot;: &quot;192.100.10.58&quot; &#125;, &#123; &quot;ethName&quot;: &quot;enp3s0&quot;, &quot;ipAddr&quot;: &quot;10.0.0.11&quot; &#125;] &#125;,&#123; &quot;nodeType&quot;: &quot;计算节点&quot;, &quot;nodeName&quot;: &quot;compute1&quot;, &quot;interfaceInfo&quot;: [&#123; &quot;ethName&quot;: &quot;enp0s31f6&quot;, &quot;ipAddr&quot;: &quot;192.100.10.160&quot; &#125;, &#123; &quot;ethName&quot;: &quot;enp0s20f0u8&quot;, &quot;ipAddr&quot;: &quot;10.0.0.31&quot; &#125;] &#125;] , &quot;reserveCidr&quot;: [ &#123; &quot;name&quot;: &quot;浮动IP网段&quot;, &quot;cidr&quot;: [&#123; &quot;start&quot;: &quot;192.100.10.140&quot;, &quot;end&quot;: &quot;192.100.10.141&quot; &#125;, &#123; &quot;start&quot;: &quot;192.100.10.161&quot;, &quot;end&quot;: &quot;192.100.10.169&quot; &#125;, &#123; &quot;start&quot;: &quot;192.100.10.144&quot;, &quot;end&quot;: &quot;192.100.10.149&quot; &#125;] &#125;,&#123; &quot;name&quot;: &quot;Overlay网段&quot;, &quot;cidr&quot;: [&#123; &quot;start&quot;: &quot;10.0.0.11&quot;, &quot;end&quot;: &quot;10.0.0.30&quot; &#125; ] &#125;,&#123; &quot;name&quot;: &quot;内部网段&quot;, &quot;cidr&quot;: [&#123; &quot;start&quot;: &quot;20.0.0.2&quot;, &quot;end&quot;: &quot;20.0.0.254&quot; &#125; ] &#125; ] &#125;&#125; 3-4用户实验室环境未保存退出Request Method: POST API: 12345678910- Params: - **instanceList**(list.)*: 实例组件uuid列表，必填 - **netlineList**(list.)*: 网线组件uuid列表，必填 - **userId**(int.)*: 用户ID，必填 - **clickF5**(str)*: 是否点击F5进行刷新，默认为&quot;False&quot;,非必填 ### 3-5获取系统资源#### Request- Method: **POST**- API: ```http://controller:8000/api/system/resource Params: 无 Response Body1234567891011121314151617&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;nodeNumber&quot;: 2, # 节点数量 &quot;runningNodeNumber&quot;: 2, # 正在运行的节点数量 &quot;instanceNumber&quot;: 2, # 实例数量 &quot;vcpuUsed&quot;: 3, # VCPU使用量 个数 &quot;vcpuTotal&quot;: 24, # VCPU总量 个数 &quot;vcpu&quot;: &quot;3/24&quot;, # VCPU使用情况 个数 &quot;memoryUsed&quot;: 4.0, # 内存使用量 GB &quot;memoryTotal&quot;: 23.8, # 内存总量 GB &quot;memory&quot;: &quot;4.0/23.8&quot;, # 内存使用情况 GB &quot;diskUsed&quot;: 30, # 磁盘使用量 GB &quot;diskTotal&quot;: 2198, # 磁盘总量 GB &quot;disk&quot;: &quot;30/2198&quot; # 磁盘使用情况 GB &#125;&#125; 3-6获取系统资源使用率Request Method: POST API: 12345- Params: - 无 #### Response- Body { “code”: 0, “data”: { “cpu”: [“4.1”, “4.1”, “3.9”, “4.6”], “memory”: [“67.6”, “67.8”, “67.8”, “67.9”], “disk”: [“5.7”, “5.7”, “5.7”, “5.7”], “net_out”: [“0”, “653”, “17702”, “0”], “net_in”: [“0”, “2203”, “18517”, “0”], “time”: [ “2019-06-14 07:38:01”, “2019-06-14 07:38:10”, “2019-06-14 07:38:20”, “2019-06-14 07:38:30”] }} 12345### 3-7按日期获取系统资源使用率#### Request- Method: **POST**- API: ```http://controller:8000/api/system/dateUsage Params: date(str.)*: 日期，例：”2019-06-17” Response Body1234567891011121314151617&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;memory&quot;: [&quot;71.8&quot;, &quot;74.5&quot;, &quot;74.5&quot;, &quot;74.5&quot;, &quot;74.1&quot;], &quot;net_out&quot;: [&quot;0&quot;, &quot;772940&quot;, &quot;130350&quot;, &quot;167966&quot;, &quot;172898&quot;], &quot;net_in&quot;: [&quot;0&quot;, &quot;14704&quot;, &quot;3530&quot;, &quot;4194&quot;, &quot;4442&quot;], &quot;time&quot;: [ &quot;2019-06-17 02:00:02&quot;, &quot;2019-06-17 03:00:02&quot;, &quot;2019-06-17 04:00:02&quot;, &quot;2019-06-17 05:00:02&quot;, &quot;2019-06-17 06:00:02&quot; ], &quot;disk&quot;: [&quot;5.7&quot;, &quot;5.7&quot;, &quot;5.7&quot;, &quot;5.7&quot;, &quot;5.7&quot;], &quot;cpu&quot;: [&quot;4.6&quot;, &quot;13.2&quot;, &quot;13.8&quot;, &quot;13.6&quot;, &quot;13.5&quot;] &#125;&#125; 4系统4-1创建镜像Request Method: POST API: 1234567891011121314- Params: - **name**(str.)*: 镜像名称，必填 - **url**(str.)*: 镜像路径，必填 - defaultVCPU(int.): 默认虚拟CPU个数，非必填，默认值1 - defaultRAM(int.): 默认内存大小，非必填，单位MB，默认值1024 - defaultDISK (int.): 默认磁盘大小，非必填，单位GB，默认值10 - advancedVCPU(int.): 高级虚拟CPU个数，非必填，默认值2 - advancedRAM (int.): 高级内存大小，非必填，默认值2048 - advancedDISK (int.): 高级磁盘大小，非必填，单位GB，默认值20 ### 4-2删除镜像#### Request- Method: **POST**- API: ```http://controller:8000/api/image/delete Params: name(str.)*: 镜像名称，必填 5纵向5-1创建纵向Request Method: POST API: 123456789101112- Params: - **uuid**(str.)*: 纵向UUID，唯一标识，必填，长度1~63 - **name**(str.)*: 纵向名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - template(int.): 模板类型，非必填， - 1代表 1 vcpu, 1G ram, 10G disk - 2代表 2 vcpu, 2G ram, 20G disk### 5-2删除纵向#### Request- Method: **POST**- API: ```http://controller:8000/api/pstunnel/delete Params: uuid(str.)*: 纵向UUID，唯一标识，必填，长度1~63 6串口线6-1创建串口线连接Request Method: POST API: 123456789101112- Params: - **uuid**(str.)*: 实例组件UUID，唯一标识，必填，长度1~63 - **dstUuid**(str.)*: 目的实例组件UUID，唯一标识，必填，长度1~63 - **seriallineUuid**(str.)*: 串口线UUID，唯一标识，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - number(int.): 默认值为0。对于主机，数值无意义。对于隔离，0==内隔离串口，1==外隔离串口 - dstNumber(int.): 默认值为0。对于主机，数值无意义。对于隔离，0==内隔离串口，1==外隔离串口### 6-2删除串口线连接#### Request- Method: **POST**- API: ```http://controller:8000/api/serline/delete Params: uuid(str.)*: 串口线UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 7UKEY7-1创建UKEYRequest Method: POST API: 123456789- Params: - **uuid**(str.)*: UKEY UUID，唯一标识，必填，长度1~63 - **name**(str.)*: UKEY 名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填### 7-2删除UKEY#### Request- Method: **POST**- API: ```http://controller:8000/api/ukey/delete Params: uuid(str.)*: UKEY UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 7-3创建UKEY与纵向实例的连接Request Method: POST API: 123456789- Params: - **uuid**(str.)*: UKEY UUID，唯一标识，必填，长度1~63 - **psUuid**(str.)*: 纵向UUID，唯一标识，必填，长度1~63 - **userId**(int.)*: 用户ID，必填### 7-4删除UKEY与纵向实例的连接#### Request- Method: **POST**- API: ```http://controller:8000/api/ukey/disconnect Params: uuid(str.)*: UKEY UUID，唯一标识，必填，长度1~63 psUuid(str.)*: 纵向UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 8隔离8-1创建隔离Request Method: POST API: 12345678910111213- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63 - **name**(str.)*: 隔离名称，必填，长度1~63 - **imageName**(str.)*: 隔离镜像名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - template(int.): 模板类型，非必填， - 1代表 1 vcpu, 1G ram, 10G disk - 2代表 2 vcpu, 2G ram, 20G disk### 8-2删除隔离#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/delete Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 8-3启动隔离Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63### 8-4关闭隔离#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/stop Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 8-5挂起隔离Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63### 8-6恢复隔离#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/resume Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 8-7隔离控制台Request Method: POST API: 123456- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63 - number(int.): 标识内网/外网隔离，值范围：0/1，0代表内，1代表外，默认值为0#### Response- Body { “code”: 0, “data”: { “console”: { “url”: “http://controller:6080/vnc_auto.html?token=aca31aec-fd05-46e4-9618-0e409c1e8b1e&quot;, “type”: “novnc” } }} 12345### 8-8隔离创建浮动IP#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/createFIP Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 number(int.): 标识内网/外网隔离，值范围：0/1，0代表内，1代表外，默认值为0 8-9隔离删除浮动IPRequest Method: POST API: 12345678- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63 - number(int.): 标识内网/外网隔离，值范围：0/1，0代表内，1代表外，默认值为0### 8-10创建隔离镜像#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/createImg Params: name(str.)*: 镜像名称，必填 urlInt(str.)*: 内镜像路径，必填 urlExt(str.)*: 外镜像路径，必填 defaultVCPU(int.): 默认虚拟CPU个数，非必填，默认值1 defaultRAM(int.): 默认内存大小，非必填，单位MB，默认值1024 defaultDISK (int.): 默认磁盘大小，非必填，单位GB，默认值10 advancedVCPU(int.): 高级虚拟CPU个数，非必填，默认值2 advancedRAM (int.): 高级内存大小，非必填，默认值2048 advancedDISK (int.): 高级磁盘大小，非必填，单位GB，默认值20 8-11删除隔离镜像Request Method: POST API: 123456789101112131415- Params: - **name**(str.)*: 镜像名称，必填## 9虚拟交换机### 9-1创建Untag虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/createUntagSwitch`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗 - **name&lt;str, 必填&gt;**: 虚拟交换机名称 - **userId&lt;str, 必填&gt;**: 用户ID - *number&lt;str, 非必填&gt;*: 虚拟交换机网口数量，默认值8#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-2删除Untag虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/deleteUntagSwitch`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 12345678910### 9-3创建虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/create`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗 - **name&lt;str, 必填&gt;**: 虚拟交换机名称 - **userId&lt;str, 必填&gt;**: 用户ID - *number&lt;str, 非必填&gt;*: 虚拟交换机网口数量，默认值8#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-4删除虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/delete`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-5启动虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/start`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-6关闭虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/stop`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 123456789101112### 9-7设置虚拟交换机端口#### Request- Method: **POST**- API: `http://controller:8000/api/switch/configSwitchPort`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗 - **number&lt;str, 必填&gt;**: 虚拟交换机端口序号，从0开始，最大值由交换机端口数量决定，必填 - **vlan&lt;str, 必填&gt;**: 端口将要设置的具体vlan标签 - *-1*：表示端口要设置成为【虚实口】 - *0*： 表示端口默认状态，此状态下端口不可用，即不能连接网线 - *1~4094*：表示端口设置为【vlan口】，vlan标签为1至4094之间的任意正整数#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-8获取被占用vlan#### Request- Method: **POST**- API: `http://controller:8000/api/switch/getUsedVlanList`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码; “data”: [1, 23, 129, …]} 1234567## 10虚拟路由器### 10-1创建虚拟路由器#### Request- Method: **POST**- API: ```http://controller:8000/api/router/create Params: uuid(str.)*: 虚拟路由器UUID，唯一标识，必填，长度1~63 name(str.)*: 虚拟路由器名称，必填，长度1~63 number(int.)*: 虚拟路由器接口数量，默认值为2，必填 cidrList(list.)*: 虚拟路由器网段列表，必填 例如：[“192.168.1.0/24”, “192.168.2.0/24”] 网段的格式：网段地址/掩码位数， 网段不能重复。 imageName(str.)*: 镜像名称，必填，长度1~63 userId(int.)*: 用户ID，必填 10-2删除虚拟路由器Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 虚拟路由器UUID，唯一标识，必填，长度1~63### 10-3查看虚拟路由器配置 #### Request- Method: **POST**- API: ```http://controller:8000/api/router/show Params: uuid(str.)*: 虚拟路由器UUID，唯一标识，必填，长度1~63 Response Body123456789101112131415&#123; &quot;code&quot;: 0, &quot;data&quot;: [ &#123; &quot;number&quot;: 0, &quot;cidr&quot;: &quot;192.168.1.0/24&quot;, &quot;gateway&quot;: &quot;192.168.1.1&quot; &#125;, &#123; &quot;number&quot;: 1, &quot;cidr&quot;: &quot;192.168.2.0/24&quot;, &quot;gateway&quot;: &quot;192.168.2.1&quot; &#125; ]&#125; 10-4虚拟路由器上传镜像Request Method: POST API: 12345678910- Params: - **name**(str.)*: 镜像名称，必填 - **url**(str.)*: 镜像路径，必填 虚拟路由器镜像默认1VCPU，1G内存，10G磁盘### 10-5虚拟路由器删除镜像 #### Request- Method: **POST**- API: ```http://controller:8000/api/router/deleteImg Params: name(str.)*: 镜像名称，必填]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
=======
<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Openstack 虚拟机修改ERROR状态为ACTIVE]]></title>
    <url>%2F2021%2F07%2F05%2FOpenstack%2FOpenstackStateError%2F</url>
    <content type="text"><![CDATA[1.SSH登录Controller节点，执行授权脚本1. /opt/kdpastack/admin-openrc 2.浏览器登录Openstack的WebUI：http://controller:10080/dashboard 进入项目 -&gt; 计算 -&gt; 实例， 筛选条件选择：状态=， 筛选框中输入ERROR，筛选状态为错误的实例列表， 点击 实例名称 如：ps_T16Z2PS-SCENE32@-1，进入实例概况页面， 复制【ID】后面32位字符串。 3.Controller节点，执行重置状态操作：1nova reset-state 2步复制的ID --active 4.Controller节点，执行将实例关机：1nova stop 2步复制的ID 5.以上步骤结束后，登录实训平台，场景管理对应的场景页面， 在场景中对此错误状态的实例进行开机操作， *如果实例当前状态为开机，需先关机再开机。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FreeBSD更新pkg]]></title>
    <url>%2F2021%2F06%2F16%2FOther%2Ffreebsd_pkg%2F</url>
    <content type="text"><![CDATA[1.PKG二进制仓储源文件存储目录 的使用方法系统中常用的PKG二进制仓储源文件存储目录有两个，一个是系统级仓储文件目录，另一个是用户级仓储文件目录，系统级仓储文件目录为 /etc/pkg/， 而用户级别仓储文件目录为 /usr/local/etc/pkg/repos/，这个目录在默认情况下并不存在于系统中，需要用户手工建立，而这两个路径均由 /usr/local/etc/pkg.conf 中 REPOS_DIR 变量控制，原则上可以由用户自由定制。 2. 建立通用户级PKG二进制仓储源文件存储目录1# mkdir -p /usr/local/etc/pkg/repos 3. 建立常用的用户级PKG二进制仓储源文件1# cd /usr/local/etc/pkg/repos 建立仓储源文件的格式要求为：必须使用 .conf 为后缀名结尾的文件。最好使用 “0.” 或者 “1-“ 等数字为前缀的文件名，因为同时启用多个 PKG 源文件时，PKG源文件名的第一个数字前缀直接影响着源的使用优先级，其文件格式的建立如下： 定制第一个仓储文件为 0.bme.conf 1234567bme: &#123; url: "pkg+http://pkg0.bme.freebsd.org/$&#123;ABI&#125;/quarterly", mirror_type: "srv", signature_type: "none", fingerprints: "/usr/share/keys/pkg", enabled: yes&#125; 定制第二个仓储文件为 1.nyi.conf 1234567nyi: &#123; url: "pkg+http://pkg0.nyi.freebsd.org/$&#123;ABI&#125;/quarterly", mirror_type: "srv", signature_type: "none", fingerprints: "/usr/share/keys/pkg", enabled: yes&#125; 定制第三个仓储文件为 2.ydx.conf 1234567ydx: &#123; url: "pkg+http://pkg0.ydx.freebsd.org/$&#123;ABI&#125;/quarterly", mirror_type: "srv", signature_type: "none", fingerprints: "/usr/share/keys/pkg", enabled: yes&#125; 定制第四个仓储文件为 3.isc.conf 1234567isc: &#123; url: "pkg+http://pkg0.isc.freebsd.org/$&#123;ABI&#125;/quarterly", mirror_type: "srv", signature_type: "none", fingerprints: "/usr/share/keys/pkg", enabled: yes&#125; 定制第五个仓储文件为 4.chinafreebsd.conf 1234567chinafreebsd: &#123; url: "pkg+http://pkg.reebsd.cn/$&#123;ABI&#125;/quarterly", mirror_type: "srv", signature_type: "none", fingerprints: "/usr/share/keys/pkg", enabled: yes&#125; 重要:建议只选用一个最快的PKG源，而不是同时启用多个，如果同时启用了多个 PKG 源，那么在安装软件包或升级 PKG 源时候请使用 -r 选项指定要操作的 PKG 源。比如：pkg update -r chinafreebsd 或者 pkg install -r chinafreebsd -y xxxx 。 4. 禁用默认 PKG 仓储源可以直接禁用系统级源文件，换源的主要目的是增加 pkg install 命令下载速度，或者是不能忍受默认源的龟速，用户可以直接禁用系统默认的官方源。比如： 1# echo "FreeBSD: &#123; enabled: no &#125;" &gt; /usr/local/etc/pkg/repos/FreeBSD.conf 注意:此步骤不是必须，如果保留系统仓储源文件，则系统默认源将和用户源一同有效 5. 更新源所有源在使用前最好进行一次强制更新。比如： 123456789# pkg update -f Updating nyi repository catalogue...Fetching meta.txz: 100% 944 B 0.9kB/s 00:01Fetching packagesite.txz: 100% 6 MiB 268.1kB/s 00:22Processing entries: 100%nyi repository update completed. 25828 packages processed.Updating ydx repository catalogue...Fetching meta.txz: 100% 944 B 0.9kB/s 00:01Fetching packagesite.txz: 100% 1 KiB 0.0kB/s 01:00...... 或者更新某个想要使用的源。比如： 12345# pkg update -r bme Updating bme repository catalogue...Fetching meta.txz: 100% 944 B 0.9kB/s 00:01Fetching packagesite.txz: 100% 6 MiB 268.1kB/s 00:22Processing entries: 100%bme repository update completed. 25828 packages processed. 6. 验证当前生效源使用 pkg -vv 命令可以打印当前 PKG 的配置信息，以及所有生效源配置，例如： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135# pkg -vv Version : 1.8.8PKG_DBDIR = "/var/db/pkg";PKG_CACHEDIR = "/var/cache/pkg";PORTSDIR = "/usr/ports";INDEXDIR = "";INDEXFILE = "INDEX-11";HANDLE_RC_SCRIPTS = false;DEFAULT_ALWAYS_YES = false;ASSUME_ALWAYS_YES = false;REPOS_DIR [ "/etc/pkg/", "/usr/local/etc/pkg/repos/",]PLIST_KEYWORDS_DIR = "";SYSLOG = true;ABI = "FreeBSD:11:amd64";ALTABI = "freebsd:11:x86:64";DEVELOPER_MODE = false;VULNXML_SITE = "http://vuxml.freebsd.org/freebsd/vuln.xml.bz2";FETCH_RETRY = 3;PKG_PLUGINS_DIR = "/usr/local/lib/pkg/";PKG_ENABLE_PLUGINS = true;PLUGINS []DEBUG_SCRIPTS = false;PLUGINS_CONF_DIR = "/usr/local/etc/pkg/";PERMISSIVE = false;REPO_AUTOUPDATE = true;NAMESERVER = "";HTTP_USER_AGENT = "pkg/1.8.8";EVENT_PIPE = "";FETCH_TIMEOUT = 30;UNSET_TIMESTAMP = false;SSH_RESTRICT_DIR = "";PKG_ENV &#123;&#125;PKG_SSH_ARGS = "";DEBUG_LEVEL = 0;ALIAS &#123; all-depends = "query %dn-%dv"; annotations = "info -A"; build-depends = "info -qd"; cinfo = "info -Cx"; comment = "query -i \"%c\""; csearch = "search -Cx"; desc = "query -i \"%e\""; download = "fetch"; iinfo = "info -ix"; isearch = "search -ix"; prime-list = "query -e '%a = 0' '%n'"; leaf = "query -e '%#r == 0' '%n-%v'"; list = "info -ql"; noauto = "query -e '%a == 0' '%n-%v'"; options = "query -i \"%n - %Ok: %Ov\""; origin = "info -qo"; provided-depends = "info -qb"; raw = "info -R"; required-depends = "info -qr"; roptions = "rquery -i \"%n - %Ok: %Ov\""; shared-depends = "info -qB"; show = "info -f -k"; size = "info -sq";&#125;CUDF_SOLVER = "";SAT_SOLVER = "";RUN_SCRIPTS = true;CASE_SENSITIVE_MATCH = false;LOCK_WAIT = 1;LOCK_RETRIES = 5;SQLITE_PROFILE = false;WORKERS_COUNT = 0;READ_LOCK = false;PLIST_ACCEPT_DIRECTORIES = false;IP_VERSION = 0;AUTOMERGE = true;VERSION_SOURCE = "";CONSERVATIVE_UPGRADE = true;PKG_CREATE_VERBOSE = false;AUTOCLEAN = false;DOT_FILE = "";REPOSITORIES &#123;&#125;VALID_URL_SCHEME [ "pkg+http", "pkg+https", "https", "http", "file", "ssh", "ftp", "ftps", "pkg+ssh", "pkg+ftp", "pkg+ftps",]ALLOW_BASE_SHLIBS = false;WARN_SIZE_LIMIT = 1048576;Repositories: bme: &#123; url : "pkg+http://pkg0.bme.freebsd.org/FreeBSD:11:amd64/quarterly", enabled : yes, priority : 0, mirror_type : "SRV", fingerprints : "/usr/share/keys/pkg" &#125; nyi: &#123; url : "pkg+http://pkg0.nyi.freebsd.org/FreeBSD:11:amd64/quarterly", enabled : yes, priority : 0, mirror_type : "SRV", fingerprints : "/usr/share/keys/pkg" &#125; ydx: &#123; url : "pkg+http://pkg0.ydx.freebsd.org/FreeBSD:11:amd64/quarterly", enabled : yes, priority : 0, mirror_type : "SRV", fingerprints : "/usr/share/keys/pkg" &#125; isc: &#123; url : "pkg+http://pkg0.isc.freebsd.org/FreeBSD:11:amd64/quarterly", enabled : yes, priority : 0, mirror_type : "SRV", fingerprints : "/usr/share/keys/pkg" &#125; chinafreebsd: &#123; url : "pkg+http://pkg.freebsd.cn/FreeBSD:11:amd64/quarterly", enabled : yes, priority : 0, mirror_type : "SRV", fingerprints : "/usr/share/keys/pkg" &#125; 7. 用 -r 选项使用任意指定源安装软件安装二进制安装包时可以使用 -r 选项选定要使用的源，源名称为源文件中第一行中冒号之前的名称 比如 bme 1# pkg install -y -r bme vim-lite]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>FreeBSD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[libguestfs 简介]]></title>
    <url>%2F2021%2F02%2F23%2FOther%2Flibguestfs%2F</url>
    <content type="text"><![CDATA[简介使用 libguestfs 实现宿主机与虚拟机的文件传输。 ibguestfs 是一组 Linux 下的 C 语言的 API ，用来访问虚拟机的磁盘映像文件。 其项目主页是http://libguestfs.org/ ，该工具包内包含的工具有virt-cat、virt-df、virt-ls、virt-copy-in、virt-copy-out、virt- edit、guestfs、guestmount、virt-list-filesystems、virt-list-partitions等工具，具体 用法也可以参看官网。该工具可以在不启动KVM guest主机的情况下，直接查看guest主机内的文内容，也可以直接向img镜像中写入文件和复制文件到外面的物理机，当然其也可以像mount一 样，支持挂载操作。 安装计算节点安装libguestfs 123[root@compute ~]# yum -y install libguestfs-tools# 对于windows虚拟机的支持[root@compute ~]# yum -y install libguestfs-winsupport 命令列表libguestfs命令12345678root@compute144:~ # virt-virt-alignment-scan virt-customize virt-host-validate virt-pki-validate virt-tar-outvirt-builder virt-df virt-index-validate virt-rescue virt-whatvirt-builder-repository virt-diff virt-inspector virt-resize virt-win-regvirt-cat virt-edit virt-install virt-sparsify virt-xmlvirt-clone virt-filesystems virt-log virt-sysprep virt-xml-validatevirt-copy-in virt-format virt-ls virt-tailvirt-copy-out virt-get-kernel virt-make-fs virt-tar-in virt-ls： 可以列出虚拟机中目录下的文件或目录1234root@compute144:~ # virt-ls -d instance-00001445 /home/agent_linuxftpuserkedong virt-cat： 可以查看虚拟机中文件的内容12345678910111213root@compute144:~ # virt-cat -d instance-00001445 /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologin virt-df： 将在虚拟机中执行df命令的结果输出12345root@compute144:~ # virt-df -d instance-00001445Filesystem 1K-blocks Used Available Use%instance-00001445:/dev/sdb 490 490 0 100%instance-00001445:/dev/sda1 1038336 100948 937388 10%instance-00001445:/dev/centos/root 2238464 1897392 341072 85% virt-copy-in：将文件复制到虚拟机里面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657virt-copy-in - Copy files and directories into a virtual machine disk image.SYNOPSIS virt-copy-in -a disk.img file|dir [file|dir ...] /destination virt-copy-in -d domain file|dir [file|dir ...] /destinationWARNINGUsing virt-copy-in on live virtual machines, or concurrently with other disk editing tools, can be dangerous, potentially causing disk corruption. The virtual machine must be shut down before you use this command, and disk images must not be edited concurrently.DESCRIPTIONvirt-copy-in copies files and directories from the local disk into a virtual machine disk image or named libvirt domain.You can give one or more filenames and directories on the command line. Directories are copied in recursively. The final parameter must be the destination directory in the disk image which must be an absolute path starting with a / character.EXAMPLESUpdate /etc/resolv.conf in a guest: virt-copy-in -d MyGuest resolv.conf /etcUpload a home directory to a guest: virt-copy-in -d MyGuest skel /homeJUST A SHELL SCRIPT WRAPPER AROUND GUESTFISHThis command is just a simple shell script wrapper around the guestfish(1) copy-in command. For anything more complex than a trivial copy, you are probably better off using guestfish directly.OPTIONSSince the shell script just passes options straight to guestfish, read guestfish(1) to see the full list of options.SEE ALSOguestfish(1), virt-cat(1), virt-copy-out(1), virt-edit(1), virt-tar-in(1), virt-tar-out(1), http://libguestfs.org/.AUTHORSRichard W.M. Jones (rjones at redhat dot com)COPYRIGHTCopyright (C) 2011-2012 Red Hat Inc.LICENSEThis program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.BUGSTo get a list of bugs against libguestfs, use this link: https://bugzilla.redhat.com/buglist.cgi?component=libguestfs&amp;product=Virtualization+ToolsTo report a new bug against libguestfs, use this link: https://bugzilla.redhat.com/enter_bug.cgi?component=libguestfs&amp;product=Virtualization+ToolsWhen reporting a bug, please supply:The version of libguestfs.Where you got libguestfs (eg. which Linux distro, compiled from source, etc)Describe the bug accurately and give a way to reproduce it.Run libguestfs-test-tool(1) and paste the complete, unedited output into the bug report. virt-copy-out： 可以把虚拟机里的文件复制出来到本地主机12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152virt-copy-out - Copy files and directories out of a virtual machine disk image.SYNOPSIS virt-copy-out -a disk.img /file|dir [/file|dir ...] localdir virt-copy-out -d domain /file|dir [/file|dir ...] localdirDESCRIPTIONvirt-copy-out copies files and directories out of a virtual machine disk image or named libvirt domain.You can give one or more filenames and directories on the command line. Directories are copied out recursively.EXAMPLESDownload the home directories from a virtual machine: mkdir homes virt-copy-out -d MyGuest /home homesJUST A SHELL SCRIPT WRAPPER AROUND GUESTFISHThis command is just a simple shell script wrapper around the guestfish(1) copy-out command. For anything more complex than a trivial copy, you are probably better off using guestfish directly.OPTIONSSince the shell script just passes options straight to guestfish, read guestfish(1) to see the full list of options.SEE ALSOguestfish(1), virt-cat(1), virt-copy-in(1), virt-edit(1), virt-tar-in(1), virt-tar-out(1), http://libguestfs.org/.AUTHORSRichard W.M. Jones (rjones at redhat dot com)COPYRIGHTCopyright (C) 2011-2012 Red Hat Inc.LICENSEThis program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.BUGSTo get a list of bugs against libguestfs, use this link: https://bugzilla.redhat.com/buglist.cgi?component=libguestfs&amp;product=Virtualization+ToolsTo report a new bug against libguestfs, use this link: https://bugzilla.redhat.com/enter_bug.cgi?component=libguestfs&amp;product=Virtualization+ToolsWhen reporting a bug, please supply:The version of libguestfs.Where you got libguestfs (eg. which Linux distro, compiled from source, etc)Describe the bug accurately and give a way to reproduce it.Run libguestfs-test-tool(1) and paste the complete, unedited output into the bug report. 系统组件适配1234567891011121314系统组件适配 virt-copy-in virt-copy-out 备注---------- ------------ ------------- ----------------------------------------Win7 √ √ 目前查到只支持传输到根目录 / 下 ，也就是C盘---------- ------------ ------------- ----------------------------------------Centos7 √ √---------- ------------ ------------- ----------------------------------------Ubuntu16 √ √---------- ------------ ------------- ----------------------------------------凝思8 √ √---------- ------------ ------------- ----------------------------------------pfSense × × 暂时不支持FreeBSD系统---------- ------------ ------------- ----------------------------------------Kali √ √---------- ------------ ------------- ----------------------------------------]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>libguestfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zerorpc优化]]></title>
    <url>%2F2021%2F02%2F18%2FOther%2Fzerorpc%2F</url>
    <content type="text"><![CDATA[zerorpc官网：https://www.zerorpc.io/Introduction： An easy to use, intuitive, and cross-language RPCzerorpc is a light-weight, reliable and language-agnostic library for distributed communication between server-side processes. It builds on top of ZeroMQ and MessagePack. Support for streamed responses - similar to python generators - makes zerorpc more than a typical RPC engine. Built-in heartbeats and timeouts detect and recover from failed requests. Introspective capabilities, first-class exceptions and the command-line utility make debugging easy. 简介： 一个易于使用、直观和跨语言的RPC zerorpc是一个轻量级、可靠和语言无关的库，用于服务器端进程之间的分布式通信。它构建在ZeroMQ和MessagePack之上。支持流响应——类似于python生成器——使得zerorpc不仅仅是一个典型的RPC引擎。内置的心跳和超时检测并从失败的请求中恢复。内省功能、一级异常和命令行实用程序使调试变得容易。 官网示例： 12345678910# 官网-Serverimport zerorpcclass HelloRPC(object): def hello(self, name): return "Hello, %s" % names = zerorpc.Server(HelloRPC())s.bind("tcp://0.0.0.0:4242")s.run() 123456# 官网-Clientimport zerorpcc = zerorpc.Client()c.connect("tcp://127.0.0.1:4242")print c.hello("RPC") 优化1：使用gevent方式启动zerorpc服务端，提高并发连接数量。12345678# 优化1-Serverimport zerorpcs = zerorpc.Server(HelloRPC())s.bind("tcp://0.0.0.0:4242")zerorpc.gevent.spawn(s.run)while True: zerorpc.gevent.sleep(10) 优化2：报错：报错zerorpc.exceptions.LostRemote: Lost remote after 10s heartbeat，这是因为zerorpc有一个心跳检测，如果客户端没及时得到服务端反馈就报错。解决办法为：在客户端引用zerorpc.Client时加一个参数heartbeat=None， 即c = zerorpc.Client(heartbeat=None) 但是有时还是报错zerorpc.exceptions.LostRemote: Lost remote after 30s heartbeat， 这是相应延长大于30s，没有找到很好的彻底解决响应时间的办法，但是可以“治标”： 对应报错的地方会有提示报错文件：Python27\lib\site-packages\zerorpc\channel.py”或者Python27\lib\site-packages\zerorpc\core.py”，哪个文件报错就改哪个，将文件里面对timeout赋值的语句timeout=30改成timeout=300或者更长，视你需要的响应时间而定，亦可以更长，timeout=30的需要改，然后就可以了，如果不行别忘了前面加上heartbeat=None参数。 123456# 优化2-Clientimport zerorpcc = zerorpc.Client(heartbeat=None)c.connect("tcp://127.0.0.1:4242")print c.hello("RPC") zerorpc服务器端不并发处理，客户端连接阻塞。123456789101112# 举例1-Serverimport zerorpcimport timeclass HelloRPC(object): def hello(self, name): time.sleep(10) # -&gt; zerorpc.gevent.sleep(10) return "Hello, %s" % names = zerorpc.Server(HelloRPC())s.bind("tcp://0.0.0.0:4242")s.run() 这里由于time.sleep()导致所有该zerorpc的进程使用，导致连接的客户端协程全部被阻塞，故这里应该使用协程的sleep()方法，协程才能正常的并发执行。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QEMU / KVM 快照相关命令介绍]]></title>
    <url>%2F2021%2F01%2F19%2FOpenstack%2FVirshSnapshotCmd%2F</url>
    <content type="text"><![CDATA[• INSTANCE_NAME： 实例instance名称• SNAPSHOT_NAME： 快照名称• SNAPSHOT_DESCRIPTION： 快照描述 1.创建快照命令：virsh snapshot-create-as –domain INSTANCE_NAME –name SNAPSHOT_NAME –description SNAPSHOT_DESCRIPTION 12[root@compute144 ~]# virsh snapshot-create-as --domain instance-00001286 --name scene-init --description scene-initDomain snapshot scene-init created 2.删除快照命令：virsh snapshot-delete INSTANCE_NAME SNAPSHOT_NAME 12[root@compute144 ~]# virsh snapshot-delete instance-00001286 scene-initDomain snapshot scene-init deleted 3.恢复快照命令：virsh snapshot-revert INSTANCE_NAME SNAPSHOT_NAME 1[root@compute144 ~]# virsh snapshot-revert instance-00001286 scene-init 4.查看快照disk信息qemu-img info disk 1234567891011121314151617181920根据instance_name得到实例的uuid[root@compute144 ~]# cd /var/lib/nova/instances/27a7b4d6-9036-4625-99f2-dbe6141d7eb7[root@compute144 27a7b4d6-9036-4625-99f2-dbe6141d7eb7]# qemu-img info diskimage: diskfile format: qcow2virtual size: 10G (10737418240 bytes)disk size: 445Mcluster_size: 65536backing file: /var/lib/nova/instances/_baseID TAG VM SIZE DATE VM CLOCK1 scene-init 253M 2021-01-18 11:48:18 02:25:45.194Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: fals* 此功能必须为虚拟机关机状态下生效，否则：qemu-img: Could not open 'disk': Failed to get shared "write" lockIs another process using the image [disk]? 5.查看快照列表virsh snapshot-list INSTANCE_NAME 1234[root@compute144 ~]# virsh snapshot-list instance-00001286 Name Creation Time State------------------------------------------------------------ scene-init 2021-01-19 08:51:22 +0800 shutoff 6.查看快照信息virsh snapshot-info INSTANCE_NAME –current 12345678910[root@compute144 ~]# virsh snapshot-info instance-00001286 --currentName: scene-initDomain: instance-00001286Current: yesState: shutoffLocation: internalParent: -Children: 0Descendants: 0Metadata: yes 7.查看当前快照所有信息virsh snapshot-current INSTANCE_NAME 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153[root@compute144 ~]# virsh snapshot-current instance-00001286&lt;domainsnapshot&gt; &lt;name&gt;scene-init&lt;/name&gt; &lt;description&gt;scene-init&lt;/description&gt; &lt;state&gt;shutoff&lt;/state&gt; &lt;creationTime&gt;1611017482&lt;/creationTime&gt; &lt;memory snapshot='no'/&gt; &lt;disks&gt; &lt;disk name='vda' snapshot='internal'/&gt; &lt;disk name='hda' snapshot='no'/&gt; &lt;/disks&gt; &lt;domain type='kvm'&gt; &lt;name&gt;instance-00001286&lt;/name&gt; &lt;uuid&gt;27a7b4d6-9036-4625-99f2-dbe6141d7eb7&lt;/uuid&gt; &lt;metadata&gt; &lt;nova:instance xmlns:nova="http://openstack.org/xmlns/libvirt/nova/1.0"&gt; &lt;nova:package version="17.0.10-1.el7"/&gt; &lt;nova:name&gt;ps_T15Z2PS-SCENE220@-1&lt;/nova:name&gt; &lt;nova:creationTime&gt;2021-01-18 06:41:30&lt;/nova:creationTime&gt; &lt;nova:flavor name="&amp;#x4E3B;&amp;#x7AD9;&amp;#x7EB5;&amp;#x5411;"&gt; &lt;nova:memory&gt;1024&lt;/nova:memory&gt; &lt;nova:disk&gt;10&lt;/nova:disk&gt; &lt;nova:swap&gt;0&lt;/nova:swap&gt; &lt;nova:ephemeral&gt;0&lt;/nova:ephemeral&gt; &lt;nova:vcpus&gt;1&lt;/nova:vcpus&gt; &lt;/nova:flavor&gt; &lt;nova:owner&gt; &lt;nova:user uuid="d5853486b6904865abaf98e1eedfd926"&gt;admin&lt;/nova:user&gt; &lt;nova:project uuid="a385d3107887463abebad53b48dda754"&gt;admin&lt;/nova:project&gt; &lt;/nova:owner&gt; &lt;nova:root type="image" uuid="ebe94aab-979a-4311-bf59-9be20a3f44e7"/&gt; &lt;/nova:instance&gt; &lt;/metadata&gt; &lt;memory unit='KiB'&gt;1048576&lt;/memory&gt; &lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt; &lt;vcpu placement='static'&gt;1&lt;/vcpu&gt; &lt;cputune&gt; &lt;shares&gt;1024&lt;/shares&gt; &lt;/cputune&gt; &lt;sysinfo type='smbios'&gt; &lt;system&gt; &lt;entry name='manufacturer'&gt;RDO&lt;/entry&gt; &lt;entry name='product'&gt;OpenStack Compute&lt;/entry&gt; &lt;entry name='version'&gt;17.0.10-1.el7&lt;/entry&gt; &lt;entry name='serial'&gt;12c77e03-1355-43af-a482-61ecf2aad317&lt;/entry&gt; &lt;entry name='uuid'&gt;27a7b4d6-9036-4625-99f2-dbe6141d7eb7&lt;/entry&gt; &lt;entry name='family'&gt;Virtual Machine&lt;/entry&gt; &lt;/system&gt; &lt;/sysinfo&gt; &lt;os&gt; &lt;type arch='x86_64' machine='pc-i440fx-rhel7.6.0'&gt;hvm&lt;/type&gt; &lt;boot dev='hd'/&gt; &lt;smbios mode='sysinfo'/&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;/features&gt; &lt;cpu mode='host-model' check='partial'&gt; &lt;model fallback='allow'/&gt; &lt;topology sockets='1' cores='1' threads='1'/&gt; &lt;/cpu&gt; &lt;clock offset='utc'&gt; &lt;timer name='pit' tickpolicy='delay'/&gt; &lt;timer name='rtc' tickpolicy='catchup'/&gt; &lt;timer name='hpet' present='no'/&gt; &lt;/clock&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;destroy&lt;/on_crash&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2' cache='none'/&gt; &lt;source file='/var/lib/nova/instances/27a7b4d6-9036-4625-99f2-dbe6141d7eb7/disk'/&gt; &lt;target dev='vda' bus='virtio'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/&gt; &lt;/disk&gt; &lt;disk type='file' device='cdrom'&gt; &lt;driver name='qemu' type='raw' cache='none'/&gt; &lt;source file='/var/lib/nova/instances/27a7b4d6-9036-4625-99f2-dbe6141d7eb7/disk.config'/&gt; &lt;target dev='hda' bus='ide'/&gt; &lt;readonly/&gt; &lt;address type='drive' controller='0' bus='0' target='0' unit='0'/&gt; &lt;/disk&gt; &lt;controller type='ide' index='0'&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/&gt; &lt;/controller&gt; &lt;controller type='usb' index='0' model='piix3-uhci'&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x2'/&gt; &lt;/controller&gt; &lt;controller type='pci' index='0' model='pci-root'/&gt; &lt;interface type='bridge'&gt; &lt;mac address='fa:16:3e:70:8f:e9'/&gt; &lt;source bridge='qbr9a416b99-f4'/&gt; &lt;target dev='tap9a416b99-f4'/&gt; &lt;model type='virtio'/&gt; &lt;mtu size='1450'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/&gt; &lt;/interface&gt; &lt;interface type='bridge'&gt; &lt;mac address='fa:16:3e:cb:8b:c6'/&gt; &lt;source bridge='qbr4e232a0d-3e'/&gt; &lt;target dev='tap4e232a0d-3e'/&gt; &lt;model type='virtio'/&gt; &lt;mtu size='1500'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/&gt; &lt;/interface&gt; &lt;interface type='bridge'&gt; &lt;mac address='fa:16:3e:dd:4e:8d'/&gt; &lt;source bridge='qbr3a023c95-a5'/&gt; &lt;target dev='tap3a023c95-a5'/&gt; &lt;model type='virtio'/&gt; &lt;mtu size='1500'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0'/&gt; &lt;/interface&gt; &lt;interface type='bridge'&gt; &lt;mac address='fa:16:3e:66:a0:b7'/&gt; &lt;source bridge='qbr0c33b092-d0'/&gt; &lt;target dev='tap0c33b092-d0'/&gt; &lt;model type='virtio'/&gt; &lt;mtu size='1450'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/&gt; &lt;/interface&gt; &lt;serial type='pty'&gt; &lt;log file='/var/lib/nova/instances/27a7b4d6-9036-4625-99f2-dbe6141d7eb7/console.log' append='off'/&gt; &lt;target type='isa-serial' port='0'&gt; &lt;model name='isa-serial'/&gt; &lt;/target&gt; &lt;/serial&gt; &lt;console type='pty'&gt; &lt;log file='/var/lib/nova/instances/27a7b4d6-9036-4625-99f2-dbe6141d7eb7/console.log' append='off'/&gt; &lt;target type='serial' port='0'/&gt; &lt;/console&gt; &lt;input type='tablet' bus='usb'&gt; &lt;address type='usb' bus='0' port='1'/&gt; &lt;/input&gt; &lt;input type='mouse' bus='ps2'/&gt; &lt;input type='keyboard' bus='ps2'/&gt; &lt;graphics type='vnc' port='-1' autoport='yes' listen='0.0.0.0' keymap='en-us'&gt; &lt;listen type='address' address='0.0.0.0'/&gt; &lt;/graphics&gt; &lt;video&gt; &lt;model type='cirrus' vram='16384' heads='1' primary='yes'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/&gt; &lt;/video&gt; &lt;memballoon model='virtio'&gt; &lt;stats period='10'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/&gt; &lt;/memballoon&gt; &lt;/devices&gt; &lt;/domain&gt;&lt;/domainsnapshot&gt;]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>kvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QEMU / KVM 快照介绍]]></title>
    <url>%2F2021%2F01%2F18%2FOpenstack%2FQemuKvmSnapshot%2F</url>
    <content type="text"><![CDATA[1.QEMU/KVM快照 1.1 概念QEMU/KVM 快照的定义：快照就是将虚机在某一个时间点上的磁盘、内存和设备状态保存一下，以备将来之用。它包括以下几类： 磁盘快照：磁盘的内容（可能是虚机的全部磁盘或者部分磁盘）在某个时间点上被保存，然后可以被恢复。磁盘数据的保存状态：在一个运行着的系统上，一个磁盘快照很可能只是崩溃一致的（crash-consistent） 而不是完整一致（clean）的，也是说它所保存的磁盘状态可能相当于机器突然掉电时硬盘数据的状态，机器重启后需要通过 fsck 或者别的工具来恢复到完整一致的状态（类似于 Windows 机器在断电后会执行文件检查）。(注：命令 qemu-img check -f qcow2 –output=qcow2 -r all filename-img.qcow2 可以对 qcow2 和 vid 格式的镜像做一致性检查。)对一个非运行中的虚机来说，如果上次虚机关闭的时候磁盘是完整一致的，那么其被快照的磁盘快照也将是完整一致的。磁盘快照有两种：• 内部快照 - 使用单个的 qcow2 的文件来保存快照和快照之后的改动。这种快照是 libvirt 的默认行为，现在的支持很完善（创建、回滚和删除），但是只能针对 qcow2 格式的磁盘镜像文件，而且其过程较慢等。• 外部快照 - 快照是一个只读文件，快照之后的修改是另一个 qcow2 文件中。外置快照可以针对各种格式的磁盘镜像文件。外置快照的结果是形成一个 qcow2 文件链：original &lt;- snap1 &lt;- snap2 &lt;- snap3。内存状态（或者虚机状态）：只是保持内存和虚机使用的其它资源的状态。如果虚机状态快照在做和恢复之间磁盘没有被修改，那么虚机将保持一个持续的状态；如果被修改了，那么很可能导致数据corruption。系统还原点（system checkpoint）：虚机的所有磁盘的快照和内存状态快照的集合，可用于恢复完整的系统状态（类似于系统休眠）。关于 崩溃一致（crash-consistent）的附加说明： 应该尽量避免在虚机I/O繁忙的时候做快照。这种时候做快照不是可取的办法。vmware 的做法是装一个 tools，它是个 PV driver，可以在做快照的时候挂起系统似乎 KVM 也有类似的实现 QEMU Guest Agent，但是还不是很成熟，可参考 http://wiki.libvirt.org/page/Qemu_guest_agent快照还可以分为 live snapshot（热快照）和 Clod snapshot：Live snapshot：系统运行状态下做的快照Cold snapshot：系统停止状态下的快照libvit 做 snapshot 的各个 API： 分别来看看这些 API 是如何工作的： virDomainSnapshotCreateXML (virDomainPtr domain, const char * xmlDesc, unsigned int flags)作用：根据 xmlDesc 指定的 snapshot xml 和 flags 来创建虚机的快照。 其内部实现根据虚机的运行状态有两种情形：• 对运行着的虚机，API 使用 QEMU Monitor 去做快照，磁盘镜像文件必须是 qcow2 格式，虚机的 CPU 被停止，快照结束后会重新启动。• 对停止着的虚机，API 调用 qemu-img 方法来操作所有磁盘镜像文件。这里有其实现代码，可见其基本的实现步骤： 1234567891011121314static virDomainSnapshotPtr qemuDomainSnapshotCreateXML&#123; .... call qemuDomainSnapshotCreateDiskActive &#123; call qemuProcessStopCPUs # 停止 vCPUs for each disk call qemuDomainSnapshotCreateSingleDiskActive &#123; call qemuMonitorDiskSnapshot # 调用 QEMU Monitor 去为每个磁盘做snapshot &#125; call qemuProcessStartCPUs # 启动 vCPUs &#125; ....&#125; virDomainSave 相关的几个 API这几个API 功能都比较类似： 1.2 使用 virsh 实验virsh snapshot-create/snapshort-create-as先看看它的用法： 123456789101112131415161718192021222324virsh # help snapshot-create-as NAME snapshot-create-as - Create a snapshot from a set of args SYNOPSIS snapshot-create-as &lt;domain&gt; [&lt;name&gt;] [&lt;description&gt;] [--print-xml] [--no-metadata] [--halt] [--disk-only] [--reuse-external] [--quiesce] [--atomic] [--live] [--memspec &lt;string&gt;] [[--diskspec] &lt;string&gt;]... DESCRIPTION Create a snapshot (disk and RAM) from arguments OPTIONS [--domain] &lt;string&gt; domain name, id or uuid [--name] &lt;string&gt; name of snapshot [--description] &lt;string&gt; description of snapshot --print-xml print XML document rather than create --no-metadata take snapshot but create no metadata #创建的快照不带任何元数据 --halt halt domain after snapshot is created #快照创建后虚机会关闭 --disk-only capture disk state but not vm state #只对磁盘做快照，忽略其它参数 --reuse-external reuse any existing external files --quiesce quiesce guest's file systems #libvirt 会通过 QEMU GA 尝试去freeze和unfreeze客户机已经mounted的文件系统；如果客户机没有安装QEMU GA，则操作会失败。 --atomic require atomic operation #快照要么完全成功要么完全失败，不允许部分成果。不是所有的VMM都支持。 --live take a live snapshot #当客户机处于运行状态下做快照 --memspec &lt;string&gt; memory attributes: [file=]name[,snapshot=type] [--diskspec] &lt;string&gt; disk attributes: disk[,snapshot=type][,driver=type][,file=name] 其中一些参数，比如 –atomic，在一些老的 QEMU libary 上不支持，需要更新它到新的版本。根据 这篇文章，atomic 应该是 QEMU 1.0 中加入的。（1）默认的话，该命令创建虚机的所有磁盘和内存做内部快照，创建快照时虚机处于 paused 状态，快照完成后变为 running 状态。持续时间较长。 123456&lt;memory snapshot='internal'/&gt; &lt;disks&gt; &lt;disk name='vda' snapshot='internal'/&gt; &lt;disk name='vdb' snapshot='internal'/&gt; &lt;disk name='vdc' snapshot='internal'/&gt; &lt;/disks&gt; 每个磁盘的镜像文件都包含了 snapshot 的信息： 1234567891011121314151617[root@compute144 8984f8b3-8429-4d16-a6f6-bff239605f46]# qemu-img info diskimage: diskfile format: qcow2virtual size: 10G (10737418240 bytes)disk size: 745Mcluster_size: 65536backing file: /var/lib/nova/instances/_base/af01f8737b75e5ccf8a5f51ce051bde57b71fdfbSnapshot list:ID TAG VM SIZE DATE VM CLOCK1 123 0 2021-01-15 16:30:00 00:00:00.0002 12345 230M 2021-01-15 16:40:42 00:07:27.6653 345 229M 2021-01-15 16:57:44 00:07:16.928Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false 你可以运行 snapshot-revert 命令回滚到指定的snapshot。 virsh # snapshot-revert instance-0000002e 1433950148 根据 这篇文章，libvirt 将内存状态保存到某一个磁盘镜像文件内 （”state is saved inside one of the disks (as in qemu’s ‘savevm’system checkpoint implementation). If needed in the future,we can also add an attribute pointing out which disk saved the internal state; maybe disk=’vda’.） （2）可以使用 “–memspec” 和 “–diskspec” 参数来给内存和磁盘外部快照。这时候，在获取内存状态之前需要 Pause 虚机，就会产生服务的 downtime。 12345678910virsh # snapshot-create-as 0000002e livesnap2 --memspec /home/s1/livesnap2mem,snapshot=external --diskspec vda,snapshot=externalDomain snapshot livesnap2 createdvirsh # snapshot-dumpxml 0000002e livesnap2 &lt;memory snapshot='external' file='/home/s1/livesnap2mem'/&gt; &lt;disks&gt; &lt;disk name='vda' snapshot='external' type='file'&gt; &lt;driver type='qcow2'/&gt; &lt;source file='/home/s1/testvm/testvm1.livesnap2'/&gt; &lt;/disk&gt; &lt;/disks&gt; （3）可以使用 “–disk-only” 参数，这时会做所有磁盘的外部快照，但是不包含内存的快照。不指定快照文件名字的话，会放在原来的磁盘文件所在的目录中。多次快照后，会形成一个外部快照链，新的快照使用前一个快照的镜像文件作为 backing file。 1234567891011virsh # snapshot-list instance-0000002e --tree1433950148 #内部快照1433950810 #内部快照1433950946 #内部快照snap1 #第一个外部快照 | +- snap2 #第二个外部快照 | +- 1433954941 #第三个外部快照 | +- 1433954977 #第四个外部快照 而第一个外部快照的镜像文件是以虚机的原始镜像文件作为 backing file 的： 1234567891011root@compute1:/var/lib/nova/instances/eddc46a8-e026-4b2c-af51-dfaa436fcc7b# qemu-img info disk.snap1image: disk.snap1file format: qcow2virtual size: 30M (31457280 bytes)disk size: 196Kcluster_size: 65536backing file: /var/lib/nova/instances/eddc46a8-e026-4b2c-af51-dfaa436fcc7b/disk.swap #虚机的 swap disk 原始镜像文件backing file format: qcow2Format specific information: compat: 1.1 lazy refcounts: false 目前还不支持回滚到某一个extrenal disk snapshot。这篇文章 谈到了一个workaround。 12[root@rh65 osdomains]# virsh snapshot-revert d-2 1434467974error: unsupported configuration: revert to external disk snapshot not supported yet （4）还可以使用 “–live” 参数创建系统还原点，包括磁盘、内存和设备状态等。使用这个参数时，虚机不会被 Paused（那怎么实现的？）。其后果是增加了内存 dump 文件的大小，但是减少了系统的 downtime。该参数只能用于做外部的系统还原点（external checkpoint）。 12345678910virsh # snapshot-create-as 0000002e livesnap3 --memspec /home/s1/livesnap3mem,snapshot=external --diskspec vda,snapshot=external --liveDomain snapshot livesnap3 createdvirsh # snapshot-dumpxml 0000002e livesnap3 &lt;memory snapshot='external' file='/home/s1/livesnap3mem'/&gt; &lt;disks&gt; &lt;disk name='vda' snapshot='external' type='file'&gt; &lt;driver type='qcow2'/&gt; &lt;source file='/home/s1/testvm/testvm1.livesnap3'/&gt; &lt;/disk&gt; &lt;/disks&gt; 注意到加 “–live” 生成的快照和不加这个参数生成的快照不会被链在一起： 12345678virsh # snapshot-list 0000002e --treelivesnap1 #没加 --live | +- livesnap2 #没加 --livelivesnap3 #加了 --live | +- livesnap4 #加了 --live 不过，奇怪的是，使用 QEMU 2.3 的情况下，即使加了 –live 参数，虚机还是会被短暂的 Paused 住： 1234567891011121314151617181920212223[root@rh65 ~]# virsh snapshot-create-as d-2 --memspec /home/work/d-2/mem3,snapshot=external --diskspec hda,snapshot=external --liveDomain snapshot 1434478667 created[root@rh65 ~]# virsh list --all Id Name State---------------------------------------------------- 40 osvm1 running 42 osvm2 running 43 d-2 running[root@rh65 ~]# virsh list --all Id Name State---------------------------------------------------- 40 osvm1 running 42 osvm2 running 43 d-2 paused[root@rh65 ~]# virsh list --all Id Name State---------------------------------------------------- 40 osvm1 running 42 osvm2 running 43 d-2 running 可以使用 snapshot-revert 命令来回滚到指定的系统还原点，不过得使用 “-force” 参数 。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>kvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cloud-init 初始化虚拟机配置]]></title>
    <url>%2F2020%2F10%2F21%2FOpenstack%2FCloudinitIntro%2F</url>
    <content type="text"><![CDATA[梳理一下，什么是 cloud-init，它解决了什么实际问题，以及最重要的它该怎么用。 cloud-init 是什么cloud-init 是运行在 Guest machine 中，并在初始化时将一些自定义的配置应用到 Guest machine 中的应用程序。想象一下，假如你是一个云主机提供商，每天都需要为客户初始化成千上万台虚拟主机，这些机器可能使用不用的操作系统，可能根据客户需求设定不同的 IP 地址，不同的 SSH key，以及设置不同的 hostname 等等，这个时候需要怎么办，cloud-init 就是为了解决这个问题而诞生的。 cloud-init 最早由 Ubuntu 的开发商 Canonical 开发，现在已经支持绝大多数 Linux 发行版和 FreeBSD 系统。而目前大部分的公有云都在用 cloud-init 初始化系统配置，cloud-init 也支持部分私有云 (KVM, OpenStack, LXD 等等） 1，已经成为了事实上的标准。而这里就回到了 Proxmox，因为 Proxmox 是用来部署和管理虚拟机的平台，所以天然的适合 cloud-init 的使用场景，甚至可以说是不可或缺的一部分。 当我们在 AWS，或者 Google Cloud 这些公有云中申请计算资源的时候，云服务的提供商总是会叫我们选择一个系统镜像，然后做一些基础设置 (Hostname, SSH key 等等），然后在此基础上进行系统创建。cloud-init 正是在这个背景下诞生，自动化将用户数据初始化到系统实例中。 cloud-init 的主旨是定义一些独立于操作系统的配置，比如 hostname, networking configuration 等等。 cloud-init 特性： 设置默认的 locale 设置 hostname 生成并设置 SSH 私钥 设置临时的挂载点 Boot Stagescloud-init 对系统的初始化分为这几个阶段： Generator Local Network Config Final Generator当系统启动的时候，generator 会检查 cloud-init.target 是否需要启动。默认情况下，generator 会启动 cloud-init. 但是如下情况 cloud-init 不会在开机运行： /etc/cloud/cloud-init.disabled 文件存在时 当内核命令发现文件 /proc/cmdline 包含 cloud-init=disabled 时，当在容器中运行时，内核命令可能会被忽略，但是 cloud-init 会读取 KERNEL_CMDLINE 这个环境变量 LocalLocal 阶段会在挂载根分区 / 时，立即执行 1cloud-init-local.service Local 阶段的目的是： 查找 local data source 将网络配置应用到本地大多数情况下，这个阶段就只会做这些事情。它会在 datasource 中查找，并应用网络配置。网络配置可能从这些地方来： datasource: 云端通过 metadata 提供 fallback: 通过 dhcp on eth0，在虚拟机内自行通过 DHCP 获取 IP none: 网络配置可以通过 /etc/cloud/cloud.cfg 中配置 network: {config: disabled} 来禁用如果是该实例的第一次启动，那么被选中的网络配置会被应用，所有老旧的配置都会会清除。 该阶段需要阻止网络服务启动以及老的配置被应用，这可能带来一些负面的影响，比如 DHCP 服务挂起，或者已经广播了老的 hostname，这可能导致系统进入一个奇怪的状态需要重启网络设备。 cloud-init 然后再继续启动系统，将网络配置应用后启动。 Network在 local 阶段后，网络服务启动后，启动 1cloud-init.service 该阶段需要所有的网络配置已经被应用，并且网络在线，然后才会应用所有的 user-data 递归检索任何 #include 或者 #include-once 包括 http 解压缩任何压缩的内容 运行任何找到的 part-handler该阶段运行 disk_set 和 mounts 模块，可能会分区并格式化任何配置挂载点（比如 /etc/fstab中）的磁盘。这个模块不能再早运行，因为有可能有些信息来源于网络，只有等网络信息获取到后才能执行。比如用户可能在网络资源中提供了挂载点配置信息。 在一些云服务中，比如 Azure，这个阶段会创建可以被挂载的文件系统。 part-handler 也会在这个阶段运行，包括 cloud-config bootcmd。 Config在网络启动后运行： 1cloud-config.service 这个阶段只会运行 config 模块，不会对其他阶段产生影响的模块在这里运行。 Final启动的最后阶段运行： 1cloud-final.service 用户登录系统后习惯于运行的脚本在这个阶段运行，包括： 包安装 配置管理的插件 (puppet, chef, salt-minion) 用户脚本（包括 runcmd) 配置文件地址cloud-init 配置文件在： 12/etc/cloud/cloud.cfg/etc/cloud/cloud.cfg.d/*.cfg cloud-init 在配置文件 /etc/cloud/cloud.cfg 中定义了各个阶段需要执行的任务，任务以 module 形式组织。 cloud.cfg 中指定了 set_hostname 这个 module, 则表示 cloud-init 会执行设置 hostname 的任务，但是具体设置的内容由 metadata 指定。 cloud-init 的日志在： 123/var/log/cloud-init-output.log: 每一个阶段的输出/var/log/cloud-init.log: 每一个操作更详细的调试日志/run/cloud-init: contains logs about how cloud-init decided to enable or disable itself, as well as what platforms/datasources were detected. These logs are most useful when trying to determine what cloud-init ran or did not run. 数据存放在： 1/var/lib/cloud]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 CloudInit 安装使用及配置说明]]></title>
    <url>%2F2020%2F10%2F21%2FOpenstack%2FCentos7Cloudinit%2F</url>
    <content type="text"><![CDATA[1.使用本地YUM源安装cloud-init及其依赖，cloud-init版本18.2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308[root@localhost ~] yum -y install cloud-initLoaded plugins: fastestmirrorDetermining fastest mirrorsResolving Dependencies--&gt; Running transaction check---&gt; Package cloud-init.x86_64 0:18.2-1.el7.centos will be installed--&gt; Processing Dependency: python-six for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: python-requests for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: python-prettytable for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: python-jsonpatch for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: python-jinja2 for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: pyserial for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: policycoreutils-python for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Processing Dependency: PyYAML for package: cloud-init-18.2-1.el7.centos.x86_64--&gt; Running transaction check---&gt; Package PyYAML.x86_64 0:3.10-11.el7 will be installed--&gt; Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64---&gt; Package policycoreutils-python.x86_64 0:2.5-29.el7 will be installed--&gt; Processing Dependency: policycoreutils = 2.5-29.el7 for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: setools-libs &gt;= 3.3.8-4 for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libsemanage-python &gt;= 2.5-14 for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: audit-libs-python &gt;= 2.1.3-4 for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: python-IPy for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libqpol.so.1(VERS_1.4)(64bit) for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libqpol.so.1(VERS_1.2)(64bit) for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libcgroup for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libapol.so.4(VERS_4.0)(64bit) for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: checkpolicy for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libqpol.so.1()(64bit) for package: policycoreutils-python-2.5-29.el7.x86_64--&gt; Processing Dependency: libapol.so.4()(64bit) for package: policycoreutils-python-2.5-29.el7.x86_64---&gt; Package pyserial.noarch 0:2.6-6.el7 will be installed---&gt; Package python-prettytable.noarch 0:0.7.2-3.el7 will be installed---&gt; Package python2-jinja2.noarch 0:2.10-2.el7 will be installed--&gt; Processing Dependency: python2-babel &gt;= 0.8 for package: python2-jinja2-2.10-2.el7.noarch--&gt; Processing Dependency: python2-markupsafe for package: python2-jinja2-2.10-2.el7.noarch---&gt; Package python2-jsonpatch.noarch 0:1.21-1.el7 will be installed--&gt; Processing Dependency: python2-jsonpointer for package: python2-jsonpatch-1.21-1.el7.noarch---&gt; Package python2-requests.noarch 0:2.14.2-1.el7 will be installed--&gt; Processing Dependency: python2-urllib3 = 1.21.1 for package: python2-requests-2.14.2-1.el7.noarch--&gt; Processing Dependency: python-idna for package: python2-requests-2.14.2-1.el7.noarch--&gt; Processing Dependency: python-chardet for package: python2-requests-2.14.2-1.el7.noarch---&gt; Package python2-six.noarch 0:1.10.0-9.el7 will be installed--&gt; Running transaction check---&gt; Package audit-libs-python.x86_64 0:2.8.4-4.el7 will be installed--&gt; Processing Dependency: audit-libs(x86-64) = 2.8.4-4.el7 for package: audit-libs-python-2.8.4-4.el7.x86_64---&gt; Package checkpolicy.x86_64 0:2.5-8.el7 will be installed---&gt; Package libcgroup.x86_64 0:0.41-20.el7 will be installed---&gt; Package libsemanage-python.x86_64 0:2.5-14.el7 will be installed--&gt; Processing Dependency: libsemanage = 2.5-14.el7 for package: libsemanage-python-2.5-14.el7.x86_64---&gt; Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed---&gt; Package policycoreutils.x86_64 0:2.5-22.el7 will be updated---&gt; Package policycoreutils.x86_64 0:2.5-29.el7 will be an update--&gt; Processing Dependency: libsepol &gt;= 2.5-10 for package: policycoreutils-2.5-29.el7.x86_64--&gt; Processing Dependency: libselinux-utils &gt;= 2.5-14 for package: policycoreutils-2.5-29.el7.x86_64---&gt; Package python-IPy.noarch 0:0.75-6.el7 will be installed---&gt; Package python-chardet.noarch 0:2.2.1-1.el7_1 will be installed---&gt; Package python2-babel.noarch 0:2.3.4-1.el7 will be installed--&gt; Processing Dependency: pytz for package: python2-babel-2.3.4-1.el7.noarch---&gt; Package python2-idna.noarch 0:2.5-1.el7 will be installed---&gt; Package python2-jsonpointer.noarch 0:1.10-4.el7 will be installed---&gt; Package python2-markupsafe.x86_64 0:0.23-16.el7 will be installed---&gt; Package python2-urllib3.noarch 0:1.21.1-1.el7 will be installed--&gt; Processing Dependency: python2-pyOpenSSL for package: python2-urllib3-1.21.1-1.el7.noarch--&gt; Processing Dependency: python-pysocks for package: python2-urllib3-1.21.1-1.el7.noarch--&gt; Processing Dependency: python-cryptography for package: python2-urllib3-1.21.1-1.el7.noarch---&gt; Package setools-libs.x86_64 0:3.3.8-4.el7 will be installed--&gt; Processing Dependency: libselinux &gt;= 2.5-14.1 for package: setools-libs-3.3.8-4.el7.x86_64--&gt; Running transaction check---&gt; Package audit-libs.x86_64 0:2.8.1-3.el7 will be updated--&gt; Processing Dependency: audit-libs(x86-64) = 2.8.1-3.el7 for package: audit-2.8.1-3.el7.x86_64---&gt; Package audit-libs.x86_64 0:2.8.4-4.el7 will be an update---&gt; Package libselinux.x86_64 0:2.5-12.el7 will be updated--&gt; Processing Dependency: libselinux(x86-64) = 2.5-12.el7 for package: libselinux-python-2.5-12.el7.x86_64---&gt; Package libselinux.x86_64 0:2.5-14.1.el7 will be an update---&gt; Package libselinux-utils.x86_64 0:2.5-12.el7 will be updated---&gt; Package libselinux-utils.x86_64 0:2.5-14.1.el7 will be an update---&gt; Package libsemanage.x86_64 0:2.5-11.el7 will be updated---&gt; Package libsemanage.x86_64 0:2.5-14.el7 will be an update---&gt; Package libsepol.x86_64 0:2.5-8.1.el7 will be updated---&gt; Package libsepol.x86_64 0:2.5-10.el7 will be an update---&gt; Package python2-cryptography.x86_64 0:2.1.4-2.el7 will be installed--&gt; Processing Dependency: python2-cffi &gt;= 1.7 for package: python2-cryptography-2.1.4-2.el7.x86_64--&gt; Processing Dependency: python2-asn1crypto &gt;= 0.21 for package: python2-cryptography-2.1.4-2.el7.x86_64--&gt; Processing Dependency: python-enum34 for package: python2-cryptography-2.1.4-2.el7.x86_64---&gt; Package python2-pyOpenSSL.noarch 0:17.3.0-3.el7 will be installed---&gt; Package python2-pysocks.noarch 0:1.5.6-3.el7 will be installed---&gt; Package pytz.noarch 0:2016.10-2.el7 will be installed--&gt; Running transaction check---&gt; Package audit.x86_64 0:2.8.1-3.el7 will be updated---&gt; Package audit.x86_64 0:2.8.4-4.el7 will be an update---&gt; Package libselinux-python.x86_64 0:2.5-12.el7 will be updated---&gt; Package libselinux-python.x86_64 0:2.5-14.1.el7 will be an update---&gt; Package python-enum34.noarch 0:1.0.4-1.el7 will be installed---&gt; Package python2-asn1crypto.noarch 0:0.23.0-2.el7 will be installed---&gt; Package python2-cffi.x86_64 0:1.11.2-1.el7 will be installed--&gt; Processing Dependency: python-pycparser for package: python2-cffi-1.11.2-1.el7.x86_64--&gt; Running transaction check---&gt; Package python-pycparser.noarch 0:2.14-1.el7 will be installed--&gt; Processing Dependency: python-ply for package: python-pycparser-2.14-1.el7.noarch--&gt; Running transaction check---&gt; Package python-ply.noarch 0:3.4-11.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved================================================================================ Package Arch Version Repository Size================================================================================Installing: cloud-init x86_64 18.2-1.el7.centos kdpa 776 kInstalling for dependencies: PyYAML x86_64 3.10-11.el7 kdpa 153 k audit-libs-python x86_64 2.8.4-4.el7 kdpa 76 k checkpolicy x86_64 2.5-8.el7 kdpa 295 k libcgroup x86_64 0.41-20.el7 kdpa 66 k libsemanage-python x86_64 2.5-14.el7 kdpa 113 k libyaml x86_64 0.1.4-11.el7_0 kdpa 55 k policycoreutils-python x86_64 2.5-29.el7 kdpa 456 k pyserial noarch 2.6-6.el7 kdpa 124 k python-IPy noarch 0.75-6.el7 kdpa 32 k python-chardet noarch 2.2.1-1.el7_1 kdpa 227 k python-enum34 noarch 1.0.4-1.el7 kdpa 52 k python-ply noarch 3.4-11.el7 kdpa 123 k python-prettytable noarch 0.7.2-3.el7 kdpa 37 k python-pycparser noarch 2.14-1.el7 kdpa 104 k python2-asn1crypto noarch 0.23.0-2.el7 kdpa 172 k python2-babel noarch 2.3.4-1.el7 kdpa 4.8 M python2-cffi x86_64 1.11.2-1.el7 kdpa 229 k python2-cryptography x86_64 2.1.4-2.el7 kdpa 510 k python2-idna noarch 2.5-1.el7 kdpa 94 k python2-jinja2 noarch 2.10-2.el7 kdpa 527 k python2-jsonpatch noarch 1.21-1.el7 kdpa 21 k python2-jsonpointer noarch 1.10-4.el7 kdpa 14 k python2-markupsafe x86_64 0.23-16.el7 kdpa 32 k python2-pyOpenSSL noarch 17.3.0-3.el7 kdpa 92 k python2-pysocks noarch 1.5.6-3.el7 kdpa 20 k python2-requests noarch 2.14.2-1.el7 kdpa 116 k python2-six noarch 1.10.0-9.el7 kdpa 31 k python2-urllib3 noarch 1.21.1-1.el7 kdpa 173 k pytz noarch 2016.10-2.el7 kdpa 46 k setools-libs x86_64 3.3.8-4.el7 kdpa 620 kUpdating for dependencies: audit x86_64 2.8.4-4.el7 kdpa 250 k audit-libs x86_64 2.8.4-4.el7 kdpa 100 k libselinux x86_64 2.5-14.1.el7 kdpa 162 k libselinux-python x86_64 2.5-14.1.el7 kdpa 235 k libselinux-utils x86_64 2.5-14.1.el7 kdpa 151 k libsemanage x86_64 2.5-14.el7 kdpa 151 k libsepol x86_64 2.5-10.el7 kdpa 297 k policycoreutils x86_64 2.5-29.el7 kdpa 916 kTransaction Summary================================================================================Install 1 Package (+30 Dependent packages)Upgrade ( 8 Dependent packages)Total download size: 12 MDownloading packages:Delta RPMs disabled because /usr/bin/applydeltarpm not installed.--------------------------------------------------------------------------------Total 16 MB/s | 12 MB 00:00 Running transaction checkRunning transaction testTransaction test succeededRunning transaction Updating : libsepol-2.5-10.el7.x86_64 1/47 Updating : libselinux-2.5-14.1.el7.x86_64 2/47 Updating : audit-libs-2.8.4-4.el7.x86_64 3/47 Installing : python2-idna-2.5-1.el7.noarch 4/47 Installing : python2-six-1.10.0-9.el7.noarch 5/47 Updating : libsemanage-2.5-14.el7.x86_64 6/47 Updating : libselinux-python-2.5-14.1.el7.x86_64 7/47 Installing : libsemanage-python-2.5-14.el7.x86_64 8/47 Installing : audit-libs-python-2.8.4-4.el7.x86_64 9/47 Installing : setools-libs-3.3.8-4.el7.x86_64 10/47 Updating : libselinux-utils-2.5-14.1.el7.x86_64 11/47 Updating : policycoreutils-2.5-29.el7.x86_64 12/47 Installing : python-chardet-2.2.1-1.el7_1.noarch 13/47 Installing : python-prettytable-0.7.2-3.el7.noarch 14/47 Installing : libyaml-0.1.4-11.el7_0.x86_64 15/47 Installing : PyYAML-3.10-11.el7.x86_64 16/47 Installing : python-ply-3.4-11.el7.noarch 17/47 Installing : python-pycparser-2.14-1.el7.noarch 18/47 Installing : python2-cffi-1.11.2-1.el7.x86_64 19/47 Installing : checkpolicy-2.5-8.el7.x86_64 20/47 Installing : python2-asn1crypto-0.23.0-2.el7.noarch 21/47 Installing : python2-markupsafe-0.23-16.el7.x86_64 22/47 Installing : python2-jsonpointer-1.10-4.el7.noarch 23/47 Installing : python2-jsonpatch-1.21-1.el7.noarch 24/47 Installing : python-IPy-0.75-6.el7.noarch 25/47 Installing : python2-pysocks-1.5.6-3.el7.noarch 26/47 Installing : pytz-2016.10-2.el7.noarch 27/47 Installing : python2-babel-2.3.4-1.el7.noarch 28/47 Installing : python2-jinja2-2.10-2.el7.noarch 29/47 Installing : pyserial-2.6-6.el7.noarch 30/47 Installing : python-enum34-1.0.4-1.el7.noarch 31/47 Installing : python2-cryptography-2.1.4-2.el7.x86_64 32/47 Installing : python2-pyOpenSSL-17.3.0-3.el7.noarch 33/47 Installing : python2-urllib3-1.21.1-1.el7.noarch 34/47 Installing : python2-requests-2.14.2-1.el7.noarch 35/47 Installing : libcgroup-0.41-20.el7.x86_64 36/47 Installing : policycoreutils-python-2.5-29.el7.x86_64 37/47 Installing : cloud-init-18.2-1.el7.centos.x86_64 38/47 Updating : audit-2.8.4-4.el7.x86_64 39/47 Cleanup : policycoreutils-2.5-22.el7.x86_64 40/47 Cleanup : libsemanage-2.5-11.el7.x86_64 41/47 Cleanup : libselinux-utils-2.5-12.el7.x86_64 42/47 Cleanup : libselinux-python-2.5-12.el7.x86_64 43/47 Cleanup : libselinux-2.5-12.el7.x86_64 44/47 Cleanup : audit-2.8.1-3.el7.x86_64 45/47 Cleanup : audit-libs-2.8.1-3.el7.x86_64 46/47 Cleanup : libsepol-2.5-8.1.el7.x86_64 47/47 Verifying : libcgroup-0.41-20.el7.x86_64 1/47 Verifying : python-enum34-1.0.4-1.el7.noarch 2/47 Verifying : pyserial-2.6-6.el7.noarch 3/47 Verifying : cloud-init-18.2-1.el7.centos.x86_64 4/47 Verifying : audit-libs-2.8.4-4.el7.x86_64 5/47 Verifying : audit-2.8.4-4.el7.x86_64 6/47 Verifying : pytz-2016.10-2.el7.noarch 7/47 Verifying : python2-pysocks-1.5.6-3.el7.noarch 8/47 Verifying : python-IPy-0.75-6.el7.noarch 9/47 Verifying : python2-cffi-1.11.2-1.el7.x86_64 10/47 Verifying : python2-requests-2.14.2-1.el7.noarch 11/47 Verifying : python2-jsonpatch-1.21-1.el7.noarch 12/47 Verifying : python2-jsonpointer-1.10-4.el7.noarch 13/47 Verifying : setools-libs-3.3.8-4.el7.x86_64 14/47 Verifying : policycoreutils-2.5-29.el7.x86_64 15/47 Verifying : python2-markupsafe-0.23-16.el7.x86_64 16/47 Verifying : python2-urllib3-1.21.1-1.el7.noarch 17/47 Verifying : libsemanage-python-2.5-14.el7.x86_64 18/47 Verifying : python2-asn1crypto-0.23.0-2.el7.noarch 19/47 Verifying : python2-babel-2.3.4-1.el7.noarch 20/47 Verifying : libsemanage-2.5-14.el7.x86_64 21/47 Verifying : libsepol-2.5-10.el7.x86_64 22/47 Verifying : python2-cryptography-2.1.4-2.el7.x86_64 23/47 Verifying : checkpolicy-2.5-8.el7.x86_64 24/47 Verifying : python-ply-3.4-11.el7.noarch 25/47 Verifying : python2-six-1.10.0-9.el7.noarch 26/47 Verifying : libselinux-python-2.5-14.1.el7.x86_64 27/47 Verifying : audit-libs-python-2.8.4-4.el7.x86_64 28/47 Verifying : python-pycparser-2.14-1.el7.noarch 29/47 Verifying : libyaml-0.1.4-11.el7_0.x86_64 30/47 Verifying : python-prettytable-0.7.2-3.el7.noarch 31/47 Verifying : libselinux-utils-2.5-14.1.el7.x86_64 32/47 Verifying : policycoreutils-python-2.5-29.el7.x86_64 33/47 Verifying : python2-idna-2.5-1.el7.noarch 34/47 Verifying : python-chardet-2.2.1-1.el7_1.noarch 35/47 Verifying : PyYAML-3.10-11.el7.x86_64 36/47 Verifying : libselinux-2.5-14.1.el7.x86_64 37/47 Verifying : python2-jinja2-2.10-2.el7.noarch 38/47 Verifying : python2-pyOpenSSL-17.3.0-3.el7.noarch 39/47 Verifying : libsemanage-2.5-11.el7.x86_64 40/47 Verifying : libselinux-python-2.5-12.el7.x86_64 41/47 Verifying : audit-libs-2.8.1-3.el7.x86_64 42/47 Verifying : libselinux-utils-2.5-12.el7.x86_64 43/47 Verifying : policycoreutils-2.5-22.el7.x86_64 44/47 Verifying : audit-2.8.1-3.el7.x86_64 45/47 Verifying : libsepol-2.5-8.1.el7.x86_64 46/47 Verifying : libselinux-2.5-12.el7.x86_64 47/47 Installed: cloud-init.x86_64 0:18.2-1.el7.centos Dependency Installed: PyYAML.x86_64 0:3.10-11.el7 audit-libs-python.x86_64 0:2.8.4-4.el7 checkpolicy.x86_64 0:2.5-8.el7 libcgroup.x86_64 0:0.41-20.el7 libsemanage-python.x86_64 0:2.5-14.el7 libyaml.x86_64 0:0.1.4-11.el7_0 policycoreutils-python.x86_64 0:2.5-29.el7 pyserial.noarch 0:2.6-6.el7 python-IPy.noarch 0:0.75-6.el7 python-chardet.noarch 0:2.2.1-1.el7_1 python-enum34.noarch 0:1.0.4-1.el7 python-ply.noarch 0:3.4-11.el7 python-prettytable.noarch 0:0.7.2-3.el7 python-pycparser.noarch 0:2.14-1.el7 python2-asn1crypto.noarch 0:0.23.0-2.el7 python2-babel.noarch 0:2.3.4-1.el7 python2-cffi.x86_64 0:1.11.2-1.el7 python2-cryptography.x86_64 0:2.1.4-2.el7 python2-idna.noarch 0:2.5-1.el7 python2-jinja2.noarch 0:2.10-2.el7 python2-jsonpatch.noarch 0:1.21-1.el7 python2-jsonpointer.noarch 0:1.10-4.el7 python2-markupsafe.x86_64 0:0.23-16.el7 python2-pyOpenSSL.noarch 0:17.3.0-3.el7 python2-pysocks.noarch 0:1.5.6-3.el7 python2-requests.noarch 0:2.14.2-1.el7 python2-six.noarch 0:1.10.0-9.el7 python2-urllib3.noarch 0:1.21.1-1.el7 pytz.noarch 0:2016.10-2.el7 setools-libs.x86_64 0:3.3.8-4.el7 Dependency Updated: audit.x86_64 0:2.8.4-4.el7 audit-libs.x86_64 0:2.8.4-4.el7 libselinux.x86_64 0:2.5-14.1.el7 libselinux-python.x86_64 0:2.5-14.1.el7 libselinux-utils.x86_64 0:2.5-14.1.el7 libsemanage.x86_64 0:2.5-14.el7 libsepol.x86_64 0:2.5-10.el7 policycoreutils.x86_64 0:2.5-29.el7 Complete! 2.查看cloud-init是否安装成功。 12[root@localhost ~] cloud-init -v/bin/cloud-init 18.2 3.cloud-init默认日志路径：/var/log/cloud-init.log]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows CloudBase-Init 安装使用及配置说明]]></title>
    <url>%2F2020%2F10%2F20%2FOpenstack%2FWindowsCloudBaseInit%2F</url>
    <content type="text"><![CDATA[1.下载Windows CloudBase-Init安装包，地址：https://cloudbase.it/cloudbase-init/#download 当前版本为：CloudbaseInitSetup_1_1_2_x64.msi 2.安装：安装目录默认为 C:\Program Files\Cloudbase Solutions\Cloudbase-Init用户名修改为当前Windows超级管理员Administrator这里不勾选Use metadata password，勾选此项这里会在孵化虚拟机时生成新的随机密码Serial口选择Windows当前使用的串口COM1安装结束，不勾选Run Sysprep to create a generalized image.及 Shutdown when Sysprep terminates. 3.安装结束之后，修改Cloudbaase-init配置文件：C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\下的cloudbase-init.conf及cloudbase-init-unattend.conf配置修改为：安装CloudBase-init后，cloudbase-init会自动重启，将其关闭重启：allow_reboot=false 关闭CloudBase-init自动更新：check_latest_version=false 4.* Windows在安装cloudbase-init后需要重新启动，再制作镜像。5.使用Openstack在孵化过程中上传的文件目录为(E:)config\openstack\content\下。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloudbaseinit]]></title>
    <url>%2F2020%2F10%2F19%2FOpenstack%2FCloudBaseInit%2F</url>
    <content type="text"><![CDATA[官方文档: https://cloudbase-init.readthedocs.io/en/latest/intro.html IntroIntroThe open source project cloudbase-init is a service conceived and maintained by Cloudbase Solutions Srl, currently working on NT systems. It was designed to initialize and configure guest operating systems under OpenStack, OpenNebula, CloudStack, MaaS and many others. Under Cloudbase page, stable and beta installers can be found and the service itself is very easy to configure through configuration files. It can also customize instances based on user input like local scripts and data. More details on how you can use this can be found under Tutorial. Portable cloud initialization serviceThe main goal of this project is to provide guest cloud initialization for Windows and other operating systems. The architecture of the project is highly flexible and allows extensions for additional clouds and plugins. There’s no limitation in the type of supported hypervisors. This service can be used on instances running on Hyper-V, KVM, Xen, ESXi etc. BinariesStable installers: https://www.cloudbase.it/downloads/CloudbaseInitSetup_Stable_x64.msi https://www.cloudbase.it/downloads/CloudbaseInitSetup_Stable_x86.msi Beta installers: https://www.cloudbase.it/downloads/CloudbaseInitSetup_x64.msi https://www.cloudbase.it/downloads/CloudbaseInitSetup_x86.msi Use a x64 installer on 64 bit versions of Windows and the x86 one exclusively on 32 bit versions. TutorialTutorialFirst, download your desired type of installer from here, then install it and fill in configuration options which suits you best. Based on the current selected cloudbase-init installer architecture, it’ll be available under C:\Program Files or C:\Program Files (x86) as Cloudbase Solutions\Cloudbase-Init directory. There, are located some folders of interest like: bin - Executable files and other binaries. conf - Configuration files holding miscellaneous options. log - Here are the cloudbase-init logs. LocalScripts - User supplied scripts. Python - Bundle of executable and library files to support Python scripts and core execution. After install, cloudbase-init acts like a 2-step service which will read metadata using Services and will pass that to the executing Plugins, this way configuring all the supported things. Depending on the platform, some plugins may request reboots. SyspreppingThe System Preparation (Sysprep) tool prepares an installation of Windows for duplication, auditing, and customer delivery. Duplication, also called imaging, enables you to capture a customized Windows image that you can reuse throughout an organization. The Sysprep phase uses the “Unattend.xml” which implies the service to run using the “cloudbase-init-unattend.conf” configuration file. Configuration fileIn the chosen installation path, under the conf directory, are present two config files named “cloudbase-init.conf” and “cloudbase-init-unattend.conf”. These can hold various config options for picking up the desired available services and plugins ready for execution and also customizing user experience. Explained example of configuration file: 12345678910111213141516171819202122232425262728293031323334[DEFAULT]# What user to create and in which group(s) to be put.username=Admingroups=Administratorsinject_user_password=true # Use password from the metadata (not random).# Which devices to inspect for a possible configuration drive (metadata).config_drive_raw_hhd=trueconfig_drive_cdrom=true# Path to tar implementation from Ubuntu.bsdtar_path=C:\Program Files (x86)\Cloudbase Solutions\Cloudbase-Init\bin\bsdtar.exe# Logging debugging level.verbose=truedebug=true# Where to store logs.logdir=C:\Program Files (x86)\Cloudbase Solutions\Cloudbase-Init\log\logfile=cloudbase-init-unattend.logdefault_log_levels=comtypes=INFO,suds=INFO,iso8601=WARNlogging_serial_port_settings=# Enable MTU and NTP plugins.mtu_use_dhcp_config=truentp_use_dhcp_config=true# Where are located the user supplied scripts for execution.local_scripts_path=C:\Program Files (x86)\Cloudbase Solutions\Cloudbase-Init\LocalScripts\# Services that will be tested for loading until one of them succeeds.metadata_services=cloudbaseinit.metadata.services.configdrive.ConfigDriveService, cloudbaseinit.metadata.services.httpservice.HttpService, cloudbaseinit.metadata.services.ec2service.EC2Service, cloudbaseinit.metadata.services.maasservice.MaaSHttpService# What plugins to execute.plugins=cloudbaseinit.plugins.common.mtu.MTUPlugin, cloudbaseinit.plugins.common.sethostname.SetHostNamePlugin# Miscellaneous.allow_reboot=false # allow the service to reboot the systemstop_service_on_exit=false The “cloudbase-init-unattend.conf” configuration file is similar to the default one and is used by the Sysprepping phase. It was designed for the scenario where the minimum user intervention is required and it only runs the MTU and host name plugins, leaving the image ready for further initialization cases. More of these explained options are available under the Services, Plugins and Userdata documentation. A complete list of config options can be found at Configuration options reference. File executionCloudbase-init has the ability to execute user provided scripts, usually found in the default path C:\Program Files (x86)\Cloudbase Solutions\Cloudbase-Init\LocalScripts, through a specific plugin for doing it. Depending on the platform used, the files should be valid PowerShell, Python, Batch or Bash scripts. The userdata can be also a PEM certificate, in a cloud-config format or a MIME content. The user data plugin is capable of executing various script types and exit code value handling. Based on their exit codes, you can instruct the system to reboot or even re-execute the plugin on the next boot: 1001 - reboot and don’t run the plugin again on next boot1002 - don’t reboot now and run the plugin again on next boot1003 - reboot and run the plugin again on next boot ServicesServicesA metadata service has the role of getting the guest provided data (configuration information) and exposing it to the Plugins for a general and basic initialization of the instance. These sub-services can change their behavior according to custom configuration options documented below. Configuring available servicesAny of these classes can be specified manually in the configuration file under metadata_services option. Based on this option, the service loader will search across these providers in the defined order and load the first one that is available. For more details on doing this, see configuration file in Tutorial. OpenStack (web API)classcloudbaseinit.metadata.services.httpservice.HttpServiceA complete service which supports password related capabilities and can be usually accessed at the http://169.254.169.254/ magic URL. The magic URL can be customized using the metadata_base_url config option. A default value of True for add_metadata_private_ip_route option is used to add a route for the IP address to the gateway. This is needed for supplying a bridge between different VLANs in order to get access to the web server. Metadata version used: latest. Capabilities: instance idhostnamepublic keysWinRM authentication certificatesstatic network configurationadmin user passwordpost admin user password (only once)user data Config options for openstack section: metadata_base_url (string: “http://169.254.169.254/”) add_metadata_private_ip_route (bool: True)https_allow_insecure (bool: False)https_ca_bundle (string: None) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) OpenStack (configuration drive)classcloudbaseinit.metadata.services.configdrive.ConfigDriveServiceThis is similar to the web API, but it “serves” its files locally without requiring network access. The data is generally retrieved from a cdrom, vfat or raw disks/partitions by enabling selective lookup across different devices. Use the types option to specify which types of config drive content the service will search for and also on which devices using the locations option. It will search for metadata: in mounted optical unitsdirectly in the physical disk bytesby exploring the physical disk as a vfat drive; which requires mtools (specified by the mtools_path option in the Default section) This service is usually faster than the HTTP twin, as there is no timeout waiting for the network to be up. Metadata version used: latest. Capabilities: instance idhostnamepublic keysauthentication certificatesstatic network configurationadmin user passworduser data Config options for config_drive section: raw_hdd (bool: True)cdrom (bool: True)vfat (bool: True) types (list: [“vfat”, “iso”]) locations (list: [“cdrom”, “hdd”, “partition”]) NoCloud configuration driveclasscloudbaseinit.metadata.services.nocloudservice.NoCloudConfigDriveServiceNoCloudConfigDriveService is similar to OpenStack config drive metadata in terms of the medium on which the data is provided (as an attached ISO, partition or disk) and similar to the EC2 metadata in terms of how the metadata files are named and structured. The metadata is provided on a config-drive (vfat or iso9660) with the label cidata or CIDATA. The folder structure for NoCloud is: /user-data/meta-data The user-data and meta-data files respect the EC2 metadata service format. Capabilities: instance idhostnamepublic keysstatic network configuration (Debian and network config v1 formats)user data Config options for config_drive section: raw_hdd (bool: True)cdrom (bool: True)vfat (bool: True) types (list: [“vfat”, “iso”]) locations (list: [“cdrom”, “hdd”, “partition”]) Example metadata: 12345678910instance-id: windows1network-interfaces: | iface Ethernet0 inet static address 10.0.0.2 network 10.0.0.0 netmask 255.255.255.0 broadcast 10.0.0.255 gateway 10.0.0.1 hwaddress ether 00:11:22:33:44:55hostname: windowshost1 Cloud-init’s network config v1 format can be used to configure static network configuration. The configuration file should be named network-config and should be present at the same folder level with the meta-data and user-data file. If no network-config is found, cloudbase-init will use the network-interfaces value from the metadata (if any). The following network config types are implemented: physical, bond, vlan and nameserver. Unsupported config types: bridge and route. Example: 123456789101112131415161718192021222324252627282930313233343536373839404142434445version: 1config: - type: physical name: interface0 mac_address: "52:54:00:12:34:00" mtu: 1450 subnets: - type: static address: 192.168.1.10 netmask: 255.255.255.0 dns_nameservers: - 192.168.1.11 - type: bond name: bond0 bond_interfaces: - gbe0 - gbe1 mac_address: "52:54:00:12:34:00" params: bond-mode: active-backup bond-lacp-rate: false mtu: 1450 subnets: - type: static address: 192.168.1.10 netmask: 255.255.255.0 dns_nameservers: - 192.168.1.11 - type: vlan name: vlan0 vlan_link: eth1 vlan_id: 150 mac_address: "52:54:00:12:34:00" mtu: 1450 subnets: - type: static address: 192.168.1.10 netmask: 255.255.255.0 dns_nameservers: - 192.168.1.11 - type: nameserver address: - 192.168.23.2 - 8.8.8.8 search: acme.local More information on the NoCloud metadata service specifications can be found here. Amazon EC2classcloudbaseinit.metadata.services.ec2service.EC2ServiceThis is similar to the OpenStack HTTP service but is using a different format for metadata endpoints and has general capabilities. Metadata version used: 2009-04-04. Capabilities: instance idhostnamepublic keysuser data Config options for ec2 section: metadata_base_url (string: “http://169.254.169.254/”) add_metadata_private_ip_route (bool: True)https_allow_insecure (bool: False)https_ca_bundle (string: None) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) Note http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html Apache CloudStackclasscloudbaseinit.metadata.services.cloudstack.CloudStackAnother web-based service which usually uses “10.1.1.1” or DHCP addresses for retrieving content. If no metadata can be found at the metadata_base_url, the service will look for the metadata at the DHCP server URL. Capabilities: instance idhostnamepublic keysadmin user passwordpoll for, post, delete admin user password (each reboot)user data Config options for cloudstack section: metadata_base_url (string: “http://10.1.1.1/”) password_server_port (int: 8080)add_metadata_private_ip_route (bool: True)https_allow_insecure (bool: False)https_ca_bundle (string: None) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) Note By design, this service can update the password anytime, so it will cause the setuserpassword plugin to run at every boot and by security concerns, the password is deleted right after retrieval and no updating will occur until a new password is available on the server. OpenNebula Serviceclasscloudbaseinit.metadata.services.opennebulaservice.OpenNebulaServiceThe OpenNebula provider is related to configuration drive and searches for a specific context file which holds all the available info. The provided details are exposed as bash variables gathered in a shell script. Capabilities: hardcoded instance id to iid-dsopennebulahostnamepublic keysstatic network configurationuser data Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) Ubuntu MaaSclasscloudbaseinit.metadata.services.maasservice.MaaSHttpServiceThis metadata service usually works with instances on baremetal and uses web requests for retrieving the available exposed metadata. It uses OAuth to secure the requests. Metadata version used: 2012-03-01. Capabilities: instance idhostnamepublic keysWinRM authentication certificatesstatic network configurationuser data Config options for maas section: metadata_base_url (string: None)oauth_consumer_key (string: None)oauth_consumer_secret (string: None)oauth_token_key (string: None)oauth_token_secret (string: None)https_allow_insecure (bool: False)https_ca_bundle (string: None) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) Note By design, the configuration options are set by an agent called curtin which runs the hooks that set the config values. On Windows, these hooks need to be present in the root directory: Windows curtin hooks. Open Virtualization Format (OVF)classcloudbaseinit.metadata.services.ovfservice.OvfServiceThe OVF provider searches data from OVF environment ISO transport. Capabilities: instance id (hardcoded to iid-ovf if not present)hostnamepublic keysadmin user nameadmin user passworduser data Config options: config_file_name (string: “ovf-env.xml”)drive_label (string: “OVF ENV”)ns (string: “oe”) Packet Serviceclasscloudbaseinit.metadata.services.packet.PacketServicePacket metadata service provides the metadata for baremetal servers at the magic URL https://metadata.packet.net/. Capabilities: instance idhostnamepublic keyspost admin user password (only once)user datacall home on successful provision Config options for packet section: metadata_base_url (string: “https://metadata.packet.net/”) https_allow_insecure (bool: False)https_ca_bundle (string: None) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) Azure Serviceclasscloudbaseinit.metadata.services.azureservice.AzureServiceAzure metadata service provides the metadata for Microsoft Azure cloud platform. Azure metadata is offered via multiple sources like HTTP metadata, config-drive metadata and KVP (Hyper-V Key-Value Pair Data Exchange). This implementation uses only HTTP and config-drive metadata sources. Azure service implements the interface to notify the cloud provider when the instance has started provisioning, completed provisioning and if the provisioning failed. Metadata version used: 2015-04-05. Capabilities: instance idhostnamepublic keysWinRM authentication certificatesadmin user nameadmin user passworduser datapost RDP certificate thumbprintprovisioning statusWindows Update statusVM agent configurationlicensing configurationephemeral disk warning Config options for azure section: transport_cert_store_name (string: Windows Azure Environment”) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) Empty Metadata Serviceclasscloudbaseinit.metadata.services.base.EmptyMetadataServiceThe empty metadata service can be used to run plugins that do not rely on metadata service information, like setting NTP, MTU, extending volumes, local scripts execution, licensing, etc. It can be used also as a fallback metadata service, in case no other previous metadata service could be loaded. EmptyMetadataService does not support the following plugins:cloudbaseinit.plugins.windows.createuser.CreateUserPlugincloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPlugincloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPlugincloudbaseinit.plugins.windows.winrmcertificateauth.ConfigWinRMCertificateAuthPlugin If any of the plugins defined above are executed, they will fail with exception NotExistingMetadataException. The reason for the hardcoded failure is that these plugins rely on metadata to execute correctly. If metadata like username or password is not provided, these plugins can lock or misconfigure the user, leading to unwanted problems. Note If a service returns an empty instance-id (like EmptyMetadataService does), all the plugins will be executed at every cloudbase-init run (reboot, service restart). Plugins that set NTP, MTU, extend volumes are idempotent and can be re-executed with no issues. Make sure that if you configure cloudbase-init to run local scripts, those local scripts are idempotent. VMware GuestInfo Serviceclasscloudbaseinit.metadata.services.vmwareguestinfoservice.VMwareGuestInfoServiceVMwareGuestInfoService is a metadata service which uses VMware’s rpctool to extract guest metadata and userdata configured for machines running on VMware hypervisors. The VMware RPC tool used to query the instance metadata and userdata needs to be present at the config option path. Both json and yaml are supported as metadata formats. The metadata / userdata can be encoded in base64, gzip or gzip+base64. Example metadata in yaml format: 1234567instance-id: cloud-vmlocal-hostname: cloud-vmadmin-username: cloud-usernameadmin-password: Passw0rdpublic-keys-data: | ssh-key 1 ssh-key 2 This metadata content needs to be set as string in the guestinfo dictionary, thus needs to be converted to base64 (it is recommended to gzip it too). To convert to gzip+base64 format: 1cat metadata.yml | gzip.exe -9 | base64.exe -w0 The output of the gzip+base64 conversion needs to be set in the instance guestinfo, along with the encoding of the metadata / userdata. For more information on how to achieve this, please check https://github.com/vmware/cloud-init-vmware-guestinfo#configuration This is an example how to set the information from the instance: 1234&lt;rpctool_path&gt; "info-set guestinfo.metadata &lt;gzip+base64-encoded-metadata&gt;"&lt;rpctool_path&gt; "info-set guestinfo.metadata.encoding gzip+base64"&lt;rpctool_path&gt; "info-set guestinfo.userdata &lt;gzip+base64-encoded-userdata&gt;"&lt;rpctool_path&gt; "info-set guestinfo.userdata.encoding gzip+base64" Capabilities: instance idhostnamepublic keysadmin user nameadmin user passworduser data Config options for vmwareguestinfo section: vmware_rpctool_path (string: “%ProgramFiles%/VMware/VMware Tools/rpctool.exe”) Google Compute Engine Serviceclasscloudbaseinit.metadata.services.gceservice.GCEServiceGCE metadata service provides the metadata for instances running on Google Compute Engine. GCE metadata is offered via an internal HTTP metadata endpoint, reachable at the magic URL http://metadata.google.internal/computeMetadata/v1/. More information can be found in the GCE metadata documents. To provide userdata to be executed by the instance (in cloud-config format, for example), use the user-data and user-data-encoding instance metadata keys. Capabilities: instance idhostnamepublic keysuser data Config options for gce section: metadata_base_url (string: http://metadata.google.internal/computeMetadata/v1/”) https_allow_insecure (bool: False)https_ca_bundle (string: None) Config options for default section: retry_count (integer: 5)retry_count_interval (integer: 4) PluginsPluginsPlugins execute actions based on the metadata obtained by the loaded service. They are intended to configure the instance using data provided by the underlying cloud and by the user who created the instance. There are three stages for the plugins’ execution: The PRE_NETWORKING stage (for setting up the network, before doing any valid web request. The PRE_METADATA_DISCOVERY stage (additional configuration before the metadata service discovery). The default MAIN stage, which holds the rest of the plugins which are (re)executed according to their saved status. The metadata service loaded needs to provide an instance id for the plugins to be able to have a saved status. If the metadata service cannot provide an instance id, the plugins state from the MAIN stage cannot be saved, and therefore, all plugins will be executed at every boot. Note that the plugins from the two stages are executed each time the cloudbase-init service starts (those plugins do not have saved status). Just before the MAIN stage, the metadata service can report to the cloud service that the provision started. After the MAIN stage ended, the metadata service can report to the cloud service that the provisioning completed successfully or failed. Configuring selected pluginsBy default, only a subset of plugins is executed. The plugins are: 12[DEFAULT]plugins = cloudbaseinit.plugins.common.mtu.MTUPlugin, cloudbaseinit.plugins.windows.ntpclient.NTPClientPlugin, cloudbaseinit.plugins.common.sethostname.SetHostNamePlugin, cloudbaseinit.plugins.windows.createuser.CreateUserPlugin, cloudbaseinit.plugins.common.networkconfig.NetworkConfigPlugin, cloudbaseinit.plugins.windows.licensing.WindowsLicensingPlugin, cloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPlugin, cloudbaseinit.plugins.windows.extendvolumes.ExtendVolumesPlugin, cloudbaseinit.plugins.common.userdata.UserDataPlugin, cloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPlugin, cloudbaseinit.plugins.windows.winrmlistener.ConfigWinRMListenerPlugin, cloudbaseinit.plugins.windows.winrmcertificateauth.ConfigWinRMCertificateAuthPlugin, cloudbaseinit.plugins.common.localscripts.LocalScriptsPlugin A custom list of plugins can be specified through the plugins option in the configuration file. For more details on doing this, see configuration file in Tutorial. Setting hostname (MAIN)classcloudbaseinit.plugins.common.sethostname.SetHostNamePluginSets the instance hostname. The hostname gets truncated to 15 characters for Netbios compatibility reasons if netbios_host_name_compatibility is set. Config options: netbios_host_name_compatibility (bool: True) Notes: Requires support in the metadata service.May require a system restart. Creating user (MAIN)classcloudbaseinit.plugins.windows.createuser.CreateUserPluginCreates (or updates if existing) a new user and adds it to a set of provided local groups. By default, it creates the user “Admin” under “Administrators” group, but this can be changed in the configuration file. A random user password is set for the user. The password length is by default set to 20 and can be customized using the user_password_length configuration option. If rename_admin_user is set to True, the user Administrator is renamed to the username config value or to the metadata service provided value. Config options: username (string: “Admin”)groups (list of strings: [“Administrators”])user_password_length (int: 20)rename_admin_user (bool: false) Notes: The metadata service can provide the username. If the metadata service provides the admin username, it will override the username configuration value. Setting password (MAIN)classcloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPluginSets the cloud user’s password. If a password has been provided in the metadata during boot it will be used, otherwise a random password will be generated, encrypted with the user’s SSH public key and posted to the metadata provider. An option called inject_user_password is set True by default to make available the use of metadata password which is found under the “admin_pass” field or through an URL request. If the option is set to False or if the password isn’t found in metadata, then an attempt of using an already set password is done (usually a random value by the CreateUserPlugin plugin). With first_logon_behaviour you can control what happens with the password at the next logon. If this option is set to “always”, the user will be forced to change the password at the next logon. If it is set to “clear_text_injected_only”, the user will be forced to change the password only if the password is a clear text password, coming from the metadata. The last option is “no”, when the user is never forced to change the password. Config options: username (string: “Admin”)inject_user_password (bool: True)first_logon_behaviour (string: “clear_text_injected_only”)user_password_length (int: 20) Notes: The metadata service may provide the username. If the metadata service provides the admin username, it will override the username configuration value. May run at every boot to (re)set and post the password if the metadata service supports this behaviour. Static networking (MAIN)classcloudbaseinit.plugins.common.networkconfig.NetworkConfigPluginStatically configures each network adapter for which corresponding details are found into metadata. The details/addresses association is done using MAC matching and if this fails, then name or interface index matching. The basic setting is based on IPv4 addresses, but it supports IPv6 addresses too if they are enabled and exposed to the metadata. The purpose of this plugin is to configure network adapters, for which the DHCP server is disabled, to have internet access and static IPs. NIC teaming (bonding) is supported and uses NetLBFO implementation. Notes: Requires support in the metadata service.May require a system restart. Saving public keys (MAIN)classcloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPluginCreates an authorized_keys file in the user’s home directory containing the SSH keys provided in the metadata. It is needed by the plugin responsible for encrypting and setting passwords. Config options: username (string: “Admin”) Notes: Requires support in the metadata service. The metadata service provides the SSH public keys. The metadata service can provide the username. If the metadata service provides the admin username, it will override the username configuration value. Volume expanding (MAIN)classcloudbaseinit.plugins.windows.extendvolumes.ExtendVolumesPluginExtends automatically a disk partition to its maximum size. This is useful when booting images with different flavors. By default, all the volumes are extended, but you can select specific ones by populating with their indexes the volumes_to_extend option. Config options: volumes_to_extend (list of integers: None) Notes: Runs at every boot. WinRM listener (MAIN)classcloudbaseinit.plugins.windows.winrmlistener.ConfigWinRMListenerPluginConfigures a WinRM HTTPS listener to allow remote management via WinRM or PowerShell. If winrm_enable_basic_auth is set to True, it enables basic authentication (authentication using username and password) for the WinRM listeners. If winrm_configure_http_listener is set to True, the WinRM http listener will also be enabled. Config options: winrm_enable_basic_auth (bool: True)winrm_configure_https_listener (bool: True)winrm_configure_http_listener (bool: False) Notes:The metadata service can provide the listeners configuration (protocol and certificate thumbprint). May run at every boot. If the WinRM Windows service does not exist, it will run at the next boot. WinRM certificate (MAIN)classcloudbaseinit.plugins.windows.winrmcertificateauth.ConfigWinRMCertificateAuthPluginEnables password-less authentication for remote management via WinRS or PowerShell. Usually uses x509 embedded with UPN certificates. Config options: username (string: “Admin”) Notes Requires support in the metadata service. The metadata service must provide the certificate metadata. The admin user password needs to be present, either from the metadata, either as shared data set by running CreateUserPlugin or SetUserPasswordPlugin. The metadata service can provide the username. If the metadata service provides the admin username, it will override the username configuration value. How to use this feature: http://www.cloudbase.it/windows-without-passwords-in-openstack/ Local Scripts execution (MAIN)classcloudbaseinit.plugins.common.localscripts.LocalScriptsPluginExecutes any script (powershell, batch, python etc.) located in the following path indicated by local_scripts_path option. More details about the supported scripts and content can be found in Tutorial on file execution subject. Config options: local_scripts_path (string: None) Notes: May require a system restart. May run at every boot. It depends on the exit codes of the scripts. Licensing (MAIN)classcloudbaseinit.plugins.windows.licensing.WindowsLicensingPluginActivates the Windows instance if the activate_windows option is True. If set_kms_product_key or set_avma_product_key are set, it will use that KMS or AVMA product key in Windows. If kms_host is set, it will set the provided host as the KMS licensing server. Config options: activate_windows (bool: False)set_kms_product_key (bool: False)set_avma_product_key (bool: False)kms_host (string: None)log_licensing_info (bool: True) Notes: The metadata service can provide the KMS host, overriding the configuration option kms_host. The metadata service can provide the avma_product_key, overriding the configuration option set_avma_product_key. Clock synchronization (PRE_NETWORKING)classcloudbaseinit.plugins.windows.ntpclient.NTPClientPluginApplies NTP client info based on the DHCP server options, if available. This behavior is enabled only when the ntp_use_dhcp_config option is set to True (which by default is False). If real_time_clock_utc is set to True, it will set the real time clock to use universal time. If set to False, it will set the real time clock to use the local time. Config options: ntp_use_dhcp_config (bool: False)real_time_clock_utc (bool: False)ntp_enable_service (bool: True) Notes: May require a reboot. May run at every boot. MTU customization (PRE_METADATA_DISCOVERY)classcloudbaseinit.plugins.common.mtu.MTUPluginSets the network interfaces MTU based on the value provided by the DHCP server options, if available and enabled (by default is True). This is particularly useful for cases in which a lower MTU value is required for networking (e.g. OpenStack GRE Neutron Open vSwitch configurations). Config options: mtu_use_dhcp_config (bool: True) Notes: Runs at every boot. User data (MAIN)classcloudbaseinit.plugins.common.userdata.UserDataPluginExecutes custom scripts provided by user data metadata as plain text or compressed with Gzip. More details, examples and possible formats here: Userdata. Trim Config (MAIN)classcloudbaseinit.plugins.common.trim.TrimConfigPluginEnables or disables TRIM delete notifications for the underlying storage device. Config options: trim_enabled (bool: False) San Policy Config (MAIN)classcloudbaseinit.plugins.windows.sanpolicy.SANPolicyPluginIf not None, the SAN policy is set to the given value of the configuration option san_policy. The possible values are: OnlineAll, OfflineAll or OfflineShared. Config options: san_policy (string: None) RDP Settings Config (MAIN)classcloudbaseinit.plugins.windows.rdp.RDPSettingsPluginSets the registry key KeepAliveEnable, to enable or disable the RDP keep alive functionality. Config options: rdp_set_keepalive (bool: False) RDP Post Certificate Thumbprint (MAIN)classcloudbaseinit.plugins.windows.rdp.RDPPostCertificateThumbprintPluginPosts the RDP certificate thumbprint to the metadata service endpoint. Notes: Requires support in the metadata service. The metadata service should expose an HTTP endpoint where the certificate thumbprint can be posted. Page Files (MAIN)classcloudbaseinit.plugins.windows.pagefiles.PageFilesPluginSets custom page files according to the config options. Config options: page_file_volume_labels (array: [])page_file_volume_mount_points (array: []) Notes: May require a reboot. If the page file is configured, a reboot is required. Runs at every boot. Display Idle Timeout Config (MAIN)classcloudbaseinit.plugins.windows.displayidletimeout.DisplayIdleTimeoutConfigPluginSets the idle timeout, in seconds, before powering off the display. Set 0 to leave the display always on. Config options: display_idle_timeout (int: 0) Boot Status Policy Config (MAIN)classcloudbaseinit.plugins.windows.bootconfig.BootStatusPolicyPluginSets the Windows BCD boot status policy according to the config option. When set, the only possible value for bcd_boot_status_policy is ignoreallfailures. Config options: bcd_boot_status_policy (string: None) BCD Config (MAIN)classcloudbaseinit.plugins.windows.bootconfig.BCDConfigPluginA unique disk ID is needed to avoid disk signature collisions. This plugin resets the boot disk id and enables auto-recovery in the BCD store. Config options: set_unique_boot_disk_id (bool: False)bcd_enable_auto_recovery (bool: False) Ephemeral Disk Config (MAIN)classcloudbaseinit.plugins.common.ephemeraldisk.EphemeralDiskPluginSets the ephemeral disk data loss warning file. On public clouds like Azure, the ephemeral disk should contain a read only file with data loss warning text, that warns the user to not use the ephemeral disk as a persistent storage disk. Config options: ephemeral_disk_volume_label (string: None)ephemeral_disk_volume_mount_point (string: None)ephemeral_disk_data_loss_warning_path (string: None) Notes: Requires support in the metadata service. The metadata service should provide the disk data loss warning text. Windows Auto Updates (MAIN)classcloudbaseinit.plugins.windows.updates.WindowsAutoUpdatesPluginEnables automatic Windows updates based on the user configuration or the metadata service information. The metadata service setting takes priority over the configuration option. Config options: enable_automatic_updates (bool: False) Notes: If the metadata service provides the information needed to enable the automatic updates, it will override the enable_automatic_updates configuration value. Server Certificates (MAIN)classcloudbaseinit.plugins.windows.certificates.ServerCertificatesPluginImports X509 certificates into the desired store location. The metadata service provides the certificate and key in a PFX archive, their store location and store name. Notes: Requires support in the metadata service. Azure Guest Agent (MAIN)classcloudbaseinit.plugins.windows.azureguestagent.AzureGuestAgentPluginInstalls Azure Guest agent, which is required for the Azure cloud platform. Notes: Requires support in the metadata service. Azure metadata service should provide the agent package provisioning data. UserdataUserdataThe userdata is the user custom content exposed to the guest instance by the currently deployed and running cloud infrastructure. Its purpose is to provide additional data for the instance to customize it as much as you need, if the cloud initialization service does support this feature. Fortunately, cloudbase-init is able to interpret and use this kind of user specific data in multiple ways. In most of the cases, the thing that indicates of what type is the processed data is usually the first line. Currently supported contents: PEM certificate—–BEGIN CERTIFICATE—– This one should start with a PEM specific beginning header, which will be eventually parsed by the configuration drive and web API OpenStack services and used by the WinRM certificate (MAIN) plugin for storing and using it. Batchrem cmd The file is executed in a cmd.exe shell (can be changed with the COMSPEC environment variable). PowerShell**** #ps1 or #ps1_sysnative (system native) #ps1_x86 (Windows On Windows 32bit) Execute PowerShell scripts using the desired executable. For finding out more about the system nativeness thing, click here. Bash #!/bin/bash A bash shell needs to be installed in the system and available in the PATH in order to use this feature. Python #!/usr/bin/env python Python is available by default with the build itself, but also it must be in the system PATH. EC2 formatThere is no “first line” here, but the content should follow a XML pattern with valid Batch/PowerShell script contents under script or powershell enclosing tags like in this example: 12345678910&lt;script&gt;set root=%SystemDrive%echo ec2dir&gt;%root%\ec2file.txt&lt;/script&gt;&lt;powershell&gt;$root = $env:SystemDrive$dname = Get-Content "$root\ec2file.txt"New-Item -path "$root\$dname" -type directory&lt;/powershell&gt; Note http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/UsingConfig_WinAMI.html Cloud config #cloud-config Cloud-config YAML configuration as supported by cloud-init, excluding Linux specific content. The following cloud-config directives are supported: write_files - Defines a set of files which will be created on the local filesystem. It can be a list of items or only one item, with the following attributes: path - Absolute path on disk where the content should be written.content - The content which will be written in the given file.permissions - Integer representing file permissions.encoding - The encoding of the data in content. Supported encodings are: b64, base64 for base64-encoded content, gz, gzip for gzip encoded content, gz+b64, gz+base64, gzip+b64, gzip+base64 for base64 encoded gzip content. Examples: 123456789101112131415161718192021#cloud-configwrite_files: encoding: b64 content: NDI= path: C:\test permissions: '0o466'#cloud-configwrite_files: - encoding: b64 content: NDI= path: C:\b64 permissions: '0644' - encoding: base64 content: NDI= path: C:\b64_1 permissions: '0644' - encoding: gzip content: !!binary | H4sIAGUfoFQC/zMxAgCIsCQyAgAAAA== path: C:\gzip permissions: '0644' set_timezone - Change the underlying timezone. Example: 12#cloud-configset_timezone: Asia/Tbilisi set_hostname - Override the already default set hostname value (taken from metadata). If the hostname is changed, a reboot will be required. Example: 12#cloud-configset_hostname: newhostname groups - Create local groups and add existing users to those local groups. The definition of the groups consists of a list in the format: : [, ] The list of users can be empty, when creating a group without members. Example: 123groups: - windows-group: [user1, user2] - cloud-users users - Create and configure local users. The users are defined as a list. Each element from the list represents a user. Each user can have the the following attributes defined: name - The username (required string).gecos - the user description.primary_group - the user’s primary group.groups - the user’s groups. On Windows, primary_group and groups are concatenated.passwd - the user’s password. On Linux, the password is a hashed string, whereas on Windows the password is a plaintext string. If the password is not defined, a random password will be set.inactive - boolean value, defaults to False. If set to True, the user will be disabled.expiredate - a string in the format --. Example: 2020-10-01.ssh_authorized_keys - a list of SSH public keys, that will be set in ~/.ssh/authorized_keys. Example: 1234567891011121314users: - name: Admin - name: brian gecos: 'Brian Cohen' primary_group: Users groups: cloud-users passwd: StrongPassw0rd inactive: False expiredate: 2020-10-01 ssh_authorized_keys: - ssh-rsa AAAB...byV - ssh-rsa AAAB...ctV ntp - Set NTP servers. The definition is a dict with the following attributes: enabled - Boolean value, defaults to True, to enable or disable the NTP config.servers - A list of NTP servers.pools - A list of NTP pools. The servers and pools are aggregated, servers being the first ones in the list. On Windows, there is no difference between an NTP pool or server. Example: 12345#cloud-configntp: enabled: True servers: ['my.ntp.server.local', '192.168.23.2'] pools: ['0.company.pool.ntp.org', '1.company.pool.ntp.org'] runcmd - Directive that can contain a list of commands that will be executed, in the order of their definition. A command can be defined as a string or as a list of strings, the first one being the executable path. On Windows, the commands are aggregated into a file and executed with cmd.exe. The userdata exit codes can be used to request a reboot: File execution. Example: 1234#cloud-configruncmd: - 'dir C:\\' - ['echo', '1'] The cloud-config directives are executed by default in the following order: write_files, set_timezone, set_hostname, ntp, groups, users, runcmd. Use config option cloud_config_plugins to filter or to change the order of the cloud config plugins. The execution of set_hostname or runcmd can request a reboot if needed. The reboot is performed at the end of the cloud-config execution (after all the directives have been executed). Multi-part contentMIME multi-part user data is supported. The content will be handled based on the content type. text/x-shellscript - Any script to be executed: PowerShell, Batch, Bash or Python. text/part-handler - A script that can manage other content type parts. This is used in particular by Heat / CFN templates, although Linux specific. text/x-cfninitdata - Heat / CFN content. Written to the path provided by heat_config_dir option which defaults to “C:\cfn”. (examples of Heat Windows templates) SysnativenessWhen deciding which path to use for system executable files… On 32bit OSes, the return value will be the System32 directory, which contains 32bit programs. On 64bit OSes, the return value may be different, depending on the Python bits and the sysnative parameter. If the Python interpreter is 32bit, the return value will be System32 (containing 32bit programs) if sysnative is set to False and Sysnative otherwise. But if the Python interpreter is 64bit and sysnative is False, the return value will be SysWOW64 and System32 for a True value of sysnative. Why this behavior and what is the purpose of sysnative parameter? On a 32bit OS the things are clear, there is one System32 directory containing 32bit applications and that’s all. On a 64bit OS, there’s a System32 directory containing 64bit applications and a compatibility one named SysWOW64 (WindowsOnWindows) containing the 32bit version of them. Depending on the Python interpreter’s bits, the sysnative flag will try to bring the appropriate version of the system directory, more exactly, the physical System32 or SysWOW64 found on disk. On a WOW case (32bit interpreter on 64bit OS), a return value of System32 will point to the physical SysWOW64 directory and a return value of Sysnative, which is consolidated by the existence of this alias, will point to the real physical System32 directory found on disk. If the OS is still 64bit and there is no WOW case (that means the interpreter is 64bit), the system native concept is out of discussion and each return value will point to the physical location it intends to. On a 32bit OS the sysnative parameter has no meaning, but on a 64bit one, based on its value, it will provide a real/alias path pointing to system native applications if set to True (64bit programs) and to system compatibility applications if set to False (32bit programs). Its purpose is to provide the correct system paths by taking into account the Python interpreter bits too, because on a 32bit interpreter version, System32 is not the same with the System32 on a 64bit interpreter. Also, using a 64bit interpreter, the Sysnative alias will not work, but the sysnative parameter will take care to return SysWOW64 if you explicitly want 32bit applications, by setting it to False. Configuration options referenceThe following is an overview of all available configuration options in cloudbase-init. DEFAULTdebugTypeboolean DefaultFalse MutableThis option can be changed without restarting. If set to true, the logging level will be set to DEBUG instead of the default INFO level. log_config_appendTypestring Default MutableThis option can be changed without restarting. The name of a logging configuration file. This file is appended to any existing logging configuration files. For details about logging configuration files, see the Python logging module documentation. Note that when logging configuration files are used then all logging configuration is set in the configuration file and other logging configuration options are ignored (for example, log-date-format). Deprecated VariationsGroup Name DEFAULT log-config DEFAULT log_config log_date_formatTypestring Default%Y-%m-%d %H:%M:%S Defines the format string for %(asctime)s in log records. Default: the value above . This option is ignored if log_config_append is set. log_fileTypestring Default (Optional) Name of log file to send logging output to. If no default is set, logging will go to stderr as defined by use_stderr. This option is ignored if log_config_append is set. Deprecated VariationsGroup Name DEFAULT logfile log_dirTypestring Default (Optional) The base directory used for relative log_file paths. This option is ignored if log_config_append is set. Deprecated VariationsGroup Name DEFAULT logdir watch_log_fileTypeboolean DefaultFalse Uses logging handler designed to watch file system. When log file is moved or removed this handler will open a new log file with specified path instantaneously. It makes sense only if log_file option is specified and Linux platform is used. This option is ignored if log_config_append is set. use_syslogTypeboolean DefaultFalse Use syslog for logging. Existing syslog format is DEPRECATED and will be changed later to honor RFC5424. This option is ignored if log_config_append is set. use_journalTypeboolean DefaultFalse Enable journald for logging. If running in a systemd environment you may wish to enable journal support. Doing so will use the journal native protocol which includes structured metadata in addition to log messages.This option is ignored if log_config_append is set. syslog_log_facilityTypestring DefaultLOG_USER Syslog facility to receive log lines. This option is ignored if log_config_append is set. use_jsonTypeboolean DefaultFalse Use JSON formatting for logging. This option is ignored if log_config_append is set. use_stderrTypeboolean DefaultFalse Log output to standard error. This option is ignored if log_config_append is set. use_eventlogTypeboolean DefaultFalse Log output to Windows Event Log. log_rotate_intervalTypeinteger Default1 The amount of time before the log files are rotated. This option is ignored unless log_rotation_type is setto “interval”. log_rotate_interval_typeTypestring Defaultdays Valid ValuesSeconds, Minutes, Hours, Days, Weekday, Midnight Rotation interval type. The time of the last file change (or the time when the service was started) is used when scheduling the next rotation. max_logfile_countTypeinteger Default30 Maximum number of rotated log files. max_logfile_size_mbTypeinteger Default200 Log file maximum size in MB. This option is ignored if “log_rotation_type” is not set to “size”. log_rotation_typeTypestring Defaultnone Valid Valuesinterval, size, none Log rotation type. Possible values intervalRotate logs at predefined time intervals. sizeRotate logs once they reach a predefined size. noneDo not rotate log files. logging_context_format_stringTypestring Default%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s Format string to use for log messages with context. Used by oslo_log.formatters.ContextFormatter logging_default_format_stringTypestring Default%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s Format string to use for log messages when context is undefined. Used by oslo_log.formatters.ContextFormatter logging_debug_format_suffixTypestring Default%(funcName)s %(pathname)s:%(lineno)d Additional data to append to log message when logging level for the message is DEBUG. Used by oslo_log.formatters.ContextFormatter logging_exception_prefixTypestring Default%(asctime)s.%(msecs)03d %(process)d ERROR %(name)s %(instance)s Prefix each line of exception output with this format. Used by oslo_log.formatters.ContextFormatter logging_user_identity_formatTypestring Default%(user)s %(tenant)s %(domain)s %(user_domain)s %(project_domain)s Defines the format string for %(user_identity)s that is used in logging_context_format_string. Used by oslo_log.formatters.ContextFormatter default_log_levelsTypelist Default[‘amqp=WARN’, ‘amqplib=WARN’, ‘boto=WARN’, ‘qpid=WARN’, ‘sqlalchemy=WARN’, ‘suds=INFO’, ‘oslo.messaging=INFO’, ‘oslo_messaging=INFO’, ‘iso8601=WARN’, ‘requests.packages.urllib3.connectionpool=WARN’, ‘urllib3.connectionpool=WARN’, ‘websocket=WARN’, ‘requests.packages.urllib3.util.retry=WARN’, ‘urllib3.util.retry=WARN’, ‘keystonemiddleware=WARN’, ‘routes.middleware=WARN’, ‘stevedore=WARN’, ‘taskflow=WARN’, ‘keystoneauth=WARN’, ‘oslo.cache=INFO’, ‘oslo_policy=INFO’, ‘dogpile.core.dogpile=INFO’] List of package logging levels in logger=LEVEL pairs. This option is ignored if log_config_append is set. publish_errorsTypeboolean DefaultFalse Enables or disables publication of error events. instance_formatTypestring Default“[instance: %(uuid)s] “ The format for an instance that is passed with the log message. instance_uuid_formatTypestring Default“[instance: %(uuid)s] “ The format for an instance UUID that is passed with the log message. rate_limit_intervalTypeinteger Default0 Interval, number of seconds, of log rate limiting. rate_limit_burstTypeinteger Default0 Maximum number of logged messages per rate_limit_interval. rate_limit_except_levelTypestring DefaultCRITICAL Log level name used by rate limiting: CRITICAL, ERROR, INFO, WARNING, DEBUG or empty string. Logs with level greater or equal to rate_limit_except_level are not filtered. An empty string means that all levels are filtered. fatal_deprecationsTypeboolean DefaultFalse Enables or disables fatal status of deprecations. allow_rebootTypeboolean DefaultTrue Allows OS reboots requested by plugins stop_service_on_exitTypeboolean DefaultTrue In case of execution as a service, specifies if the service must be gracefully stopped before exiting check_latest_versionTypeboolean DefaultFalse Check if there is a newer version of cloudbase-init available. If this option is activated, a log message will be emitted if there is a newer version available. retry_countTypeinteger Default5 Max. number of attempts for fetching metadata in case of transient errors retry_count_intervalTypefloating point Default4 Interval between attempts in case of transient errors, expressed in seconds mtools_pathTypestring Default Path to “mtools” program suite, used for interacting with VFAT filesystems bsdtar_pathTypestring Defaultbsdtar.exe Path to “bsdtar”, used to extract ISO ConfigDrive files netbios_host_name_compatibilityTypeboolean DefaultTrue Truncates the hostname to 15 characters for Netbios compatibility logging_serial_port_settingsTypestring Default Serial port logging settings. Format: “port,baudrate,parity,bytesize”, e.g.: “COM1,115200,N,8”. Set to None (default) to disable. activate_windowsTypeboolean DefaultFalse Activates Windows automatically set_kms_product_keyTypeboolean DefaultFalse Sets the KMS product key for this operating system set_avma_product_keyTypeboolean DefaultFalse Sets the AVMA product key for this operating system kms_hostTypestring Default The KMS host address in form [:], e.g: “kmshost:1688” log_licensing_infoTypeboolean DefaultTrue Logs the operating system licensing information winrm_enable_basic_authTypeboolean DefaultTrue Enables basic authentication for the WinRM HTTPS listener winrm_configure_http_listenerTypeboolean DefaultFalse Configures the WinRM HTTP listener winrm_configure_https_listenerTypeboolean DefaultTrue Configures the WinRM HTTPS listener volumes_to_extendTypelist Default List of volumes that need to be extended if contiguous space is available on the disk. By default all the available volumes can be extended. Volumes must be specified using a comma separated list of volume indexes, e.g.: “1,2” san_policyTypestring Default Valid ValuesOnlineAll, OfflineAll, OfflineShared If not None, the SAN policy is set to the given value local_scripts_pathTypestring Default Path location containing scripts to be executed when the plugin runs mtu_use_dhcp_configTypeboolean DefaultTrue Configures the network interfaces MTU based on the values provided via DHCP usernameTypestring DefaultAdmin User to be added to the system or updated if already existing groupsTypelist Default[‘Administrators’] List of local groups to which the user specified in “username” will be added rename_admin_userTypeboolean DefaultFalse Renames the builtin admin user instead of creating a new user heat_config_dirTypestring DefaultC:\cfn The directory where the Heat configuration files must be saved ntp_enable_serviceTypeboolean DefaultTrue Enables the NTP client service ntp_use_dhcp_configTypeboolean DefaultFalse Configures NTP client time synchronization using the NTP servers provided via DHCP real_time_clock_utcTypeboolean DefaultFalse Sets the real time clock to use universal time (True) or local time (False) inject_user_passwordTypeboolean DefaultTrue Set the password provided in the configuration. If False or no password is provided, a random one will be set first_logon_behaviourTypestring Defaultclear_text_injected_only Valid Valuesclear_text_injected_only, no, always Control the behaviour of what happens at next logon. If this option is set to always, then the user will be forced to change the password at next logon. If it is set to clear_text_injected_only, then the user will have to change the password only if the password is a clear text password, coming from the metadata. The last option is no, when the user is never forced to change the password. metadata_servicesTypelist Default[‘cloudbaseinit.metadata.services.httpservice.HttpService’, ‘cloudbaseinit.metadata.services.configdrive.ConfigDriveService’, ‘cloudbaseinit.metadata.services.ec2service.EC2Service’, ‘cloudbaseinit.metadata.services.maasservice.MaaSHttpService’, ‘cloudbaseinit.metadata.services.cloudstack.CloudStack’, ‘cloudbaseinit.metadata.services.opennebulaservice.OpenNebulaService’] List of enabled metadata service classes, to be tested for availability in the provided order. The first available service will be used to retrieve metadata pluginsTypelist Default[‘cloudbaseinit.plugins.common.mtu.MTUPlugin’, ‘cloudbaseinit.plugins.windows.ntpclient.NTPClientPlugin’, ‘cloudbaseinit.plugins.common.sethostname.SetHostNamePlugin’, ‘cloudbaseinit.plugins.windows.createuser.CreateUserPlugin’, ‘cloudbaseinit.plugins.common.networkconfig.NetworkConfigPlugin’, ‘cloudbaseinit.plugins.windows.licensing.WindowsLicensingPlugin’, ‘cloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPlugin’, ‘cloudbaseinit.plugins.windows.extendvolumes.ExtendVolumesPlugin’, ‘cloudbaseinit.plugins.common.userdata.UserDataPlugin’, ‘cloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPlugin’, ‘cloudbaseinit.plugins.windows.winrmlistener.ConfigWinRMListenerPlugin’, ‘cloudbaseinit.plugins.windows.winrmcertificateauth.ConfigWinRMCertificateAuthPlugin’, ‘cloudbaseinit.plugins.common.localscripts.LocalScriptsPlugin’] List of enabled plugin classes, to be executed in the provided order user_data_pluginsTypelist Default[‘cloudbaseinit.plugins.common.userdataplugins.parthandler.PartHandlerPlugin’, ‘cloudbaseinit.plugins.common.userdataplugins.cloudconfig.CloudConfigPlugin’, ‘cloudbaseinit.plugins.common.userdataplugins.cloudboothook.CloudBootHookPlugin’, ‘cloudbaseinit.plugins.common.userdataplugins.shellscript.ShellScriptPlugin’, ‘cloudbaseinit.plugins.common.userdataplugins.multipartmixed.MultipartMixedPlugin’, ‘cloudbaseinit.plugins.common.userdataplugins.heat.HeatPlugin’] List of enabled userdata content plugins cloud_config_pluginsTypelist Default[] List which contains the name of the cloud config plugins ordered by priority. rdp_set_keepaliveTypeboolean DefaultTrue Sets the RDP KeepAlive policy bcd_boot_status_policyTypestring Default Valid Valuesignoreallfailures Sets the Windows BCD boot status policy bcd_enable_auto_recoveryTypeboolean DefaultFalse Enables or disables the BCD auto recovery set_unique_boot_disk_idTypeboolean DefaultTrue Sets a new random unique id on the boot disk to avoid collisions display_idle_timeoutTypeinteger Default0 The idle timeout, in seconds, before powering off the display. Set 0 to leave the display always on page_file_volume_labelsTypelist Default[] Labels of volumes on which a Windows page file needs to be created. E.g.: “Temporary Storage” page_file_volume_mount_pointsTypelist Default[] Volume mount points on which a Windows page file needs to be created. E.g.: “?GLOBALROOTdeviceHarddisk1Partition1” trim_enabledTypeboolean DefaultFalse Enables or disables TRIM delete notifications for the underlying storage device. process_userdataTypeboolean DefaultTrue Processes the userdata content based on the type, e.g. executing a PowerShell script userdata_save_pathTypestring Default Copies the userdata to the given file path. The path can include environment variables that will be expanded, e.g. “%SYSTEMDRIVE%CloudbaseInitUserData.bin” enable_automatic_updatesTypeboolean Default If set, enables or disables automatic operating system updates. metadata_report_provisioning_startedTypeboolean DefaultFalse Reports to the metadata service that provisioning has started metadata_report_provisioning_completedTypeboolean DefaultFalse Reports to the metadata service that provisioning completed successfully or failed ephemeral_disk_volume_labelTypestring Default Ephemeral disk volume label, e.g.: “Temporary Storage” ephemeral_disk_volume_mount_pointTypestring Default Ephemeral disk volume mount point, e.g.:”?GLOBALROOTdeviceHarddisk1Partition1” ephemeral_disk_data_loss_warning_pathTypestring Default Ephemeral disk data loss warning path, relative to the ephemeral disk volume path. E.g.: DATALOSS_WARNING_README.txt user_password_lengthTypeinteger Default20 The length of the generated password for the user defined by the username config option. azuretransport_cert_store_nameTypestring DefaultWindows Azure Environment Certificate store name for metadata certificates cloudstackmetadata_base_urlTypestring Defaulthttp://10.1.1.1/ The base URL where the service looks for metadata Deprecated VariationsGroup Name DEFAULT cloudstack_metadata_ip password_server_portTypeinteger Default8080 The port number used by the Password Server. https_allow_insecureTypeboolean DefaultFalse Whether to disable the validation of HTTPS certificates. https_ca_bundleTypestring Default The path to a CA_BUNDLE file or directory with certificates of trusted CAs. add_metadata_private_ip_routeTypeboolean DefaultFalse Add a route for the metadata ip address to the gateway config_driveraw_hddTypeboolean DefaultTrue Look for an ISO config drive in raw HDDs Deprecated VariationsGroup Name DEFAULT config_drive_raw_hhd Warning This option is deprecated for removal. Its value may be silently ignored in the future. cdromTypeboolean DefaultTrue Look for a config drive in the attached cdrom drives Deprecated VariationsGroup Name DEFAULT config_drive_cdrom Warning This option is deprecated for removal. Its value may be silently ignored in the future. vfatTypeboolean DefaultTrue Look for a config drive in VFAT filesystems Deprecated VariationsGroup Name DEFAULT config_drive_vfat Warning This option is deprecated for removal. Its value may be silently ignored in the future. typesTypelist Default[‘vfat’, ‘iso’] Supported formats of a configuration drive Deprecated VariationsGroup Name DEFAULT config_drive_types locationsTypelist Default[‘cdrom’, ‘hdd’, ‘partition’] Supported configuration drive locations Deprecated VariationsGroup Name DEFAULT config_drive_locations ec2metadata_base_urlTypestring Defaulthttp://169.254.169.254/ The base URL where the service looks for metadata Deprecated VariationsGroup Name DEFAULT ec2_metadata_base_url add_metadata_private_ip_routeTypeboolean DefaultTrue Add a route for the metadata ip address to the gateway Deprecated VariationsGroup Name DEFAULT ec2_add_metadata_private_ip_route https_allow_insecureTypeboolean DefaultFalse Whether to disable the validation of HTTPS certificates. https_ca_bundleTypestring Default The path to a CA_BUNDLE file or directory with certificates of trusted CAs. gcemetadata_base_urlTypestring Defaulthttp://metadata.google.internal/computeMetadata/v1/ The base URL where the service looks for metadata https_allow_insecureTypeboolean DefaultFalse Whether to disable the validation of HTTPS certificates. https_ca_bundleTypestring Default The path to a CA_BUNDLE file or directory with certificates of trusted CAs. maasmetadata_base_urlTypestring Default The base URL for MaaS metadata Deprecated VariationsGroup Name DEFAULT maas_metadata_url oauth_consumer_keyTypestring Default‘’ The MaaS OAuth consumer key Deprecated VariationsGroup Name DEFAULT maas_oauth_consumer_key oauth_consumer_secretTypestring Default‘’ The MaaS OAuth consumer secret Deprecated VariationsGroup Name DEFAULT maas_oauth_consumer_secret oauth_token_keyTypestring Default‘’ The MaaS OAuth token key Deprecated VariationsGroup Name DEFAULT maas_oauth_token_key oauth_token_secretTypestring Default‘’ The MaaS OAuth token secret Deprecated VariationsGroup Name DEFAULT maas_oauth_token_secret https_allow_insecureTypeboolean DefaultFalse Whether to disable the validation of HTTPS certificates. https_ca_bundleTypestring Default The path to a CA_BUNDLE file or directory with certificates of trusted CAs. openstackmetadata_base_urlTypestring Defaulthttp://169.254.169.254/ The base URL where the service looks for metadata Deprecated VariationsGroup Name DEFAULT metadata_base_url add_metadata_private_ip_routeTypeboolean DefaultTrue Add a route for the metadata ip address to the gateway Deprecated VariationsGroup Name DEFAULT add_metadata_private_ip_route https_allow_insecureTypeboolean DefaultFalse Whether to disable the validation of HTTPS certificates. https_ca_bundleTypestring Default The path to a CA_BUNDLE file or directory with certificates of trusted CAs. ovfconfig_file_nameTypestring Defaultovf-env.xml Configuration file name drive_labelTypestring DefaultOVF ENV Look for configuration file in drives with this label nsTypestring Defaultoe Namespace prefix for ovf environment packetmetadata_base_urlTypestring Defaulthttps://metadata.packet.net/ The URL where the service looks for metadata https_allow_insecureTypeboolean DefaultFalse Whether to disable the validation of HTTPS certificates. https_ca_bundleTypestring Default The path to a CA_BUNDLE file or directory with certificates of trusted CAs. vmwareguestinfovmware_rpctool_pathTypestring Default%ProgramFiles%/VMware/VMware Tools/rpctool.exe The local path where VMware rpctool is found]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络ISO七层模型图]]></title>
    <url>%2F2020%2F10%2F13%2FOther%2FISO7Module%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pfSense防火墙扩展磁盘大小]]></title>
    <url>%2F2020%2F10%2F10%2FLinux%2FpfsenseDisk%2F</url>
    <content type="text"><![CDATA[12345678910df -hgpart showsugpart resize -i 1 -s 38G -a 4k vtbd0gpart showgpart delete -i 2 vtbd0s1gpart resize -i 1 -s 47G -a 4k vtbd0s1gpart showgrowfs /dev/ufsid/5cde6f38370e9a3fdf -h 参考freebsd官方文档：https://www.freebsd.org/doc/handbook/disks-growing.html]]></content>
      <categories>
        <category>Firewall</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H3C S5130-EI系列以太网交换机典型配置-SSH典型配置]]></title>
    <url>%2F2020%2F10%2F09%2FSwitch%2Fh3cs5130ssh%2F</url>
    <content type="text"><![CDATA[配置步骤 生成 RSA 密钥对。123456789101112&lt;Device&gt; system-view [Device] public-key local create rsa The range of public key size is (512 ~ 2048). If the key modulus is greater than 512, it will take a few minutes. Press CTRL+C to abort. Input the modulus length [default = 1024]: Generating Keys... ........................++++++ ...................++++++ ..++++++++ ............++++++++ Create the key pair successfully. 生成 DSA 密钥对。12345678910[Device] public-key local create dsa The range of public key size is (512 ~ 2048). If the key modulus is greater than 512, it will take a few minutes. Press CTRL+C to abort. Input the modulus length [default = 1024]: Generating Keys... .++++++++++++++++++++++++++++++++++++++++++++++++++* ........+......+.....+......................................+ ...+.................+..........+...+. Create the key pair successfully. 使能 SSH 服务器功能。1[Device] ssh server enable 创建 VLAN 2，并将 GigabitEthernet1/0/2 加入 VLAN 2。123[Device] vlan 2 [Device-vlan2] port gigabitethernet 1/0/2 [Device-vlan2] quit 配置 VLAN 接口 2 的 IP 地址，客户端将通过该地址连接 Stelnet 服务器。123[Device] interface vlan-interface 2 [Device-Vlan-interface2] ip address 192.168.1.40 255.255.255.0 [Device-Vlan-interface2] quit 设置 Stelnet 客户端登录用户界面的认证方式为 scheme。123[Device] line vty 0 63 [Device-line-vty0-63] authentication-mode scheme [Device-line-vty0-63] quit 创建本地用户 client001，并设置用户密码、服务类型和用户角色。123456[Device] local-user client001 class manage New local user added. [Device-luser-manage-client001] password simple aabbcc [Device-luser-manage-client001] service-type ssh [Device-luser-manage-client001] authorization-attribute user-role network-admin [Device-luser-manage-client001] quit 验证配置打开PuTTY.exe程序，点击“Session”功能区• 在“Host Name（or IP address）”文本框中输入 Stelnet 服务器的 IP 地址为 192.168.1.40。• 在“Port”文本框中输入 SSH 协议端口号 22。• 在“Connection type”区域选择 SSH 协议。]]></content>
      <categories>
        <category>Switch</category>
      </categories>
      <tags>
        <tag>switch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows禁用/重新启用笔记本电脑自带键盘]]></title>
    <url>%2F2020%2F10%2F09%2FOther%2FWindowsDisableKeyboard%2F</url>
    <content type="text"><![CDATA[禁用：123管理员身份运行cmd输入 sc config i8042prt start= disabled 回车重启电脑生效 重新启用：123管理员身份运行cmd输入 sc config i8042prt start= auto 回车重启电脑生效]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Docker pull镜像速度过慢的问题]]></title>
    <url>%2F2020%2F07%2F06%2FDocker%2FdockerProxy%2F</url>
    <content type="text"><![CDATA[目前，Docker拥有中国的官方镜像，具体内容可访问https://www.docker-cn.com/registry-mirror 在使用时，Docker 中国官方镜像加速可通过 registry.docker-cn.com访问。该镜像库只包含流行的公有镜像。私有镜像仍需要从美国镜像库中拉取。 您可以使用以下命令直接从该镜像加速地址进行拉取： $ docker pull registry.docker-cn.com/myname/myrepo:mytag例如: $ docker pull registry.docker-cn.com/library/ubuntu:16.04注: 除非您修改了 Docker 守护进程的 --registry-mirror 参数 (见下文), 否则您将需要完整地指定官方镜像的名称。例如，library/ubuntu、library/redis、library/nginx。 使用 –registry-mirror 配置 Docker 守护进程您可以配置 Docker 守护进程默认使用 Docker 官方镜像加速。这样您可以默认通过官方镜像加速拉取镜像，而无需在每次拉取时指定 registry.docker-cn.com。 您可以在 Docker 守护进程启动时传入 –registry-mirror 参数： $ docker –registry-mirror=https://registry.docker-cn.com daemon为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。 123&#123; "registry-mirrors": ["https://registry.docker-cn.com"]&#125; 修改保存后重启 Docker 以使配置生效。 1systemctl restart docker 注: 您也可以使用适用于 Mac 的 Docker 和适用于 Windows 的 Docker 来进行设置。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7部署dzzoffice私有网盘]]></title>
    <url>%2F2020%2F07%2F06%2FOther%2Fdzzoffice%2F</url>
    <content type="text"><![CDATA[搭建Lamp框架(Linux+apache+mariadb+php)1.首先安装wget 1yum install -y wget 2.下载epel额外包及YUM源配置 12wget https://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-7 #epel额外包的密钥wget https://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm #epel额外包的yum的配置 3.导入密钥，为了防止安装错误，安装yum的配置文件 12rpm --import RPM-GPG-KEY-EPEL-7 #导入epel额外包的密钥rpm -ivh epel-release-latest-7.noarch.rpm #安装epel额外包的yum配置 4.安装升级php，作为依赖httpd都安装好了，apache(httpd)和php就安装好了 1234567891011121314yum install -y php php-mysql #升级php的软件包 php x86_64 7.3.4-1.el7.remi php 3.2 M为依赖而安装: libargon2 x86_64 20161029-3.el7 epel 23 k apr x86_64 1.4.8-3.el7_4.1 centos 103 k apr-util x86_64 1.5.2-6.el7 centos 92 k httpd x86_64 2.4.6-88.el7.centos centos 2.7 M httpd-tools x86_64 2.4.6-88.el7.centos centos 90 k mailcap noarch 2.1.41-2.el7 centos 31 k php-cli x86_64 7.3.4-1.el7.remi php 4.9 M php-common x86_64 7.3.4-1.el7.remi php 1.1 M php-json x86_64 7.3.4-1.el7.remi php 63 k——————————— 5.安装mariadb数据库 1yum -y install mariadb mariadb-server #安装mariadb数据库 6.关闭防火墙服务及关机selinux 1234systemctl stop firewalldsystemctl disable firewalldsetenforce 0vim /etc/selinux/config -&gt; disabled 7.开启mariadb和httpd,设置开机自动启动；执行脚本，设置mariadb数据库参数 1234567891011121314151617181920212223[root@localhost ~]# systemctl start mariadb #开启mariadb[root@localhost ~]# systemctl start httpd #开启httpd[root@localhost ~]# systemctl enable mariadb #设置开机自动开启mariadb[root@localhost ~]# systemctl enable httpd #设置开机自动开启httpdmysql_secure_installation #执行脚本...#省略部分内容Set root password? [Y/n] yNew password: 123456Re-enter new password: 123456Password updated successfully!Reload privilege tables now? [Y/n] y ... Success!Disallow root login remotely? [Y/n] n ... skipping.Remove test database and access to it? [Y/n] y - Dropping test database... ... Success! - Removing privileges on test database... ... Success!Reload privilege tables now? [Y/n] y ... Success! 安装dzzoffice1.下载最新稳定版本，我现在是2.02为最新版 1wget https://github.com/zyx0814/dzzoffice/archive/2.02.tar.gz 2.解压文件 1tar -zxvf 2.02.tar.gz 3.将解压后的文件移动到apache的目录下，并改名为dzzoffice 1mv dzzoffice-2.02 /var/www/html/dzzoffice 4.然后将目录权限授权给apache启动用户，默认为apache用户，如果自己修改了，则以你修改的为准 12cd /var/www/html/chown -R apache. dzzoffice 5.启动apache 12systemctl start httpdsystemctl enable httpd # 设置开机启动apache 访问页面进行安装上一步已启动apache，现在可以直接访问你服务器的ip或域名，后跟dzzoffice的路径来来访问dzzoffice，访问如：http://ip/dzzoffice 会自动跳转到安装界面： 安装完成后，手动删除安装文件rm -rf /var/www/html/dzzoffice/install/index.php 安装onlyoffice插件dzzoffice本身不支持excel或者文档的在线浏览和编辑，需要额外的第三方工具进行支持，在官方文档中也有说明：http://dzzoffice.com/corpus/list?cid=3# 这里我现在安装onlyoffice作为在线文档服务器，部署方式，由于直接在服务器上部署比较繁琐，这里我直接使用docker部署docker版本。首先安装docker，然后用docker启动onlyoffice 1.删除旧版本，确保机器没有docker 12yum remove docker docker-client docker-client-latest docker-common \ docker-latest docker-latest-logrotate docker-logrotate docker-engine 2.安装依赖 1yum install -y yum-utils device-mapper-persistent-data lvm2 3.安装yum仓库 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 4.安装docker 1yum install docker-ce docker-ce-cli containerd.io 5.启动docker 12systemctl start dockersystemctl enable docker 6.启动onlyoffice，使用本地的8000端口 1docker run -i -t -d -p8000:80 --restart=always onlyoffice/documentserver 启动onlyoffice服务后，在浏览器中访问http://ip:8000查看是否可以正常使用，如果出现如下界面，则为正常 √ Document Server is running 12345678910请输入OnlyOffice Document Server API地址:http://DZZOFFICE_IP:8000填写您的onlyoffice Document Server API地址，如:http://192.168.0.2:90/ 根据你的文档服务器填写请输入文件服务器(dzzoffice服务器)地址:填写您的文件服务器地址，如:http://dzzoffice.com:90/,根据你的dzzoffice服务器地址填写,留空使用当前地址。tips:设置内网地址可以提高文件传输速度缩略图后缀列表:支持生成缩略图的后缀列表，用小写字母。多个用英文逗号隔开，如：pdf,doc,docx,ppt,pptx,xls,xlsx 点击保存，然后启动应用 然后在文档，excel应用中，就可以直接点击在线浏览和编辑啦。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Too many open files的四种解决办法]]></title>
    <url>%2F2020%2F06%2F01%2FLinux%2FTooManyOpenFiles%2F</url>
    <content type="text"><![CDATA[【摘要】Too many open files有四种可能: 一 单个进程打开文件句柄数过多 二 操作系统打开的文件句柄数过多 三 systemd对该进程进行了限制 四 inotify达到上限 单个进程打开文件句柄数过多ulimit中的nofile表示单进程可以打开的最大文件句柄数，可以通过ulimit -a查看，子进程默认继承父进程的限制（注意，是继承，不是共享，子进程和父进程打开的文件句柄数是单独算的）。 网上还有一种解读是nofile表示单用户可以打开的文件句柄数，因为他们在limit.conf中看到类似于”openstack soft nofile 65536”，便认为是openstack用户最多可以打开的文件句柄数。该解读是错误的，”openstack soft nofile 65536”表示的含义是当你执行”su - openstack”切换到openstack用户后，你创建的所有进程最大可以打开的文件句柄数是65536。要查看一个进程可以打开的文件句柄数，可以通过”cat /proc//limits”查看。 要修改ulimit中的nofile，可以通过修改/etc/security/limits.conf文件，在其中加入类似”openstack soft nofile 65536”的语句来进行修改。修改完成后，可以通过”su - openstack”切换用户，或者重新登录，来使该配置生效。 要动态修改一个进程的限制，可以使用prlimit命令，具体用法为：”prlimit –pid ${pid} –nofile=102400:102400”。 操作系统打开的文件句柄数过多整个操作系统可以打开的文件句柄数是有限的，受内核参数”fs.file-max”影响。 可以通过执行”echo 100000000 &gt; /proc/sys/fs/file-max”命令来动态修改该值，也可以通过修改”/etc/sysctl.conf”文件来永久修改该值。 systemd对该进程进行了限制该场景仅针对被systemd管理的进程（也就是可以通过systemctl来控制的进程）生效，可以通过修改该进程的service文件（通常在/etc/systemd/system/目录下），在”[Service]”下面添加”LimitNOFILE=20480000”来实现，修改完成之后需要执行”systemctl daemon-reload”来使该配置生效。 inotify达到上限inotify是linux提供的一种监控机制，可以监控文件系统的变化。该机制受到2个内核参数的影响：”fs.inotify.max_user_instances”和 “fs.inotify.max_user_watches”，其中”fs.inotify.max_user_instances”表示每个用户最多可以创建的inotify instances数量上限，“fs.inotify.max_user_watches”表示么个用户同时可以添加的watch数目，当出现too many open files问题而上面三种方法都无法解决时，可以尝试通过修改这2个内核参数来生效。修改方法是修改”/etc/sysctl.conf”文件，并执行”sysctl -p”。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF中Crypto题目的常见题型]]></title>
    <url>%2F2020%2F05%2F20%2FCTF%2FCTFCrypto%2F</url>
    <content type="text"><![CDATA[CTF中Crypto题目的常见题型 BugKu 提供了很多加解密工具，链接：http://tool.bugku.com/ SSL在线工具网址提供了很多工具，链接：http://www.ssleye.com/ text bin hex base64 dec 转码工具：https://conv.darkbyte.ru/ 1. 摩斯密码 / Morse编码摩尔斯电码(Morse code)是一种时通时断的信号代码，通过不同的排列 顺序来表达不同的英文字母、数字和标点符号。是由美国人艾尔菲德·维 尔(Alfred Lewis Vail)与萨缪尔·摩尔斯(Samuel Finley Breese Morse) 在1836年发明。由点（·）和划（-）组成。 特征：点和横的组合。 在线工具：http://www.zhongguosou.com/zonghe/moErSiCodeConverter.aspxhttp://tool.bugku.com/mosi/ 例如：-… -.- -.-. - ..-. – .. … -.-. 解密结果：BKCTFMISC –/—/.-./…/.解密结果：MORSE 2.ASCII编码ASCII(American Standard Code for Information Interchange，美国信息交换标准代码)是基于拉丁字母的一套 电脑编码系统，主要用于显示现代英语和其他西欧语言。它是现今最通用的单字节编码系统，并等同于国际标准ISO/IEC 646。 例如：72 105 65 115 99 105 105解密结果：H i A s c i i 特点：一般常用字符为0-9（48-57）、A-Z（65-90）、a-z（97-122）、空格（32） 在线工具：http://www.ab126.com/goju/1711.html 3.Tap Code敲击码敲击码(Tap code)是一种以非常简单的方式对文本信息进行 编码的方法。因该编码对信息通过使用一系列的点击声音来编 码而命名，敲击码是基于 5 ×5 方格波利比奥斯方阵来实现的， 不同点是是用 K 字母被整合到 C 中。 1 2 3 4 51 A B C/K D E2 F G H I J3 L M N O P4 Q R S T U5 V W X Y Z 例如：2,3 1,5 3,1 3,1 3,4.. …/. …../… ./… ./… …./解密结果：H E L L O ps. 当出现1,3时，对比C/K，选择更合适的结果 4.Base编码Base64是网络上最常见的用于传输8Bit字节码的编码方式之一，Base64 就是一种基于64(65)个可打印字符来表示二进制数据的方法。 a-z、A-Z、0-9、符号“+”、“/”（再加上作为补位的”=”，实际上是 65个字符） 。 Base xx 中的 xx 表示的是采用多少个字符进行编码，比如说 base64 就是采用 64 个字符编码，由于 2 的 6 次方等于 64，所以每 6 个比特 为一个单元，对应某个可打印字符。 例如：d2VsY29tZQ==解密结果：welcome 特点：base64 结尾可能会有=号，但最多有2个 。 base32 结尾可能会有=号,最多有 3 个等号。根据 base 的不同，字符集会有所限制 。 有可能需要自己加等号。 在线工具：http://tool.chinaz.com/tools/base64.aspx 5.URL编码URL编码,又叫百分号编码，是统一资源定位(URL)编码方式。URL地址（常说网址）规定了常用地数字，字母可以直接使用，另外一批作为特殊用户字符也可以直接用（/,:@等），剩下的其它所有字符必须通过%xx编码 处理。现在已经成为一种规范了，基本所有程序语言都有这种编码，如js： 有encodeURI、encodeURIComponent，PHP有urlencode、urldecode等。编 码方法很简单，在该字节ascii码的的16进制字符前面加%.如空格字符， ascii码是32，对应16进制是‘20’，那么urlencode编码结果是:%20。 例如：URL%E7%BC%96%E7%A0%81解密结果：URL编码 特点：存在大量的%在线工具：https://tool.oschina.net/encode?type=4 6.Unicode编码Unicode（统一码、万国码、单一码）是计算机科学领域里的一项业界 标准,包括字符集、编码方案等。Unicode是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。1990年开始研发，1994年正式公布。 例如：&#72;&#101;&#108;&#108;&#111;&#67;&#84;&#70;解密结果：HelloCTF在线工具：https://tool.oschina.net/encode 7.jsfuckJSFuck 可以让你只用6个字符 !+来编写 JavaScript 程序在线工具：https://www.bugku.com/tools/jsfuck/ 8.brainfuckBrainfuck 是一种极小化的计算机语言，按照”Turing complete(完整图灵机) “思想设计的语言，它的主要设计思路是:用最小的概念实现一种“简单”的语 言，BrainFXXk语言只有八种符号，所有的操作都由这八种符号 &gt; &lt; + - . , [ ] 的组合来完成。 例如：+++++ +++++ [-&gt;++ +++++ +++&lt;] &gt;++++ .—. +++++ ++..+ ++.&lt;+ +++++ ++[-&gt;—– —&lt;] &gt;—. &lt;++++ ++++[ -&gt;+++ +++++ &lt;]&gt;++ +++++ ++++. —– —.+++.– —-. —– —.&lt; 解密结果：hello,world在线工具：https://www.splitbrain.org/services/ook 9.凯撒密码凯撒密码（Caesar）加密时会将明文中的每个字母都按照其在字母表中的顺序向后（或向前）移动固定数目（循环移动）作为密文。例如，当偏移量是左移 3 的时候（解密时 的密钥就是 3）。使用时，加密者查找明文字母表中需要加密的消息中的每一个字母所在位置，并且写下密文字母表中对应的字母。需要解密的人则根据事先已知的密钥反过来操作，得到原来的明文。 根据偏移量的不同，还存在若干特定的恺撒密码名称：偏移量为 10：Avocat （A→K）偏移量为 13：ROT13偏移量为 -5：Cassis （K 6）偏移量为 -6：Cassette （K 7） 例如：Uryyb,Jrypbzr解密结果：Hello,Welcome在线工具：http://www.mxcz.net/tools/rot13.aspx 10.栅栏密码特征：大小写和字符，其实就是分组替换加密 例如：一只小羊翻过了2个栅栏 KYsd3js2E{a2jda} 解密结果：KEY{sad23jjdsa2}在线工具：http://tool.bugku.com/jiemi/ 11.Ook 密码特征：Brainfuck 类型密码，密文由 Ook 和 三种标点 . ! ? 构成，不见得都得用上，有的是Ook，有的没有Ook只有标点。 在线工具：https://tool.bugku.com/brainfuck/ 12.类栅栏密码特征：会给你一串乱序的密文 C，同时给你从1 到 n 的一串乱序的数，找下 C 对于 n 的最大公约数，然后将他们重新排序。动手画一画就出来了 BugKu中的一道题：lf5{ag024c483549d7fd@@1} ， 一张纸条上凌乱的写着2 1 6 5 3 4 2 1 6 5 3 4l f 5 { a g0 2 4 c 4 83 5 4 9 d 7f d @ @ 1 }再按照123456的顺序数从第一行排到最后一行 flag{52048c453d794df1}@@ 提交 flag发现不对，这两个@@有点奇怪，去掉@就成功了，那么一般这种字符都是迷惑人的。 13.由0和1组成的摩斯密码特征：密文由0和1构成，可能由空格、tab或则其他字符分割，去掉这些分割后，0和1的总数是5的倍数将 0 和 1 替换为 . 或 - ，多试几次就可能有发现。 BugKu中的一道题： 0010 0100 01 110 1111011 11 11111 010 000 0 001101 1010 111 100 0 001101 01111 000 001101 00 10 1 0 010 0 000 1 01111 10 11110 101011 1111101 把0换成点 . 1换成 - 后：..-. .-.. .- –. —-.– – —– .-. … . ..–.- -.-. — -.. . ..–.- .—- … ..–.- .. -. - . .-. . … - .—- -. —-. -.-.– —–.-在线工具解密一下，得到： FLAG%u7bM0RSE_CODE_1S_INTEREST1N9!%u7d 结果有点奇怪，但八九不离十了。把%u7b 换成 { 把%u7d 换成 }，然后大小写切换 flag{m0rse_code_1s_interest1n9!} 14.键盘格子密码特征：由三到四个英文字母或数字为一组。 在键盘上找对应的键位，中间围起来的就是密文（这能能想得出。。。） 例如：r5yG lp9I BjM tFhBT6uh y7iJ QsZ bhM解密结果：t o n g y u a n 15.托马斯杰斐逊 转轮密码特征：给你一个密码表，n行的26个字母，key是 1 - n 的数列， 密文是 n 个英文字母根据 key 找对应行的密码表，然后在密码表上找密文字母，以这个字母为开头，重新排序。1： &lt;ZWAXJGDLUBVIQHKYPNTCRMOSFE &lt; 2： &lt;KPBELNACZDTRXMJQOYHGVSFUWI &lt; 3： &lt;BDMAIZVRNSJUWFHTEQGYXPLOCK &lt; 4： &lt;RPLNDVHGFCUKTEBSXQYIZMJWAO &lt; 5： &lt;IHFRLABEUOTSGJVDKCPMNZQWXY &lt; 6： &lt;AMKGHIWPNYCJBFZDRUSLOQXVET &lt; 7： &lt;GWTHSPYBXIZULVKMRAFDCEONJQ &lt; 8： &lt;NOZUTWDCVRJLXKISEFAPMYGHBQ &lt; 9： &lt;QWATDSRFHENYVUBMCOIKZGJXPL &lt; 10： &lt;WABMCXPLTDSRJQZGOIKFHENYVU &lt; 11： &lt;XPLTDAOIKFZGHENYSRUBMCQWVJ &lt; 12： &lt;TDSWAYXPLVUBOIKZGJRFHENMCQ &lt; 13： &lt;BMCSRFHLTDENQWAOXPYVUIKZGJ &lt; 14： &lt;XPHKZGJTDSENYVUBMLAOIRFCQW &lt; 密钥： 2,5,1,3,6,4,9,7,8,14,10,13,11,12密文：HCBTSXWCRQGL ES 在第 2 行密码表中找H开头的字母，然后以H开头再到尾过一遍，以此类推，整理出另一个密码表： HGVSFUWIKPBELNACZDTR X MJQOYCPMNZQWXYIHFRLABEUOT S GJVDKBVIQHKYPNTCRMOSFEZWA X JGDLUTEQGYXPLOCKBDMAIZVRN S JUWFHSLOQXVETAMKGHIWPNYCJ B FZDRUXQYIZMJWAORPLNDVHGFC U KTEBSWATDSRFHENYVUBMCOIKZ G JXPLQCEONJQGWTHSPYBXIZULV K MRAFDRJLXKISEFAPMYGHBQNOZ U TWDCVQWXPHKZGJTDSENYVUBML A OIRFCGOIKFHENYVUWABMCXPLT D SRJQZLTDENQWAOXPYVUIKZGJB M CSRFHENYSRUBMCQWVJXPLTDAO I KFZGHSWAYXPLVUBOIKZGJRFHE N MCQTD 然后在这里找一些比较明显的（语句通顺的）话，就是flag。 XSXSBUGKUADMIN提交不对的话就大小写换一下：xsxsbugkuadmin 这个其实可以写个程序出来，遍历密码表即可。 1234567891011121314151617181920212223242526272829303132333435363738# Rotor cipher decoder# parameter inputrotor = [ "ZWAXJGDLUBVIQHKYPNTCRMOSFE", "KPBELNACZDTRXMJQOYHGVSFUWI", "BDMAIZVRNSJUWFHTEQGYXPLOCK", "RPLNDVHGFCUKTEBSXQYIZMJWAO", "IHFRLABEUOTSGJVDKCPMNZQWXY", "AMKGHIWPNYCJBFZDRUSLOQXVET", "GWTHSPYBXIZULVKMRAFDCEONJQ", "NOZUTWDCVRJLXKISEFAPMYGHBQ", "QWATDSRFHENYVUBMCOIKZGJXPL", "WABMCXPLTDSRJQZGOIKFHENYVU", "XPLTDAOIKFZGHENYSRUBMCQWVJ", "TDSWAYXPLVUBOIKZGJRFHENMCQ", "BMCSRFHLTDENQWAOXPYVUIKZGJ", "XPHKZGJTDSENYVUBMLAOIRFCQW"]cipher = "HCBTSXWCRQGLES"key = [2, 5, 1, 3, 6, 4, 9, 7, 8, 14, 10, 13, 11, 12]tmp_list=[]for i in range(0, len(rotor)): tmp="" k = key[i] - 1 for j in range(0, len(rotor[k])): if cipher[i] == rotor[k][j]: if j == 0: tmp=rotor[k] break else: tmp=rotor[k][j:] + rotor[k][0:j] break tmp_list.append(tmp)# print(tmp_list)message_list = []for i in range(0, len(tmp_list[i])): tmp = "" for j in range(0, len(tmp_list)): tmp += tmp_list[j][i] message_list.append(tmp)print(message_list) 16.Base91编码特征：基本上是键盘上所有可打印的 ASC II 字符 1（0x21-0x7E），A-Z、a-z、1 - 9、 !@#$%^&amp;*()_+-=&#123;&#125;[]|\:;"'&lt;,&gt;.?/~· 之类的。 参考： http://base91.sourceforge.net/ （里面有工具源码）在线工具：http://ctf.ssleye.com/base91.html 17.Linux系统的 shadow 文件格式特征：就是Linux的shadow文件格式工具：Kali Linux 中的 Johnroot:$6$HRMJoyGA$26FIgg6CU0bGUOfqFB0Qo9AE2LRZxG8N3H.3BK8t49wGlYbkFbxVFtGOZqVIq3qQ6k0oetDbn2aVzdhuVQ6US.:17770:0:99999:7:::Linux的 /etc/shadow 文件存储了该系统下所有用户口令相关信息，只有 root 权限可以查看，用户口令是以 Hash + Salt 的形式保护的。每个字段都用 “$” 或“:”符号分割；第一个字段是用户名，如root ；第二个字段是哈希算法，比如 6 代表SHA-512，1 代表 MD5；第三个字段是盐，比如上面的 HRMJoyGA第四个字段是口令+盐加密后的哈希值后面分别是密码最后一次修改日期、密码的两次修改间隔时间（和第三个字段相比）、密码的有效期(和第三个字段相比）、密码修改到期前的警告天数（和第五个字段相比）、密码过期后的宽限天数（和第五个字段相比）、账号失效时间，这里不太重要要； 直接跑 John 试试john shadow如果解开了，加 –show 查看解密口令john –show shadow 18.ZIP 伪加密特征：一个ZIP压缩包，建议先读一下Zip文件解析与利用，里面提到：一格zip文件有三个部分组成：压缩源文件数据区 + 压缩源文件目录区 + 压缩源文件目录结束标志；每一部分都由明文 PK （50 4B）开始；这是三个头标记，主要看第二个；压缩源文件数据区：50 4B 03 04：这是头文件标记压缩源文件目录区：50 4B 01 02：目录中文件文件头标记后面两位（如 1F 00 或 3F 00）：压缩使用的 pkware 版本再后面两位（如 14 00）：解压文件所需 pkware 版本再后面两位：全局方式位标记（有无加密，这个更改这里进行伪加密，00 00 是无密码，改为09 00打开就会提示有密码了）压缩源文件目录结束标志 ：50 4B 05 06：目录结束标记工具：ZipCenOp.jar 或 WinHexe.g. BugKu 上的一道题 https://ctf.bugku.com/challenges#zip%E4%BC%AA%E5%8A%A0%E5%AF%86 使用 ZipCenOp.jar链接：https://pan.baidu.com/s/1yDcWWhY0lSlBArEJ4S6qUw提取码：g3it（需要java环境）windows下在cmd中输入：java -jar ZipCenOp.jar r xxx.zip 直接破解ZIP包； 使用 WinHex我们用winhex打开压缩包，搜索504B，点击第二个504B，从后面找第七、八位，发现是 09 00，改为 00 00 即可。这种方式只适用于ZIP的伪加密，真加密了此方法不适用。 19.RSA 加解密特征：给一些 RSA 算法的参数，然后加密\解密消息获取 flag。说一下 RSA 算法模式：分三部分，密钥生成、加密、解密：a) 密钥生成 1) 选取两个长度为 K 的素数 P 和 Q，计算 N = P * Q； 2) 计算 phi(N) = (P-1) * (Q-1)， 其中 phi(N) 是 Z_(N^*) 的阶； 3) 随机选取一个int整数 e ∈ [ 1, phi(N) - 1 ]，使得 gcd( e, phi(N)) = 1； 4) 计算它的逆 d，使得 [ e * d mod phi(N) ] = 1； 5) 输出私钥和公钥 sk = ( N, d ), pk = ( N, e )；b) 加密 c = m^e mod(N)c) 解密 m = c^d mod(N)工具：RsaCtfTool （用于输出RSA参数） libnum （用于密文的计算）具体参考Bugku-加密-rsa(WriteUp) 20.仿射密码 affine cipher特征：可能会提示你是放射密码 affine，公式： y = k * x + b mod 26 （跟一元一次函数似的）后面的取模，如果都是英文字母的话是26，不排除有其他形式，比如ASC II 什么的，取模可能会换。 工具：python代码 12345678910111213141516# Q: y = 17x-8 flag&#123;szzyfimhyzd&#125;flag = "szzyfimhyzd"flaglist = []for i in flag: flaglist.append(ord(i)-97)flags = ""for i in flaglist: for j in range(0,26): c = (17 * j - 8) % 26 if(c == i): flags += chr(j+97)print('flag&#123;'+ flags + '&#125;') 21.进制转换特征：二进制 b开头，八进制 o开头，十进制 d开头，十六进制 x开头 BugKu里的一道题：d87 x65 x6c x63 o157 d109 o145 b100000 d116 b1101111 o40 x6b b1100101 b1101100 o141 d105 x62 d101 b1101001 d46 o40 d71 x69 d118 x65 x20 b1111001 o157 b1110101 d32 o141 d32 d102 o154 x61 x67 b100000 o141 d115 b100000 b1100001 d32 x67 o151 x66 d116 b101110 b100000 d32 d102 d108 d97 o147 d123 x31 b1100101 b110100 d98 d102 b111000 d49 b1100001 d54 b110011 x39 o64 o144 o145 d53 x61 b1100010 b1100011 o60 d48 o65 b1100001 x63 b110110 d101 o63 b111001 d97 d51 o70 d55 b1100010 d125 x20 b101110 x20 b1001000 d97 d118 o145 x20 d97 o40 d103 d111 d111 x64 d32 o164 b1101001 x6d o145 x7e 12345678910111213141516171819202122232425262728s = 'd87 x65 x6c x63 o157 d109 o145 b100000 d116 b1101111 o40 x6b b1100101 b1101100 o141 d105 x62 d101 b1101001 d46 o40 d71 x69 d118 x65 x20 b1111001 o157 b1110101 d32 o141 d32 d102 o154 x61 x67 b100000 o141 d115 b100000 b1100001 d32 x67 o151 x66 d116 b101110 b100000 d32 d102 d108 d97 o147 d123 x31 b1100101 b110100 d98 d102 b111000 d49 b1100001 d54 b110011 x39 o64 o144 o145 d53 x61 b1100010 b1100011 o60 d48 o65 b1100001 x63 b110110 d101 o63 b111001 d97 d51 o70 d55 b1100010 d125 x20 b101110 x20 b1001000 d97 d118 o145 x20 d97 o40 d103 d111 d111 x64 d32 o164 b1101001 x6d o145 x7e'ss = s.split()sss = []print(ss)for i in ss: if i[0] == 'd': i = i[1:] i = int(i,10) i = chr(i) sss.append(i) elif i[0] == 'x': i = i[1:] i = int(i,16) i = chr(i) sss.append(i) elif i[0] == 'o': i = i[1:] i = int(i,8) i = chr(i) sss.append(i) elif i[0] == 'b': i = i[1:] i = int(i,2) i = chr(i) sss.append(i)print(sss)flag = ''.join(sss)print(flag)]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF中Reverse介绍]]></title>
    <url>%2F2020%2F05%2F20%2FCTF%2FCTFReverse%2F</url>
    <content type="text"><![CDATA[CTF中Reverse介绍什么是逆向？广义的逆向： 从目标代码反推源代码 从源代码理解开发者行为和目的 应用：软件破解、漏洞挖掘、恶意代码分析CTF逆向-侠义的逆向：与Crypto结合 CrackMe（破解密码，不修改程序） KeygenMe（生成注册码）与隐写取证结合 Recover（恢复文件）与Pwn结合 Reverse（interface，struct，format，protocol） Bypass auth，Patch bin逆向的基本流程 程序预处理，去混淆合过反调试 代码逆向，找到验证函数 验证函数逆向，找到验证算法 破解验证算法，得到flag 其中，80%的题目都与crypto结合，通过找到一个key过掉所有关卡。同时可能有一量与恢复文件有关。 逆向的核心逆向的核心是破解验证算法（过算法关）验证算法简化如下： 输入：key 验证： 12345if H(key) == Secret:&#123; flag = O(key); print flag;&#125; 输出：flag验证算法分类： 简单比较验证 密码算法验证 算法求解验证 也就是说，想成为一个优秀的逆向手，你要成为一个优秀的码农，算法大佬。 算法举例：算法1 key直接比较算法2 key简单变换算法3 key编码转换算法4 key散列计算算法5 key密钥加密算法6 key算法求解算法7 flag直接输出算法8 密钥空间过短算法9 伪随机算法 -&gt; 爆破 验证算法逆向思路简单变换验证： 人工逆向，找到可逆运算，按位分步破解（算法1-3）密码算法验证： 识别密码算法（有限），针对性解密（算法4-5）解题算法验证： 理解算法原理，针对性解题（算法6）验证常见漏洞： 直接输出flag（算法7） 密钥空间过短（算法8） 伪随机算法（算法9）现实竞赛： 分段、嵌套验证爆破神技： 简单验证（按位破解） 密码算法（密钥部分已知） 解题算法（暴力搜索） 双刃剑（100亿次以内，位数与取值都有关） 逆向的基础逆向的基础是理解目标代码（过语言关）必备知识 汇编，C语言 操作系统原理与核心编程，程序加载 反汇编与调试等常用工具 1.PE与ELF编辑、帧壳、脱壳工具 O1Oeditor、winhex peid、upx、resource hacker sysinternals 2.反汇编与反编译工具 IDA Pro、Hopper 3.调试器 OBydbg、gdb、windbg分析方法 静态分析方法：反汇编、反编译 动态分析方法：调试、模拟]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF中Web题目的常见题型及解题技巧]]></title>
    <url>%2F2020%2F05%2F19%2FCTF%2FCTFWeb%2F</url>
    <content type="text"><![CDATA[基础知识类题目考察基本的查看网页源代码、HTTP请求、修改页面元素等。 这些题很简单，比较难的比赛应该不会单独出，就算有应该也是Web的签到题。 实际做题的时候基本都是和其他更复杂的知识结合起来出现。 查看网页源代码按F12就都看到了，flag一般都在注释里，有时候注释里也会有一条hint或者是对解题有用的信息。 Bugku web2: http://123.206.87.240:8002/web2/ Bugku web3: http://123.206.87.240:8002/web3/ 发送HTTP请求可以用hackbar，有的也可以写脚本。 Bugku web基础$_GET: http://123.206.87.240:8002/get/ Bugku web基础$_POST: http://123.206.87.240:8002/post/ Bugku 点击一百万次: http://123.206.87.240:9001/test/ 举个写脚本的例子，（题目是Bugku web基础$POST）： 123import requestsr = requests.post('http://123.206.87.240:8002/post/', data=&#123;'what' : 'flag'&#125;)print(r.text) 不常见类型的请求发送考OPTIONS请求，如果要发送这类请求，写一个脚本应该就能解决了。 HTTP头相关的题目主要是查看和修改HTTP头。 目前做过的Web题目有很大一部分都是与HTTP头相关的，而且这种题目也相当常见，不和其他知识结合的情况下也算是属于基础题的范畴吧。 技巧：不同的类型有不同的利用方法，基本都离不开抓包改包，有些简单的也可以利用浏览器F12的网络标签解决。 但是最根本的应对策略，是熟悉一些常见请求头的格式、作用等，这样题目考到的时候就很容易知道要怎样做了。 查看响应头有时候响应头里会有hint或者题目的关键信息，也有的时候会直接把flag放在响应头里给你，但是直接查看响应头拿flag的题目并不多，因为太简单了。 只是查看的话，可以不用抓包，用F12的“网络”标签就可以解决了。 Bugku 头等舱: http://123.206.87.240:9009/hd.php 修改请求头、伪造Cookie常见的有set-cookie、XFF和Referer，总之考法很灵活，做法比较固定，知道一些常见的请求头再根据题目随机应变就没问题了。 有些题目还需要伪造Cookie，根据题目要求做就行了。 可以用BurpSuite抓包，也可以直接在浏览器的F12“网络”标签里改。 实验吧 头有点大： http://ctf5.shiyanbar.com/sHeader/ Bugku 程序员本地网站： http://123.206.87.240:8002/localhost/ Bugku 管理员系统： http://123.206.31.85:1003/ XCTF xff_referer： https://adworld.xctf.org.cn/task/answer?type=web&amp;number=3&amp;grade=0&amp;id=5068 Git源码泄露flag一般在源码的某个文件里，但也有和其他知识结合、需要进一步利用的情况，比如XCTF社区的mfw这道题。 技巧：GitHack一把梭 XCTF mfw: https://adworld.xctf.org.cn/task/answer?type=web&amp;number=3&amp;grade=1&amp;id=5002 Python爬虫信息处理这类题目一般都是给一个页面，页面中有算式或者是一些数字，要求在很短的时间内求出结果并提交，如果结果正确就可以返回flag。 因为所给时间一般都很短而且计算比较复杂，所以只能写脚本。这种题目的脚本一般都需要用到requests库和BeautifulSoup库（或者re库（正则表达式）），个人感觉使用BeautifulSoup简单一些。 技巧：requests库和BeautifulSoup库熟练掌握后，再多做几道题或者写几个爬虫的项目，一般这类题目就没有什么问题了。主要还是对BeautifulSoup的熟练掌握，另外还需要一点点web前端（HTML）的知识。 Bugku 秋名山老司机： http://123.206.87.240:8002/qiumingshan/ 1234567891011121314151617#这道题的脚本如下，还可以继续优化#经常出现执行了但是不弹flag的情况，多试几次就行了from bs4 import BeautifulSoupimport requestsr = requests.Session()s = r.get("http://123.206.87.240:8002/qiumingshan/")s.encoding = 'utf-8'text = s.textsoup = BeautifulSoup(text)tag = soup.divexpress = str(tag.string)express = express[0 : -3]answer = eval(express)ans = &#123;"value" : answer&#125;flag = r.post('http://123.206.87.240:8002/qiumingshan/', data = ans)print(flag.text) 实验吧 速度爆破： http://www.shiyanbar.com/ctf/1841HGAME2019的部分题目似乎还出现了反爬虫措施。 PHP代码审计代码审计覆盖面特别广，分类也很多，而且几乎什么样的比赛都会有，算是比较重要的题目类型之一吧。 技巧：具体问题具体分析，归根结底还是要熟练掌握PHP这门语言，了解一些常见的会造成漏洞的函数及利用方法等。 hash加密相关PHP弱类型hash比较缺陷这是代码审计最基础的题目了，也比较常见。 典型代码： 123if(md5($a) == md5($b)) &#123; //注意两个等号“==” echo $flag;&#125; 加密函数也有可能是sha1或者其他的，但是原理都是不变的。 这个漏洞的原理如下： 12== 在进行比较的时候，会先将两边的变量类型转化成相同的，再进行比较。0e在比较的时候会将其视作为科学计数法，所以无论0e后面是什么，0的多少次方还是0。 所以只要让b在经过相应的函数加密之后都是以0e开头就可以。 以下是一些md5加密后开头为0e的字符串： 12345678910111213141516171819202122232425QNKCDZO0e830400451993494058024219903391s878926199a0e545993274517709034328855841020s155964671a0e342768416822451524974117254469s214587387a0e848240448830537924465865611904s214587387a0e848240448830537924465865611904s878926199a0e545993274517709034328855841020s1091221200a0e940624217856561557816327384675s1885207154a0e509367213418206700842008763514aabg7XSs 另外，这个也可以用数组绕过，这个方法在下面会详细说。 数组返回NULL绕过PHP绝大多数函数无法处理数组，向md5函数传入数组类型的参数会使md5()函数返回NULL（转换后为False），进而绕过某些限制。 如果上面的代码变成： 123if(md5($a) === md5($b)) &#123; //两个等号变成三个 echo $flag;&#125; 那么利用弱类型hash比较缺陷将无法绕过，这时可以使用数组绕过。 传入?a[]=1&amp;b[]=2就可以成功绕过判断。 这样的方法也可以用来绕过sha1()等hash加密函数相关的判断，也可以绕过正则判断，可以根据具体情况来灵活运用。 正则表达式相关ereg正则%00截断ereg函数存在NULL截断漏洞，使用NULL可以截断过滤，所以可以使用%00截断正则匹配。 Bugku ereg正则%00截断：http://123.206.87.240:9009/5.php 数组绕过正则表达式相关的函数也可以使用数组绕过过滤，绕过方法详见数组返回NULL绕过。 上面那道题也可以用数组绕过。 单引号绕过preg_match()正则匹配在每一个字符前加上单引号可以绕过preg_match的匹配，原理暂时不明。 例如有如下代码： 1234567891011&lt;?php $p = $_GET['p']; if (preg_match('/[0-9a-zA-Z]&#123;2&#125;/',$p) === 1) &#123; echo 'False'; &#125; else &#123; $pp = trim(base64_decode($p)); if ($pp === 'flag.php') &#123; echo 'success'; &#125; &#125;?&gt; 1payload：p='Z'm'x'h'Z'y'5'w'a'H'A'= 不含数字与字母的WebShell如果题目使用preg_match()过滤掉了所有的数字和字母，但是没有过滤PHP的变量符号$，可以考虑使用这种方法。 典型代码： 123456789101112131415161718&lt;?phpinclude'flag.php';if(isset($_GET['code']))&#123; $code=$_GET['code']; if(strlen($code)&gt;50)&#123; die("Too Long."); &#125; if(preg_match("/[A-Za-z0-9_]+/",$code))&#123; die("Not Allowed."); &#125; @eval($code);&#125;else&#123; highlight_file(__FILE__);&#125;//$hint = "php function getFlag() to get flag";?&gt; 这种方法的核心是字符串的异或操作。 爆破脚本： 123456chr1 = ['@', '!', '"', '#', '$', '%', '&amp;', '\'', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '&lt;', '=', '&gt;', '?', '[', '\\', ']', '^', '_', '`', '&#123;', '|', '&#125;', '~']chr2 = ['@', '!', '"', '#', '$', '%', '&amp;', '\'', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '&lt;', '=', '&gt;', '?', '[', '\\', ']', '^', '_', '`', '&#123;', '|', '&#125;', '~']for i in chr1 : for j in chr2 : print(i + 'xor' + j + '=' + (chr(ord(i) ^ ord(j)))) 根据题目的要求，用异或出来的字符串拼出合适的Payload，并放在PHP变量中执行。变量名可以用中文。 比如这道题的 1Payload：?code=$啊="@@^|@@@"^"'%*:,!'";$啊(); Linux通配符绕过正则匹配典型代码如下，与前一种题目非常相似，但也不大一样： 12345678910111213141516&lt;?phpif(isset($_GET['code']))&#123; $code=$_GET['code']; if(strlen($code)&gt;50)&#123; die("Too Long."); &#125; if(preg_match("/[A-Za-z0-9_$]+/",$code))&#123; die("Not Allowed."); &#125; @eval($code);&#125;else&#123; highlight_file(__FILE__);&#125;//flag in /?&gt; 最主要的区别就是过滤了$和_，也就是说无法使用变量符号$了。 这时候可以考虑采用通配符绕过。 通配符有点像正则表达式，有自己的匹配规则： | 字符 | 解释 || * | 匹配任意长度任意字符 || ? | 匹配任意单个字符 || [list] | 匹配指定范围内(list)任意单个字符，也可以是单个字符组成的集合 || [^list] | 匹配指定范围外的任意单个字符或字符集合 || [!list] | 同[^list] || {str1,str2,…} | 匹配str1或者str2或者更多字符串，也可以是集合 | 所以构造一下通配符就是 1/???/??? /* 因为过滤了变量符号，没法通过上面那种方法来执行了。但是，可以通过闭合PHP标记来执行，也就是：?&gt;（/bin/cat /*）。 所以本题的 1payload为：?code=?&gt;&lt;?=/???/??? /*?&gt; 具体解法可以参照此篇文章的前两道题目：https://www.jianshu.com/p/ecc2414ec110 命令执行漏洞assert()函数引起的命令执行assert函数的参数为字符串时，会将字符串当做PHP命令来执行。 例如：assert(‘phpinfo()’)相当于执行 以一道题目为例： 本题目中题目文件夹下放置了一个隐藏的flag文件。 1234567891011121314&lt;?phperror_reporting(0);if (isset($_GET['file'])) &#123; if($_GET['file'] === "flag")&#123; highlight_file("flag.php"); &#125;else&#123; $page = $_GET['file']; &#125;&#125; else &#123; $page = "./flag.php";&#125;assert("file_exists('$page')");?&gt; 解法： 构造闭合 file_exists()函数，并使assert()执行恶意代码。 Linux命令ls -a可用于查看该目录下所有文件，包括隐藏文件。 123payload：?file=123') or system('ls -a');#?file=123') or system('cat .ffll44gg');# XSS题目这类题目会涉及到三种XSS类型，具体类型要根据题目来判断。一般都是向后台发送一个带有XSS Payload的文本，在返回的Cookie中含有flag，解法是在XSS Payload。 这类题目一般都会带有过滤和各种限制，需要了解一些常用的绕过方法。 技巧：XSS归根结底还是JavaScript，JavaScript的威力有多大，XSS的威力就有多大。要知道一些常用的XSS Payload，还要把三类XSS的原理弄明白。做题时需要用到XSS平台，网上有公用的，也可以自己在VPS上搭一个。 JavisOJ babyxss：http://web.jarvisoj.com:32800/ 绕过waf其实绝大多数比较难的题目多多少都会对输入有过滤，毕竟在现实的网络中肯定是会对输入进行限制的，但是这里还是把过滤单独列出来了。 技巧：多掌握一些不同的绕过方法。 长度限制有些题目会要求输入较长的文本，但对文本的长度进行了限制。 对于这种题目，既可以用BurpSuite抓包改包绕过，也可以直接在F12里改页面源代码。 Bugku 计算器（修改页面源代码）：http://123.206.87.240:8002/yanzhengma/ DVWA 存储型XSS的标题栏会对长度进行限制，使用BurpSuite抓包绕过。 双写双写可以绕过对输入内容过滤的单次判断，在XSS、SQL注入和PHP代码审计的题目中比较常见。 双写顾名思义就是将被过滤的关键字符写两遍，比如，如果要添加XSS Payload，又需要插入script标签，就可以构造如下的 12Payload：&lt;scr&lt;script&gt;ipt&gt;` 来绕过对script标签的单次过滤限制。 这样的方法不仅对XSS有用，也可以用于代码审计和SQL注入。 HGAME2019有一道XSS题目就是过滤了script标签，可以用双写绕过。 等价替代就是不用被过滤的字符，而使用没有被过滤却会产生相同效果的字符。 比如，如果SQL注入题目中过滤了空格，可以用 1/**/ 绕过对空格的限制；XSS题目如果过滤了script标签，可以使用其他类型的 1payload；如果需要使用cat命令却被过滤，可以使用tac、more、less命令来替代等。 实验吧 简单的SQL注入：http://www.shiyanbar.com/ctf/1875 URL编码绕过如果过滤了某个必须要用的字符串，输入的内容是以GET方式获取的（也就是直接在地址栏中输入），可以采用url编码绕过的方式。比如，过滤了 cat，可以使用 c%61t来绕过。 Linux命令使用反斜杠绕过在Linux下，命令中加入反斜杠与原命令完全等价。例如，cat与 ca\t两条命令等价，效果完全相同。 可以利用这个特性来进行一些绕过操作（当然，这个仅限于命令执行漏洞）。 URL二次解码绕过这个类型本来应该放在代码审计里面，但是既然是一种绕过过滤的姿势，就写在这里了。 如果源码中出现了urldecode()函数，可以利用url二次解码来绕过。 以下是一些常用的HTML URL编码： | ASCII Value | URL-encode | ASCII Value | URL-encode | ASCII Value | URL-encode || æ | %00 | 0 | %30 | ` | %60 || | %01 | 1 | %31 | a | %61 || | %02 | 2 | %32 | b | %62 || | %03 | 3 | %33 | c | %63 || | %04 | 4 | %34 | d | %64 || | %05 | 5 | %35 | e | %65 || | %06 | 6 | %36 | f | %66 || | %07 | 7 | %37 | g | %67 || backspace | %08 | 8 | %38 | h | %68 || tab | %09 | 9 | %39 | i | %69 || linefeed | %0a | : | %3a | j | %6a || | %0b | ; | %3b | k | %6b || | %0c | &lt; | %3c | l | %6c || c return | %0d | = | %3d | m | %6d || | %0e | &gt; | %3e | n | %6e || | %0f | ? | %3f | o | %6f || | %10 | @ | %40 | p | %70 || | %11 | A | %41 | q | %71 || | %12 | B | %42 | r | %72 || | %13 | C | %43 | s | %73 || | %14 | D | %44 | t | %74 || | %15 | E | %45 | u | %75 || | %16 | F | %46 | v | %76 || | %17 | G | %47 | w | %77 || | %18 | H | %48 | x | %78 || | %19 | I | %49 | y | %79 || | %1a | J | %4a | z | %7a || | %1b | K | %4b | { | %7b || | %1c | L | %4c | | | %7c || | %1d | M | %4d | } | %7d || | %1e | N | %4e | ~ | %7e || | %1f | O | %4f | | %7f || space | %20 | P | %50 | € | %80 || ! | %21 | Q | %51 | | %81 || “ | %22 | R | %52 | ‚ | %82 || # | %23 | S | %53 | ƒ | %83 || $ | %24 | T | %54 | „ | %84 || % | %25 | U | %55 | … | %85 || &amp; | %26 | V | %56 | † | %86 || ‘ | %27 | W | %57 | ‡ | %87 || ( | %28 | X | %58 | ˆ | %88 || ) | %29 | Y | %59 | ‰ | %89 || * | %2a | Z | %5a | Š | %8a || + | %2b | [ | %5b | ‹ | %8b || , | %2c | \ | %5c | Œ | %8c || - | %2d | ] | %5d | | %8d || . | %2e | ^ | %5e | Ž | %8e || / | %2f | _ | %5f | | %8f | Bugku urldecode二次编码绕过：http://123.206.87.240:9009/10.php 数组绕过详见PHP代码审计的“数组返回NULL”绕过。 数组绕过的应用很广，很多题目都可以用数组绕过。 SQL注入SQL注入是一种灵活而复杂的攻击方式，归根结底还是考察对SQL语言的了解和根据输入不同数据网页的反应对后台语句的判断，当然也有sqlmap这样的自动化工具可以使用。 技巧：如果不用sqlmap或者是用不了，就一定要把SQL语言弄明白，sqlmap这样的自动化工具也可以使用。 使用sqlmapsqlmap的应用范围还不大明确，我都是如果sqlmap没法注入就手工注入。 sqlmap的使用：https://www.jianshu.com/p/4509bdf5e3d0 一些sqlmap的命令，留着备用：https://www.freebuf.com/sectool/164608.html 感觉这篇教程也不错：https://www.cnblogs.com/im404/p/3505894.html 命令合集：https://www.jianshu.com/p/fa77f2ed788b]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF常见的题型]]></title>
    <url>%2F2020%2F05%2F19%2FCTF%2FCTFType%2F</url>
    <content type="text"><![CDATA[CTF常见的题型CTF比赛通常包含的题目类型有七种，包括MISC、PPC、CRYPTO、PWN、REVERSE、WEB、STEGA。 1.MISC(Miscellaneous)√ 类型，即安全杂项，题目或涉及流量分析、电子取证、人肉搜索、数据分析等等。杂项介绍Miscellaneous简称MISC，意思是杂项，混杂的意思。杂项大致有几种类型： 1.隐写，包括图片/音频/视频/其他等 2.压缩包处理，包括zip/rar等 3.流量分析，包括协议/文件/usb/wifi等 4.攻击取证，包括日志分析/内存分析/文件镜像等 5.基础 6.其它处理方法： 1.查看文件类型： file、 010Editor 2.文件分离： Binwalk、 foremost、 dd、 010Editor 3.文件合并： linux环境、 windows环境、 python脚本 2.PPC(Professionally Program Coder)类型，即编程类题目，题目涉及到编程算法，相比ACM较为容易。 3.CRYPTO(Cryptography)√ 类型，即密码学，题目考察各种加解密技术，包括古典加密技术、现代加密技术甚至出题者自创加密技术。 Morse编码 ASCII编码 Tap Code敲击码 Base编码 URL编码 Unicode编码 凯撒密码 RSA 加解密 4.PWN√ 类型，PWN在黑客俚语中代表着攻破、取得权限，多为溢出类题目。 Pwn 是其中的一类重要题型，主要考查选手二进制逆向分析、漏洞挖掘以及 Exploit 编写的能力。 PWN是一个黑客语法的俚语词，自”own”这个字引申出来的，这个词的含意在于，玩家在整个游戏对战中处在胜利的优势，或是说明竞争对手处在完全惨败的 情形下，这个词习惯上在网络游戏文化主要用于嘲笑竞争对手在整个游戏对战中已经完全被击败（例如：”You just got pwned!”）。有一个非常著名的国际赛事叫做Pwn2Own，相信你现在已经能够理解这个名字的含义了，即通过打败对手来达到拥有的目的。 CTF中PWN题型通常会直接给定一个已经编译好的二进制程序（Windows下的EXE或者Linux下的ELF文件等），然后参赛选手通过对二进制程 序进行逆向分析和调试来找到利用漏洞，并编写利用代码，通过远程代码执行来达到溢出攻击的效果，最终拿到目标机器的shell夺取flag 5.REVERSE√ 类型，即逆向工程，题目涉及到软件逆向、破解技术。 通过Ollydbg/IDA Pro/PEiD等工具在逆向分析中的基本使用方法，并通过动态调试和静态分析两种方法来找到程序密码。 6.STEGA(Steganography)类型，即隐写术，题目的Flag会隐藏到图片、音频、视频等各类数据载体中供参赛者获取。 7.WEB√ 类型，即题目会涉及到常见的Web漏洞，诸如注入、XSS、文件包含、代码执行等漏洞。工具集 基础工具：Burpsuite，python，firefox(hackbar，foxyproxy，user-agent，swither等) 扫描工具：nmap，nessus，openvas sql注入工具：sqlmap等 xss平台：xssplatfrom，beef 文件上传工具：cknife 文件包含工具：LFlsuite 暴力破解工具：burp暴力破解模块，md5Crack，hydra 常用套路总结 直接查看网页源码，即可找到flag 查看http请求/响应，使用burp查看http头部信息，修改或添加http请求头（referer–来源伪造，x-forwarded-for–ip伪造，user-agent–用户浏览器，cookie–维持登陆状态，用户身份识别） web源码泄漏：vim源码泄漏(线上CTF常见)，如果发现页面上有提示vi或vim，说明存在swp文件泄漏，地址：/.index.php.swp或index.php~ 恢复文件 vim -r index.php。备份文件泄漏，地址：index.php.bak，www.zip，htdocs.zip，可以是zip，rar，tar.gz，7z等 .git源码泄漏，地址：http://www.xxx.com/.git/config，工具：GitHack，dvcs-ripper svn导致文件泄漏，地址：http://www/xxx/com/.svn/entries，工具：dvcs-ripper，seay-svn 编码和加解密，各类编码和加密，可以使用在线工具解密，解码 windows特性，短文件名，利用～字符猜解暴露短文件/文件夹名，如backup-81231sadasdasasfa.sql的长文件，其短文件是backup1.sql，iis解析漏洞，绕过文件上传检测 php弱类型 绕waf，大小写混合，使用编码，使用注释，使用空字节 当前我们环境中的题型为： 1.CRYPTO：字符串(可能很长) 或 上传一个文件 2.PWN：每一道题Docker container对外开放一个端口映射 3.MISC:全部为 上传一个文件 4.Reserve：全部为 上传一个文件 5.Web：每一道题Docker container对外开放一个端口映射]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>ctf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS 详解]]></title>
    <url>%2F2020%2F05%2F08%2FLinux%2FNFS%2F</url>
    <content type="text"><![CDATA[nfs客户端卡住问题碰到nfs客户端卡住的情况，umount -f /mnt提示device is busy，并且尝试访问挂载目录、df -h等操作都会使终端卡住，ctrl+c也不能强行退出。 造成这种现象的原因是nfs服务器/网络挂了，nfs客户端默认采用hard-mount选项，而不是soft-mount。他们的区别是soft-mount: 当客户端加载NFS不成功时，重试retrans设定的次数.如果retrans次都不成功，则放弃此操作，返回错误信息 “Connect time out”hard-mount: 当客户端加载NFS不成功时,一直重试，直到NFS服务器有响应。hard-mount 是系统的缺省值。在选定hard-mount 时，最好同时选 intr , 允许中断系统的调用请求，避免引起系统的挂起。当NFS服务器不能响应NFS客户端的 hard-mount请求时， NFS客户端会显示“NFS server hostname not responding, still trying” nfs参数介绍下面列出mount关于nfs相关的参数（1）-a：把/etc/fstab中列出的路径全部挂载。（2）-t：需要mount的类型，如nfs等。（3）-r：将mount的路径定为read only。（4）-v mount：过程的每一个操作都有message传回到屏幕上。（5）rsize=n：在NFS服务器读取文件时NFS使用的字节数，默认值是4096个字节。（6）wsize=n：向NFS服务器写文件时NFS使用的字节数，默认值是4096个字节。（7）timeo=n：从超时后到第1次重新传送占用的1/7秒的数目，默认值是7/7秒。（8）retry=n：在放弃后台mount操作之前可以尝试的次数，默认值是7 000次。（9）soft：使用软挂载的方式挂载系统，若Client的请求得不到回应，则重新请求并传回错误信息。（10）hard：使用硬挂载的方式挂载系统，该值是默认值，重复请求直到NFS服务器回应。（11）intr：允许NFS中断文件操作和向调用它的程序返回值，默认不允许文件操作被中断。（12）fg：一直在提示符下执行重复挂载。（13）bg：如果第1次挂载文件系统失败，继续在后台尝试执行挂载，默认值是失败后不在后台处理。（14）tcp：对文件系统的挂载使用TCP，而不是默认的UDP。 如#mount -t nfs -o soft 192.168.1.2:/home/nfs /mnt nfs传输尺寸至于传输尺寸的选择，可以进行实际测试：time dd if=/dev/zero of=/mnt/nfs.dat bs=16k count=16384即向nfs服务器上的nfs.dat文件里写入16384个16KB的块（也有经验说文件大小可以设定为nfs服务器内存的2倍）。得到输出如：输出了 16384+0 个块user 0m0.200s输出了 66535+0 个块user 0m0.420s192.168.1.4:/mnt /home/nfs nfs rsize=8192,wsize=8192,timeo=10,intr重新挂载nfs服务器，调整读写块大小后重复上述过程，可以找到最佳传输尺寸。 NFS服务器的故障排除故障排除思路:NFS出现了故障，可以从以下几个方面着手检查。（1）NFS客户机和服务器的负荷是否太高，服务器和客户端之间的网络是否正常。（2）/etc/exports文件的正确性。（3）必要时重新启动NFS或portmap服务。运行下列命令重新启动portmap和NFS：service portmap restartservice nfs start（4）检查客户端中的mount命令或/etc/fstab的语法是否正确。（5）查看内核是否支持NFS和RPC服务。普通的内核应有的选项为CONFIG_NFS_FS=m、CONFIG_NFS_V3=y、CONFIG_ NFSD=m、CONFIG_NFSD_V3=y和CONFIG_SUNRPC=m。我们可以使用常见的网络连接和测试工具ping及tracerroute来测试网络连接及速度是否正常，网络连接正常是NFS作用的基础。rpcinfo命令用于显示系统的RPC信息，一般使用-p参数列出某台主机的RPC服务。用rpcinfo-p命令检查服务器时，应该能看到portmapper、status、mountd nfs和nlockmgr。用该命令检查客户端时，应该至少能看到portmapper服务。 使用nfsstat命令查看NFS服务器状态nfsstat命令显示关于NFS和到内核的远程过程调用（RPC）接口的统计信息，也可以使用该命令重新初始化该信息。如果未给定标志，默认是nfsstat -csnr命令。使用该命令显示每条信息，但不能重新初始化任何信息。 nfsstat命令的主要参数如下。（1）-b：显示NFS V4服务器的其他统计信息。（2）c：只显示客户机端的NFS和RPC信息，允许用户仅查看客户机数据的报告。nfsstat命令提供关于被客户机发送和拒绝的RPC和NFS调用数目的信息。要只显示客户机NFS或者RPC信息，将该参数与-n或者-r参数结合。（3）-d：显示与NFS V4授权相关的信息。（4）-g：显示RPCSEC_GSS信息。（5）-m：显示每个NFS文件系统的统计信息，该文件系统和服务器名称、地址、安装标志、当前读和写大小，以及重新传输计数（6）-n：为客户机和服务器显示NFS信息。要只显示NFS客户机或服务器信息，将该参数与-c和-s参数结合。（7）-r：显示RPC信息。（8）-s：显示服务器信息。（9）-t：显示与NFS标识映射子系统的转换请求相关的统计信息，要只显示NFS客户机或服务器信息，将-c和-s选项结合。（10）-4：当与-c、-n、-s或-z参数组合使用时，将包含NFS V4客户机或服务器的信息，以及现有的NFS V2和V3数据。（11）-z：重新初始化统计信息。该参数仅供root用户使用，并且在显示上面的标志后可以和那些标志中的任何一个组合到统计信息的零特殊集合。 要显示关于客户机发送和拒绝的RPC和NFS调用数目的信息，输入：nfsstat -c要显示和打印与客户机NFS调用相关的信息，输入如下命令：nfsstat -cn要显示和打印客户机和服务器的与RPC调用相关的信息，输入如下命令：nfsstat -r要显示关于服务器接收和拒绝的RPC和NFS调用数目的信息，输入如下命令：nfsstat –s]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack凝思系统虚拟桌面鼠标漂移的问题]]></title>
    <url>%2F2020%2F05%2F06%2FOpenstack%2FOpenstackGraphicMouse%2F</url>
    <content type="text"><![CDATA[问题描述在OpenstackQueens环境下分别安装Windows，Kali及凝思图型界面操作系统，发现凝思操作系统出现鼠标漂移的问题。经调查，默认情况下有图型界面的实例使用的输入设备类型为usbtablet，Windows，Kali在usbtablet下没有问题，凝思操作系统鼠标漂移。凝思在使用ps2mouse下没有问题，而ps2mouse下Windows，Kali鼠标出现漂移。 解决办法镜像定制化:在制作除凝思操作系统的镜像时，使用定制属性: 1hw_pointer_model='usbtablet' 即使用glanceClient创建镜像时， 12glanceClient.images.create( name=imageName, container_format='bare', disk_format='qcow2', hw_pointer_model='usbtablet') 或者镜像创建后，修改镜像信息: 1glance image-update --property hw_pointer_model=usbtablet [IMAGE-ID] 然后在nova配置文件中[DEFAULT]中增加: 123[DEFAULT]...pointer_model=ps2mouse 更新后重启计算节点的Nova-compute服务: 1systemctl restart openstack-nova-compute.service 这时，使用hw_pointer_model属性的镜像默认仍使用镜像定制的usbtablet，而凝思系统则使用ps2mouse的输入方式。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack虚拟桌面协议SPICE代替vnc]]></title>
    <url>%2F2020%2F05%2F06%2FOpenstack%2FSPICE%2F</url>
    <content type="text"><![CDATA[题记VNC是OpenStack的Nova默认的连接协议，面对一些简单的管理工作表现也不错，但是如果用户经常使用Windows桌面，VNC就显得能力不足。一般情况下，使用Spice协议来代替VNC。 VNCVNC (Virtual Network Computing)是虚拟网络计算机的缩写。VNC 是一款优秀的远程控制工具软件，由著名的 AT&amp;T 的欧洲研究实验室开发的。VNC 是在基于 UNIX 和 Linux 操作系统的免费的开源软件，远程控制能力强大，高效实用，其性能可以和 Windows 和 MAC 中的任何远程控制软件媲美。 在 Linux 中，VNC 包括以下四个命令：vncserver，vncviewer，vncpasswd，和 vncconnect。大多数情况下我只需要其中的两个命令：vncserver 和 vncviewer。 SPICE 已经支持和即将支持的功能当前支持功能:• 图形界面 - processes and transmits 2D graphic commands• 视频流 - heuristically identifies video streams and transmits M-JPEG video streams• 图片压缩 - offers verios compression algorithm that were built specifically for Spice, including QUIC (based on SFALIC), LZ, GLZ (history-based global dictionary), and auto (heuristic compression choice per image)• 硬件鼠标- processes and transmits cursor-specific commands• 图像,颜色,鼠标缓存 - manages client caches to reduce bandwidth requirements• 在线切换 - supports clients while migrating Spice servers to new hosts, thus avoiding interruptions• Windows 驱动 - Windows drivers for QXL display device and VDI-port• 多监视器• 客户端支持linux和windows - can be easily ported to additional platforms.• 立体声音频 - supports audio playback and captures; audio data stream is optionally compressed using CELT• 加密 - using OpenSSL• 两种鼠标模式- provides client (more user-friendly) and server (increased accuracy and fully synchronized) modes• 音频视频同步 - synchronizes video streams with audio clocks• Spice 代理 - running on the guest and performs tasks for the client• 剪切板共享 - allows copy paste between clients and the virtual machine 未来将支持的新功能:• 网络隧道 (in progress) - using virtual network interface to enable sharing of network resources. Currently the focus is on printer sharing but is not limited to that.• Off-screen surfaces (in progress) - supports off-screen surfaces as infrastructure for future DirectDraw, video acceleration and 3D acceleration. GDI and X11 will also benefit from this feature. It will also lay foundation for multi-head support• 共享usb (in progress) - allows clients to share their USB devices with Spice servers• Direct Draw• 客户端GUI - Enables user-friendly configuration• 屏幕管理 - add support for enabling selection of the screen used by the client• 配置文件 - enables persistent user and administrative settings• 共享光驱 - share your CD with Spice server• 视频加速• 3D加速• 支持Aero• Linux features parity• OSX client• Simultaneous clients connection Openstack启用SPICE协议安装软件包控制节点: 1yum install spice-server spice-protocol openstack-nova-spicehtml5proxy spice-html5 计算节点: 1yum install spice-server spice-protocol spice-html5 12345678spice-html5来自epel源，spice-server，spice-protocol来自CentOS官方源如果找不到spice-html5，添加epel源wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmrpm -ivh epel-release-latest-7.noarch.rpmyum repolist ##检查是否已添加至源列表)如果离线安装:需安装epel-release-latest-7.noarch,openstack-nova-spicehtml5proxy-17.0.10-1.el7.noarch,spice-html5-0.1.7-1.el7.noarch,spice-protocol-0.12.14-1.el7.noarch,spice-server-0.14.0-9.el7.x86_64的RPM包 修改配置文件控制节点: 12345678910111213vi /etc/nova/nova.conf这里明确两点：指定vnc_enabled=false，否则即使配置了spice，系统也仍然使用vnc一定要注释掉原vnc配置[default]vnc_enabled=false[spice]html5proxy_host=192.100.200.140html5proxy_port=6082keymap=en-us 计算节点: 1234567891011vi /etc/nova/nova.conf[default]vnc_enabled=false[spice]html5proxy_base_url=http://192.100.200.140:6082/spice_auto.htmlserver_listen=0.0.0.0#server_proxyclient_address=192.100.200.150enabled=truekeymap=en-us 重启服务控制节点: 123456789停止novncproxy并取消自启动systemctl stop openstack-nova-novncproxy.servicesystemctl disable openstack-nova-novncproxy.service启用spicehtml5proxy开机自启动并启动它systemctl enable openstack-nova-spicehtml5proxy.servicesystemctl start openstack-nova-spicehtml5proxy.service 计算节点: 1systemctl restart openstack-nova-compute.service]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack控制节点删除计算节点的方法]]></title>
    <url>%2F2020%2F04%2F14%2FOpenstack%2FOpenstackDelCompute%2F</url>
    <content type="text"><![CDATA[在控制节点Controller的操作：删除计算节点名称为compute5：1.查看计算主机及服务相关： 1234567891011[root@controller ~]# openstack host list+------------+-------------+----------+| Host Name | Service | Zone |+------------+-------------+----------+| controller | consoleauth | internal || controller | scheduler | internal || controller | conductor | internal || compute4 | compute | nova || compute6 | compute | nova || compute5 | compute | nova |+------------+-------------+----------+ 1234567891011[root@controller ~]# nova service-list+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| Id | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | Forced down |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| 936a4177-d08d-4f62-bb8c-7da7047ab6f8 | nova-consoleauth | controller | internal | enabled | up | 2020-04-14T05:59:07.000000 | - | False || c1395bf8-47dd-47b0-bc8c-e10fc083ad40 | nova-scheduler | controller | internal | enabled | up | 2020-04-14T05:59:11.000000 | - | False || 28958175-5745-4b9f-b71d-e431168f6119 | nova-conductor | controller | internal | enabled | up | 2020-04-14T05:59:10.000000 | - | False || c586b1d2-f326-4e7e-8a3a-fead78a151c0 | nova-compute | compute4 | nova | enabled | up | 2020-04-14T05:59:11.000000 | - | False || b6f3a4e3-a0ec-4f41-b47d-976bd45581b6 | nova-compute | compute6 | nova | enabled | up | 2020-04-14T05:59:03.000000 | - | False || bb93240f-58f4-4d3c-a040-a66a9b2f0ea9 | nova-compute | compute5 | nova | enabled | down | 2020-04-14T05:59:12.000000 | - | False |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ 计算节点compute的State状态是down，但Status状态还是enabled可用。2.修改compute5为不可用状态。 1[root@controller ~]# nova service-disable bb93240f-58f4-4d3c-a040-a66a9b2f0ea9 查看是否修改成功 1234567891011[root@controller ~]# nova service-list+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| Id | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | Forced down |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+| 936a4177-d08d-4f62-bb8c-7da7047ab6f8 | nova-consoleauth | controller | internal | enabled | up | 2020-04-14T05:59:07.000000 | - | False || c1395bf8-47dd-47b0-bc8c-e10fc083ad40 | nova-scheduler | controller | internal | enabled | up | 2020-04-14T05:59:11.000000 | - | False || 28958175-5745-4b9f-b71d-e431168f6119 | nova-conductor | controller | internal | enabled | up | 2020-04-14T05:59:10.000000 | - | False || c586b1d2-f326-4e7e-8a3a-fead78a151c0 | nova-compute | compute4 | nova | enabled | up | 2020-04-14T05:59:11.000000 | - | False || b6f3a4e3-a0ec-4f41-b47d-976bd45581b6 | nova-compute | compute6 | nova | enabled | up | 2020-04-14T05:59:03.000000 | - | False || bb93240f-58f4-4d3c-a040-a66a9b2f0ea9 | nova-compute | compute5 | nova | disabled| down | 2020-04-14T05:59:12.000000 | - | False |+--------------------------------------+------------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ 3.在数据库（nova）中清理 12345678910111213141516171819[root@controller ~]# mysql -pEnter password:Welcome to the MariaDB monitor. Commands end with ; or g.Your MariaDB connection id is 980Server version: 10.1.20-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type 'help;' or 'h' for help. Type 'c' to clear the current input statement.MariaDB [(none)]&gt; use novaReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [nova]&gt; delete from nova.services where host="compute5";Query OK, 1 row affected (0.01 sec)MariaDB [nova]&gt; delete from compute_nodes where hypervisor_hostname="compute5";Query OK, 0 rows affected (0.00 sec)MariaDB [nova]&gt; select host from nova.services;MariaDB [nova]&gt; select hypervisor_hostname from compute_nodes; 4.校验 12[root@controller ~]# openstack host list[root@controller ~]# nova service-list 再次查看计算节点，就发现compute已经被删除了。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack创建实例报错：No valid host was found.]]></title>
    <url>%2F2020%2F04%2F14%2FOpenstack%2FOpenstackNoValidHost%2F</url>
    <content type="text"><![CDATA[错误原因：UUID冲突，nova_api数据库中resource_providers表与nova.compute_nodes表中host的UUID不一致引起的，导致原因可能为删除计算节点时没有清空resource_providers表中的数据。 解决办法：12345678[root@controller]# nova-manage cell_v2 list_hosts+-----------+--------------------------------------+----------+| Cell Name | Cell UUID | Hostname |+-----------+--------------------------------------+----------+| cell1 | 9abb6c5c-25e2-440c-8295-4826d055298c | compute4 || cell1 | 9abb6c5c-25e2-440c-8295-4826d055298c | compute5 || cell1 | 9abb6c5c-25e2-440c-8295-4826d055298c | compute6 |+-----------+--------------------------------------+----------+ 1234567891011121314151617181920MariaDB [(none)]&gt; use nova_api;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [nova_api]&gt; select uuid,name from resource_providers where name='compute5';+--------------------------------------+----------+| uuid | name |+--------------------------------------+----------+| 305cc2a4-75e8-496f-b843-152400257c35 | compute5 |+--------------------------------------+----------+1 row in set (0.00 sec)MariaDB [nova_api]&gt; select uuid,host from nova.compute_nodes where host='compute5';+--------------------------------------+----------+| uuid | host |+--------------------------------------+----------+| 924c0d27-1952-4663-8f01-e8cecc67f964 | compute5 |+--------------------------------------+----------+1 row in set (0.00 sec) 可以看到，UUID为compute5的计算节点在resource_providers表中与nova.compute_nodes表中数据不一致，将resource_providers表中数据修改： 123MariaDB [nova_api]&gt; update resource_providers set uuid='924c0d27-1952-4663-8f01-e8cecc67f964' where name='compute5' and uuid='305cc2a4-75e8-496f-b843-152400257c35';Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0 修改后，compute5上实例可以成功创建。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交换机端口开启巨帧功能]]></title>
    <url>%2F2020%2F04%2F14%2FOther%2FswitchJumbo%2F</url>
    <content type="text"><![CDATA[命令功能：开启/关闭端口巨帧功能。 命令模式：全局配置模式 命令格式：1set jumbo port &lt;portlist&gt;&#123;enable | disable&#125; 命令参数解释： 参数 | 描述 portlist | 端口列表 enable | 开启端口巨帧功能 disable | 关闭端口巨帧功能 使用说明：ZXR10 2950设备可以转发10k大小的巨帧。 缺省：巨帧功能默认为disable状态。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7断电导致generating /run/initramfs/rdsosreport.txt 问题]]></title>
    <url>%2F2020%2F04%2F14%2FLinux%2Frdsosreport%2F</url>
    <content type="text"><![CDATA[开机就进入命令窗口，窗口提示信息如下：1234generating "/run/initramfs/rdsosreport.txt"entering emergencymode. exit the shell to continuetype "journalctl" to view system logs.you might want to save "/run/initramfs/rdsosreport.txt" to a usb stick or /boot after mounting them and attach it to a bug report. 解决办法：1xfs_repair /dev/mapper/centos-root -L 1reboot]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack 安全组规则不生效]]></title>
    <url>%2F2020%2F02%2F14%2FOpenstack%2FOpenstackSecurityGroup%2F</url>
    <content type="text"><![CDATA[编辑 /etc/sysctl.conf 文件这里强调，安全组主要是依靠计算节点的iptables的forward链来生效的，每加一条规则就会根据网卡作为匹配条件，来生成一条iptables的规则。 如果没有任何规则，默认是丢弃所有的包。 猜测到的原因是因为，没有开启包转发功能，所以修改 12345net.ipv4.ip_forward=1net.ipv4.conf.default.rp_filter=1net.bridge.bridge-nf-call-ip6tables=1net.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-arptables=1 重启网络 1/etc/init.d/network restart 编辑 /etc/neutron/plugins/ml2/openvswitch_agent.ini 文件增加或修改项，包括控制节点和计算节点 123[securitygroup]enable_security_group = truefirewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver 控制节点重启所有网络服务，计算节点重启Openvswitch服务。 注：neutron 也提供两种安全组的实现：IptablesFirewallDriver 和 OVSHybridIptablesFirewallDriverneutron.agent.linux.iptables_firewall.IptablesFirewallDriver iptables-based FirewallDriver implementationneutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver: subclass of IptablesFirewallDriver with additional bridge默认值是 neutron.agent.firewall.NoopFirewallDriver，表示不使用 neutron security group。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMX开启kafka]]></title>
    <url>%2F2019%2F11%2F21%2FOther%2Fjmx_kafka%2F</url>
    <content type="text"><![CDATA[开启JMXkafka开启JMX的2种方式：1.启动kafka时增加JMX_PORT=9988，即 1JMX_PORT=9988 bin/kafka-server-start.sh -daemon config/server.properties 2.修改kafka-run-class.sh脚本，第一行增加JMX_PORT=9988即可。 事实上这两种配置方式背后的原理是一样的，我们看一下kafka的启动脚本kafka-server-start.sh的最后一行 1exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka"$@" 实际上就是调用kafka-run-class.sh脚本，其中有一段这样的内容： 1234# JMX port to useif [ $JMX_PORT ]; then KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT "fi 所以，本质是给参数JMX_PORT赋值，第二种方式在脚本的第一行增加JMX_PORT=9988，$JMX_PORT就能取到值；而第一种方式有点逼格，本质是设置环境变量然后执行启动脚本，类似下面这种方式给JMX_PORT赋值： 12[root@kafka]$ export JMX_PORT=9988[root@kafka]$ bin/kafka-server-start.sh -daemon config/server.properties jmx所有相关参数都在脚本kafka-run-class.sh中，如下所示： 123456789# JMX settingsif [ -z "$KAFKA_JMX_OPTS" ]; then KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=10.0.55.229 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false "fi# JMX port to useif [ $JMX_PORT ]; then KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT "fi 某些服务器可能无法正确绑定ip，这时候我们需要显示指定绑定的host：- 1Djava.rmi.server.hostname=192.100.200.46 jconsole连接配置好jmx并启动kafka后，可以启动jconsole验证jmx配置是否正确（连接远程进程的host就是参数java.rmi.server.hostname指定的值，port就是参数JMX_PORT指定的值）： JMX开启远程访问（包括kafka启动）： 1sudo KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=192.100.200.46 -Djava.net.preferIPv4Stack=true -Dcom.sun.management.jmxremote.port=9988" bin/kafka-server-start.sh config/server.properties]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka集群管理工具kafka-manager的安装使用]]></title>
    <url>%2F2019%2F11%2F21%2FOther%2Fkafka_manager%2F</url>
    <content type="text"><![CDATA[kafka-manager简介kafka-manager是目前最受欢迎的kafka集群管理工具，最早由雅虎开源，用户可以在Web界面执行一些简单的集群管理操作。具体支持以下内容： 管理多个集群轻松检查集群状态（主题，消费者，偏移，代理，副本分发，分区分发）运行首选副本选举使用选项生成分区分配以选择要使用的代理运行分区重新分配（基于生成的分配）使用可选主题配置创建主题（0.8.1.1具有与0.8.2+不同的配置）删除主题（仅支持0.8.2+并记住在代理配​​置中设置delete.topic.enable = true）主题列表现在指示标记为删除的主题（仅支持0.8.2+）批量生成多个主题的分区分配，并可选择要使用的代理批量运行重新分配多个主题的分区将分区添加到现有主题更新现有主题的配置kafka-manager 项目地址：https://github.com/yahoo/kafka-manager kafka-manager安装下载安装包使用Git或者直接从Releases中下载，这里我们下载 2.0.0.2版本：https://github.com/yahoo/kafka-manager/releases 1wget https://github.com/yahoo/kafka-manager/archive/2.0.0.2.tar.gz 解压安装包 12tar zxvf 2.0.0.2.tar.gzcd kafka-manager-2.0.0.2 sbt编译yum安装sbt(因为kafka-manager需要sbt编译) 123curl https://bintray.com/sbt/rpm/rpm &gt; bintray-sbt-rpm.repomv bintray-sbt-rpm.repo /etc/yum.repos.d/yum install sbt 验证：检查sbt是否安装成功 12sbt[info] [launcher] getting org.scala-sbt sbt 1.3.3 (this may take some time)... 编译kafka-manager 1./sbt clean dist 安装将编译好的/root/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.zip文件解压 1unzip /root/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.zip 启动服务启动zk集群，kafka集群，再启动kafka-manager服务。bin/kafka-manager 默认的端口是9000，可通过 -Dhttp.port，指定端口;-Dconfig.file=conf/application.conf指定配置文件: 1nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=9000 &amp; WebUI查看：http://KAFKA_IP:9000/ 出现如下界面则启动成功。]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装kafka]]></title>
    <url>%2F2019%2F11%2F19%2FOther%2Fcentos7_kdfka%2F</url>
    <content type="text"><![CDATA[安装准备：基于Centos7.5 1804 minimal安装JDK1.81yum -y install java-1.8.0-openjdk* 安装kafka下载kafka 1wget http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.3.0/kafka_2.12-2.3.0.tgz 解压 1tar -zxvf kafka_2.12-2.3.0.tgz 修改配置，使kafka远程访问 12345vi config/server.properties# listeners=PLAINTEXT://:9092-&gt;listeners=PLAINTEXT://KAFKA_IP:9092 启动kafka进入kafka目录 1cd kafka_2.12-2.3.0 启动zookeeper 1bin/zookeeper-server-start.sh -daemon config/zookeeper.properties 检查zookeeper端口2181是否正常监听 12netstat -an|grep 2181tcp6 0 0 :::2181 :::* LISTEN 检查kafka默认的JVM参数配置是否需要修改Kafka默认设置1G，即”-Xmx1G -Xms1G”。如果你的测试机内存较低，需要修改才能成功启动。参数配置位于：bin/kafka-server-start.sh 启动Kafka 1bin/kafka-server-start.sh config/server.properties 如果一切顺利，就会看到如下启动成功的日志： 1[2019-11-18 21:42:37,067] INFO [KafkaServer id=0] started (kafka.server.KafkaServer) 检查Kafka的端口9092监听是否正常 12[root@localhost kafka_2.12-2.3.0]# netstat -an|grep 9092tcp6 0 0 :::9092 :::* LISTEN 测试kafka创建一个测试主题 1234cd kafka_2.12-2.3.0bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testCreated topic "test". 查看刚刚创建的test主题 123bin/kafka-topics.sh --list --zookeeper localhost:2181test 向刚刚创建的test主题中写入数据 123bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test&gt;Hello, World!&gt; “Hello World!”为写入的数据。 查看刚刚写入的数据另外开一个ssh tab连接，然后执行如下命令 1234bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].Hello, World!]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS网卡配置文件设置为网桥模式]]></title>
    <url>%2F2019%2F11%2F08%2FOpenstack%2FOpenstackProviderBridge%2F</url>
    <content type="text"><![CDATA[原eth0配置文件/etc/sysconfig/network-scripts/ifcfg-eth0 12345678910111213TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=noIPV4_FAILURE_FATAL=noNAME=eth0UUID=63754cd8-9152-44a4-b051-ea88c0182bd4DEVICE=eth0ONBOOT=yesIPADDR=191.100.200.30NETMASK=255.255.255.0GATEWAY=192.100.10.161 改成网桥配置后,eth0配置文件及br-provider网桥配置文件/etc/sysconfig/network-scripts/ifcfg-eth0 123456789TYPE=OVSPortDEVICETYPE=ovsNAME=eth0UUID=63754cd8-9152-44a4-b051-ea88c0182bd4DEVICE=eth0ONBOOT=yesIPADDR=0.0.0.0NETMASK=255.255.255.0OVS_BRIDGE=br-provider /etc/sysconfig/network-scripts/ifcfg-br-provider 123456789DEVICE=br-providerDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=192.100.200.30NETMASK=255.255.255.0GATEWAY=192.100.10.161ONBOOT=yes]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建openstack Queens版本本地yum源]]></title>
    <url>%2F2019%2F10%2F24%2FOpenstack%2FYum_OpenstackQueens%2F</url>
    <content type="text"><![CDATA[选择一台CentOS服务器，安装以下软件：1yum install yum-utils createrepo yum-plugin-priorities httpd 开启httpd服务1systemctl start httpd 获取repo文件并使用reposync同步源1yum install -y https://repos.fedorapeople.org/repos/openstack/openstack-queens/rdo-release-queens-2.noarch.rpm 查看源ID列表 1yum repolist 同步openstack-queens这个repo12cd /var/www/html/reposync --repoid=openstack-queens 第一次同步时间较长，同步结束后，执行1createrepo –update /var/www/html/openstack-queens 创建完成后，就可以使用web测试：1http://[ip]/openstack-queens/ 选择另外一台服务器作为客户机12345678910cd /etc/yum.repos.dmv CentOS-Base.repo CentOS-Base.repo_bakcp CentOS-Media.repo CentOS-Media.repo_bakvim CentOS-Media.repo[openstack-queens]name=OpenStack Queens Repositorybaseurl=http://47.98.122.105/openstack-queens/enabled=1gpgcheck=0 配置完成，清除缓存并查看软件包12yum clean allyum list 问题客户端yum安装报错： 12345Error downloading packages: glusterfs-libs-7.5-1.el7.x86_64: failed to retrieve Packages/g/glusterfs-libs-7.5-1.el7.x86_64.rpm from centos7-glustererror was [Errno 2] Local file does not exist: /etc/yum.repos.d/pdate/Packages/g/glusterfs-libs-7.5-1.el7.x86_64.rpm glusterfs-7.5-1.el7.x86_64: failed to retrieve Packages/g/glusterfs-7.5-1.el7.x86_64.rpm from centos7-glustererror was [Errno 2] Local file does not exist: /etc/yum.repos.d/pdate/Packages/g/glusterfs-7.5-1.el7.x86_64.rpm 问题解决：YUM服务器删除对应的repodata文件夹，使用如下命令 1createrepo -pdo /var/www/html/kdpa/ /var/www/html/kdpa/ 重新生成repo链接，问题解决]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack 扩大 RabbitMQ Socket Limit 方法]]></title>
    <url>%2F2019%2F10%2F15%2FOther%2FrabbitmqSocket%2F</url>
    <content type="text"><![CDATA[在RabbitMQ中，Socket descriptors 是 File descriptors 的子集，它们也是一对此消彼长的关系。然而，它们的默认配额并不大，File descriptors 默认值为“1024”，而 Socket descriptors 的默认值也只有“829”，同时，File descriptors 所能打开的最大文件数也受限于操作系统的配额。因此，如果要调整 File descriptors 文件句柄数，就需要同时调整操作系统和RabbitMQ参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@controller ~]# rabbitmqctl statusStatus of node rabbit@controller[&#123;pid,3407&#125;,&#123;running_applications, [&#123;rabbit,"RabbitMQ","3.6.16"&#125;, &#123;rabbit_common, "Modules shared by rabbitmq-server and rabbitmq-erlang-client", "3.6.16"&#125;, &#123;xmerl,"XML parser","1.3.14"&#125;, &#123;ranch,"Socket acceptor pool for TCP protocols.","1.3.2"&#125;, &#123;mnesia,"MNESIA CXC 138 12","4.14.3"&#125;, &#123;syntax_tools,"Syntax tools","2.1.1"&#125;, &#123;ssl,"Erlang/OTP SSL application","8.1.3.1"&#125;, &#123;os_mon,"CPO CXC 138 46","2.4.2"&#125;, &#123;public_key,"Public key infrastructure","1.4"&#125;, &#123;crypto,"CRYPTO","3.7.4"&#125;, &#123;asn1,"The Erlang ASN1 compiler version 4.0.4","4.0.4"&#125;, &#123;recon,"Diagnostic tools for production use","2.3.2"&#125;, &#123;compiler,"ERTS CXC 138 10","7.0.4.1"&#125;, &#123;sasl,"SASL CXC 138 11","3.0.3"&#125;, &#123;stdlib,"ERTS CXC 138 10","3.3"&#125;, &#123;kernel,"ERTS CXC 138 10","5.2"&#125;]&#125;,&#123;os,&#123;unix,linux&#125;&#125;,&#123;erlang_version, "Erlang/OTP 19 [erts-8.3.5.3] [source] [64-bit] [smp:96:96] [async-threads:1024] [hipe] [kernel-poll:true]\n"&#125;,&#123;memory, [&#123;connection_readers,20241544&#125;, &#123;connection_writers,1200000&#125;, &#123;connection_channels,4846312&#125;, &#123;connection_other,53785896&#125;, &#123;queue_procs,6683888&#125;, &#123;queue_slave_procs,0&#125;, &#123;plugins,0&#125;, &#123;other_proc,23512680&#125;, &#123;metrics,2466240&#125;, &#123;mgmt_db,0&#125;, &#123;mnesia,847160&#125;, &#123;other_ets,3015688&#125;, &#123;binary,1999169528&#125;, &#123;msg_index,176072&#125;, &#123;code,21467691&#125;, &#123;atom,891849&#125;, &#123;other_system,75976100&#125;, &#123;allocated_unused,483082808&#125;, &#123;reserved_unallocated,0&#125;, &#123;total,766799872&#125;]&#125;,&#123;alarms,[]&#125;,&#123;listeners,[&#123;clustering,25672,"::"&#125;,&#123;amqp,5672,"::"&#125;]&#125;,&#123;vm_memory_calculation_strategy,rss&#125;,&#123;vm_memory_high_watermark,0.4&#125;,&#123;vm_memory_limit,53742133248&#125;,&#123;disk_free_limit,50000000&#125;,&#123;disk_free,996377710592&#125;,&#123;file_descriptors, [&#123;total_limit,878&#125;, &#123;total_used,776&#125;, &#123;sockets_limit,829&#125;, &#123;sockets_used,774&#125;]&#125;,&#123;processes,[&#123;limit,1048576&#125;,&#123;used,9483&#125;]&#125;,&#123;run_queue,0&#125;,&#123;uptime,161034&#125;,&#123;kernel,&#123;net_ticktime,60&#125;&#125;] 修改系统内核参数系统级别 123vim /etc/sysctl.conffs.file-max=655350 1sysctl -p | grep file-max 用户级别 123456vim /etc/security/limits.conf* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 修改rabbitmq配置如果是以systemd方式管理rabbitmq服务，则需要修改rabbitmq的service文件。 1vim /usr/lib/systemd/system/rabbitmq-server.service 添加如下参数，其值请根据实际情况进行调整： 12[Service]LimitNOFILE=16384 重启rabbitmq即可： 12systemctl daemon-reloadsystemctl restart rabbitmq-server]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrony - 一步搞定NTP时间同步问题]]></title>
    <url>%2F2019%2F09%2F24%2FLinux%2Fchrony%2F</url>
    <content type="text"><![CDATA[什么是chrony？A client/server for the Network Time Protocol, this program keeps your computer’s clock accurate. It was specially designed to support systems with intermittent internet connections, but it also works well in permanently connected environments. It can use also hardware reference clocks, system real-time clock or manual input as time references.chrony是一个ntp协议的实现程序，既可以当做服务端，也可以充当客户端；它专为间歇性互联网连接的系统而设计，当然也能良好应用于持久互联网连接的环境；chrony有三个时间参考：硬件时钟、实时时钟以及手动同步。 chrony的程序环境主配置文件：/etc/chrony.conf客户端程序：/usr/bin/chronyc服务端程序：/usr/sbin/chronyd 为本地服务器配置一个时间服务器环境时间服务器：192.168.1.10允许本网段192.168.1.0/24同步时间。 配置服务端在编辑配置文件之前，我一般习惯于备份一下，以备重新调整。网络时间服务器可以自行查找，网上很多资料，下边配置两个个国内常用的时间服务器： ]# cd /etc/etc]# cp chrony.conf{,.bak}etc]# vim chrony.conf … # iburst为固定格式，记住就可以，没有深究。 server cn.pool.ntp.org iburst server tw.pool.ntp.org iburst ... # 允许指定网络的主机同步时间，不指定就是允许所有，默认不开启。 allow 192.168.1.0/24 ... # 还有一个默认不开启的选项，意思是，即使服务端没有同步到精确的网络时间，也允许向客户端同步不精确的时间。可以视情况而定。 # Serve time even if not synchronized to any NTP server. #local stratum 10~]# systemctl start chronyd.service~]# systemctl enable chronyd.service 客户端同步配置192.168.1.10作为时间服务器 etc]# vim chrony.conf … server 192.168.1.10 iburst …~]# systemctl start chronyd.service~]# systemctl enable chronyd.service 进入chronyc客户端交互式模式：~]# chronyc 查看现有的时间服务器 chronyc&gt; sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 192.168.1.10 10 6 377 53 -4546ns[-5000ns] +/- 234us查看时间服务器状态 chronyc&gt; sourcestats 210 Number of sources = 1 Name/IP Address NP NR Span Frequency Freq Skew Offset Std Dev ============================================================================== 192.168.1.10 10 6 584 +0.001 0.828 +35ns 74us chronyc&gt;exit也可以直接在命令行使用：~]# chronyc sources~]# chronyc sourcestats chrony兼容ntpdate，客户端可以使用ntpdate手动同步时间 12~]# ntpdate 192.168.1.10 9 Nov 02:54:30 ntpdate[39551]: adjust time server 192.168.43.101 offset -0.000003 sec]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[collectd + influxDB + Grafana 搭建监控平台]]></title>
    <url>%2F2019%2F08%2F06%2FOther%2Fmonitor%2F</url>
    <content type="text"><![CDATA[概述常用配置： influxdb + grafana安装在一台机器负责监控数据收集及展示collectd安装在一台或多台被监控服务端,跟监控端的25826端口对接，上传本地监控的数据influxdb监控25826端口以获得数据，自身处于8086端口，grafana从8086获得数据进行展示 InfluxDB 是 Go 语言开发的一个开源分布式时序数据库，非常适合存储指标、事件、分析等数据 collectd C 语言写的一个系统性能采集工具 Grafana 是纯 Javascript 开发的前端工具，用于访问 InfluxDB，自定义报表、显示图表等 本次安装版本 collectd 5.8.1 influxDB 1.7.7 Grafana 6.2.5 Collectdcollectd是一个守护(daemon)进程，用来收集系统性能和提供各种存储方式来存储不同值的机制。比如以RRD 文件形式，当系统运行和存储信息的时候，Collectd会周期性统计系统的相关统计信息。那些信息可以用来找到当前系统性能瓶颈。（如作为性能分析 performance analysis）和预测系统未来的load（如能力部署capacity planning） 安装1# yum install -y collectd 修改配置123456789101112131415161718192021222324252627# vim /etc/collectd.conf#更改以下内容，前面的#记得删除掉 没有就使用find / -name collectd.conf 查找在哪里 FQDNLookup true Hostname "localhost" #直接使用hostname命令查看 BaseDir "/var/lib/collectd" PIDFile "/var/run/collectd.pid" PluginDir "/usr/lib64/collectd" TypesDB "/usr/share/collectd/types.db" LoadPlugin syslog LoadPlugin rrdtool LoadPlugin disk LoadPlugin interface LoadPlugin load LoadPlugin memory LoadPlugin network LoadPlugin processes LoadPlugin users &lt;Plugin interface&gt; Interface "eth0" IgnoreSelected false &lt;/Plugin&gt; &lt;Plugin network&gt; Server "127.0.0.1" "25826" #这里填写的是influxDB安装的服务器ip &lt;Plugin rrdtool&gt; DataDir "/usr/var/lib/collectd/rrd" #如果你是使用下载安装前面应该会多出一个$&#123;prefix&#125;,未尝试是否有影响 &lt;/Plugin&gt; 安装rrdtool插及依赖包1# yum install collectd-rrdtool rrdtool rrdtool-devel 启动collectd12# systemctl start collectd.service #启动# systemctl enable collectd.service #配置开机自启 确认配置是否成功123# cd /var/lib/collectd# lsrrd 如果/var/lib/collectd目录下生成rrd文件，说明有数据了，如果没有应该是配置问题 Influxdb配置yum源配置yum(此方法为最新版本InfluxDB) 12345678# cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo&gt;[influxdb]&gt;name = InfluxDB Repository - RHEL \$releasever&gt;baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable&gt;enabled = 1&gt;gpgcheck = 1&gt;gpgkey = https://repos.influxdata.com/influxdb.key&gt;EOF 安装1# yum install -y influxdb 启动InfluxDB12# systemctl start influxdb.service#启动# systemctl enable influxdb.service #配置influxdb开机自启 启动后TCP端口:8083 为InfluxDB 管理控制台 TCP端口:8086 为客户端和InfluxDB通信时的HTTP API启动后InfluxDB用户认证默认是关闭的，先创建用户:geekwolf geekwolf命令行输入influx 配置数据库12345678910111213141516171819202122232425262728293031323334# influx #进入InfluxDBConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; create database collectdb #创建数据库&gt; show databases #查看数据库name: databases\------namecollectdb&gt; create user matianxin with password &apos;matianxin&apos; #创建一个用户和密码&gt; show users #查看所有用户user adminmatianxin false&gt; grant all on collectdb to matianxin #把上面创建的数据库的所有权限赋给geekwolf用户&gt; help showUsage: connect &lt;host:port&gt; connects to another node specified by host:port auth prompts for username and password pretty toggles pretty print for the json format use &lt;db_name&gt; sets current database format &lt;format&gt; specifies the format of the server responses: json, csv, or column precision &lt;/format&gt;&lt;format&gt; specifies the format of the timestamp: rfc3339, h, m, s, ms, u or ns consistency &lt;level&gt; sets write consistency level: any, one, quorum, or all history displays command history settings outputs the current settings for the shell exit/quit/ctrl+d quits the influx shell show databases show database names show series show series information show measurements show measurement information show tag keys show tag key information show field keys show field key information A full list of influxql commands can be found at: https://docs.influxdata.com/influxdb/v0.10/query_language/spec&gt; quit #退出 启用认证修改配置文件启用认证 12# sed -i 's#auth-enabled = false#auth-enabled = true#g' /etc/influxdb/influxdb.conf# systemctl restart influxdb.service #重启influxdb 配置InfluxDB支持Collectd12345678910# vim /etc/influxdb/influxdb.conf [collectd] enabled = true bind-address = "127.0.0.1:25826" database = "collectdb" typesdb = "/usr/share/collectd/types.db" #查找一下types.db文件不一定在这个路径，如果路径配置错误就不能监听成功 batch-size = 5000 batch-pending = 10 batch-timeout = "10s" read-buffer = 0 1# systemctl restart influxdb.service #重启influxdb 查看25826这个端口是否已经监听，如果有，则代表启动正常 12# netstat -anp| grep 25826udp 0 0 127.0.0.1:25826 0.0.0.0:* 2950/influxd 确认数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990[root@localhost ~]# influxConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; use collectdbUsing database collectdb&gt; show field keysname: cpu_valuefieldKey fieldType-------- ---------value floatname: disk_io_timefieldKey fieldType-------- ---------value floatname: disk_readfieldKey fieldType-------- ---------value floatname: disk_valuefieldKey fieldType-------- ---------value floatname: disk_weighted_io_timefieldKey fieldType-------- ---------value floatname: disk_writefieldKey fieldType-------- ---------value floatname: interface_rxfieldKey fieldType-------- ---------value floatname: interface_txfieldKey fieldType-------- ---------value floatname: load_longtermfieldKey fieldType-------- ---------value floatname: load_midtermfieldKey fieldType-------- ---------value floatname: load_shorttermfieldKey fieldType-------- ---------value floatname: memory_valuefieldKey fieldType-------- ---------value floatname: processes_valuefieldKey fieldType-------- ---------value floatname: users_valuefieldKey fieldType-------- ---------value float&gt; select * from cpu_value limit 10;name: cpu_valuetime host instance type type_instance value---- ---- -------- ---- ------------- -----1565060949576064259 localhost 0 cpu user 26631565060949576080440 localhost 0 cpu system 29521565060949576087737 localhost 0 cpu wait 891565060949576094319 localhost 0 cpu nice 01565060949576100786 localhost 0 cpu interrupt 01565060949576106664 localhost 0 cpu softirq 1601565060949576108568 localhost 0 cpu steal 01565060949576110126 localhost 0 cpu idle 2480671565060959576531164 localhost 0 cpu user 26641565060959576547037 localhost 0 cpu system 2955&gt; Grafana安装12# wget https://dl.grafana.com/oss/release/grafana-6.2.5-1.x86_64.rpm# yum localinstall grafana-6.2.5-1.x86_64.rpm 启动grafana12# systemctl start grafana-server.service #启动# systemctl enable grafana-server.service #配置开机自启 配置Grafana访问地址:http://127.0.0.1:3000 默认账号为admin 密码 admin 配置Data Source Name: InfluxDB -&gt; default URL: http://localhost:8086 Access: Server(Default) Basic Auth: √ Basic Auth Details User: matianxin Password: matianxin InfluxDB Details Database: collectdb …]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（十）Ceilometer + Gnocchi]]></title>
    <url>%2F2019%2F08%2F02%2FOpenstack%2FOpenstackQueens10%2F</url>
    <content type="text"><![CDATA[ceilometer概述什么是ceilometerCeilometer是OpenStack中的一个子项目，它像一个漏斗一样，能把OpenStack内部发生的几乎所有的事件都收集起来，然后为计费和监控以及其它服务提供数据支撑。 Ceilometer服务主要功能： 有效地轮询与OpenStack服务相关的计量数据。 通过监视从服务发送的通知来收集事件和计量数据。 将收集的数据发布到各种目标，包括数据存储和消息队列。 ceilometer如何进行监控Ceilometer监控通过在计算节点部署Compute服务，轮询其计算节点上的instance，获取各自的CPU、网络、磁盘等监控信息，发送到RabbitMQ，Collector服务负责接收信息进行持久化存储，也可通过libvirt和openstack服务的API采集数据。 监控信息存储Ceilometer以前提供了存储和API解决方案。截至N版本，此功能已被正式弃用并且不鼓励。为了有效存储和统计分析ceilometer数据，建议使用Gnocchi。采集信息的存储可以有多种，如文件，数据库等，openstack queens版本默认采用gnocchi+文件形式存储。 gnocchi概述gnocchi是什么Gnocchi是一个多租户时间序列，计量和资源数据库。提供了HTTP REST接口来创建和操作数据。Gnocchi设计用于超大规模计量数据的存储，同时向操作者和用户提供对度量和资源信息的访问。Gnocchi是OpenStack项目的一部分。因此它支持OpenStack，但也能完全独立的工作。 gnocchi项目起源早期的openstack各类资源的计量数据(measurement) 存储在SQL数据库中的sample表中。随着云环境中需要被监控的资源增多和时间的推移，计量数据的增长变得难以预测；计量数据的使用方面，查询操作首先要从巨大的sample单表中过滤所需条目，然后还会涉及到相关的聚合计算；可想而知，由此带来的性能开销绝对是无法忍受的，并且随着时间的推移这个瓶颈会愈加明显直至奔溃。要解决上述问题方法有很多，比如分表：每个监控指标（Metirc）一张表，那么一个资源可能会有多张表（比如一个instance至少会有cpu，cpu.util，memory，memory.usage，disk.* 等监控指标metrics）；这似乎有点夸张，即使这样都可以接受的话，那么查询时对计量数据的聚合操作也还是个问题。为解决以上问题，红帽的Julien Danjou，发起了Gnocchi项目来解决这类问题。其总体思路是：把各个计量指标Metric的计量数据measurement直接写入后端存储中；并在measurement写入之前根据预先设定的归档策略进行聚合操作；查询时直接读取对应的文件即可获得聚合后的监控信息点；gnocchi提供资源索引，这样能更快的找到每个资源的基础信息metadata和其相关的metrics信息。注：数据存储分级：(资源项)resource-&gt;(资源指标条目)metric-&gt;(实际数据)measure 为什么使用gnocchiGnocchi已能够具备在云计算环境中提供可用的时间序列数据库的需要，提供存储大量度量数据并且易于扩展的能力。Gnocchi项目于2014年开始，作为OpenStack Ceilometer项目的分支，以解决Ceilometer在将标准数据库用作计量数据的存储后端时遇到的性能问题。Gnocchi使用各种技术压缩存储数据，降低了数据存储的空间。 ceilometer+gnocchi环境搭建安装部署ceilometer服务前，主机必须已经正确安装keystone、nova、neutron、image服务。部署过程须用到uwsgi和redis。 Compute节点安装安装ceilometer相关包：12# yum install openstack-ceilometer-compute# yum install openstack-ceilometer-ipmi (optional) 编辑/etc/ceilometer/ceilometer.conf文件并完成以下操作 在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问 123[DEFAULT]...transport_url = rabbit://openstack:123456@controller 在该[service_credentials]部分中，配置服务凭据： 12345678910[service_credentials]auth_url = http://controller:5000project_domain_id = defaultuser_domain_id = defaultauth_type = passwordusername = ceilometerproject_name = servicepassword = 123456interface = internalURLregion_name = RegionOne 配置计算服务，编辑/etc/nova/nova.conf文件并在以下[DEFAULT]部分配置通知： 12345678[DEFAULT]...instance_usage_audit = Trueinstance_usage_audit_period = hournotify_on_state_change = vm_and_task_state[oslo_messaging_notifications]...driver = messagingv2 配置计算以轮询IPMI，编辑/etc/sudoers文件并添加包含： 1ceilometer ALL = (root) NOPASSWD: /usr/bin/ceilometer-rootwrap /etc/ceilometer/rootwrap.conf * 编辑/etc/ceilometer/polling.yaml以包含所需： 1234- name: ipmi interval: 300 meters: - hardware.ipmi.temperature 完成安装 启动代理并将其配置为在系统引导时启动： 1234# systemctl enable openstack-ceilometer-compute.service# systemctl start openstack-ceilometer-compute.service# systemctl enable openstack-ceilometer-ipmi.service (optional)# systemctl start openstack-ceilometer-ipmi.service (optional) 重新启动Compute服务： 1# systemctl restart openstack-nova-compute.service Controller节点安装获取admin凭据来访问仅管理员CLI命令1$ . admin-openrc 要创建服务凭据，请完成以下步骤： 创建ceilometer用户： 1234567891011openstack user create --domain default --password-prompt ceilometerUser Password:123456Repeat User Password:123456+-----------+----------------------------------+| Field | Value |+-----------+----------------------------------+| domain_id | e0353a670a9e496da891347c589539e9 || enabled | True || id | c859c96f57bd4989a8ea1a0b1d8ff7cd || name | ceilometer |+-----------+----------------------------------+ 将admin角色添加到ceilometer用户。 1$ openstack role add --project service --user ceilometer admin 在Keystone注册Gnocchi服务 创建gnocchi用户： 1234567891011$ openstack user create --domain default --password-prompt gnocchiUser Password:123456Repeat User Password:123456+-----------+----------------------------------+| Field | Value |+-----------+----------------------------------+| domain_id | e0353a670a9e496da891347c589539e9 || enabled | True || id | 8bacd064f6434ef2b6bbfbedb79b0318 || name | gnocchi |+-----------+----------------------------------+ 创建gnocchi服务实体 1234567891011$ openstack service create --name gnocchi \ --description "Metric Service" metric+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Metric Service || enabled | True || id | 205978b411674e5a9990428f81d69384 || name | gnocchi || type | metric |+-------------+----------------------------------+ 将admin角色添加到gnocchi用户 1$ openstack role add --project service --user gnocchi admin 创建Ceilometer服务API端点 123456789101112131415$ openstack endpoint create --region RegionOne \ metric public http://controller:8041+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b808b67b848d443e9eaaa5e5d796970c || interface | public || region | RegionOne || region_id | RegionOne || service_id | 205978b411674e5a9990428f81d69384 || service_name | gnocchi || service_type | metric || url | http://controller:8041 |+--------------+----------------------------------+ 123456789101112131415$ openstack endpoint create --region RegionOne \ metric internal http://controller:8041+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | c7009b1c2ee54b71b771fa3d0ae4f948 || interface | internal || region | RegionOne || region_id | RegionOne || service_id | 205978b411674e5a9990428f81d69384 || service_name | gnocchi || service_type | metric || url | http://controller:8041 |+--------------+----------------------------------+ 123456789101112131415$ openstack endpoint create --region RegionOne \ metric admin http://controller:8041+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b2c00566d0604551b5fe1540c699db3d || interface | admin || region | RegionOne || region_id | RegionOne || service_id | 205978b411674e5a9990428f81d69384 || service_name | gnocchi || service_type | metric || url | http://controller:8041 |+--------------+----------------------------------+ 安装Gnocchi 安装服务组件 1# yum install openstack-gnocchi-api openstack-gnocchi-metricd python-gnocchiclient 新建文件 /etc/httpd/conf.d/10-gnocchi_wsgi.conf 123456789101112131415161718192021Listen 8041&lt;VirtualHost *:8041&gt; ServerName controller ## Vhost docroot DocumentRoot "/var/www/cgi-bin/gnocchi" ## Directories, there should at least be a declaration for /var/www/cgi-bin/gnocchi &lt;Directory "/var/www/cgi-bin/gnocchi"&gt; Options Indexes FollowSymLinks MultiViews AllowOverride None Require all granted &lt;/Directory&gt; ## Logging ErrorLog "/var/log/httpd/gnocchi_wsgi_error.log" ServerSignature Off CustomLog "/var/log/httpd/gnocchi_wsgi_access.log" combined SetEnvIf X-Forwarded-Proto https HTTPS=1 WSGIApplicationGroup %&#123;GLOBAL&#125; WSGIDaemonProcess gnocchi display-name=gnocchi_wsgi group=gnocchi processes=8 threads=8 user=gnocchi WSGIProcessGroup gnocchi WSGIScriptAlias / "/var/www/cgi-bin/gnocchi/app"&lt;/VirtualHost&gt; 创建文件夹路径下app文件 12mkdir /var/www/cgi-bin/gnocchi/vim /var/www/cgi-bin/gnocchi/app app文件如下： 123456789101112131415161718192021#!/usr/bin/python# Licensed under the Apache License, Version 2.0 (the "License");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or# implied.# See the License for the specific language governing permissions and# limitations under the License.if __name__ == '__main__': import sys from gnocchi.cli import api sys.exit(api.api())else: from gnocchi.cli import api from gnocchi.rest import app application = app.load_app(api.prepare_service()) 文件夹修改权限 12# chown -R gnocchi.gnocchi /var/www/cgi-bin/gnocchi# chmod +777 /var/www/cgi-bin/gnocchi 重启httpd服务 1# systemctl restart httpd 为Gnocchi的索引器创建数据库 使用数据库访问客户端以root用户身份连接到数据库服务器 1234$ mysql -u root -pCREATE DATABASE gnocchi;GRANT ALL PRIVILEGES ON gnocchi.* TO &apos;gnocchi&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;;GRANT ALL PRIVILEGES ON gnocchi.* TO &apos;gnocchi&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; 编辑/etc/gnocchi/gnocchi.conf文件并添加Keystone选项 在[api]中，配置gnocchi以使用keystone： 12[api]auth_mode = keystone 在[keystone_authtoken]部分中，配置keystone身份验证： 12345678910111213[keystone_authtoken]...auth_type = passwordauth_url = http://controller:5000/v3project_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = gnocchipassword = 123456interface = internalURLregion_name = RegionOne[indexer]url = mysql+pymysql://gnocchi:GNOCCHI_DBPASS@controller/gnocchi 在[storage]部分中，配置位置以存储度量标准数据。在这种情况下，我们将它存储到本地文件系统。有关更耐用和高性能驱动程序的列表，请参阅Gnocchi文档： 123456[storage]# coordination_url is not required but specifying one will improve# performance with better workload division across workers.coordination_url = redis://controller:6379file_basepath = /var/lib/gnocchidriver = file 初始化Gnocchi： 1gnocchi-upgrade 完成Gnocchi安装启动Gnocchi服务并将其配置为在系统引导时启动 12# systemctl enable openstack-gnocchi-api.service openstack-gnocchi-metricd.service# systemctl start openstack-gnocchi-api.service openstack-gnocchi-metricd.service 安装Ceilometer包1# yum install openstack-ceilometer-notification openstack-ceilometer-central 编辑/etc/ceilometer/pipeline.yaml文件并完成以下部分，配置Gnocchi连接： 12345publishers: # set address of Gnocchi # + filter out Gnocchi-related activity meters (Swift driver) # + set default archive policy - gnocchi://?filter_project=service&amp;archive_policy=low 编辑/etc/ceilometer/ceilometer.conf文件并完成以下操作 在该[DEFAULT]部分中，配置RabbitMQ消息队列访问： 123[DEFAULT]...transport_url = rabbit://openstack:123456@controller 在该[service_credentials]部分中，配置服务凭据： 1234567891011[service_credentials]...auth_type = passwordauth_url = http://controller:5000/v3project_domain_id = defaultuser_domain_id = defaultproject_name = serviceusername = ceilometerpassword = 123456interface = internalURLregion_name = RegionOne 在Gnocchi创建Ceilometer资源。Gnocchi应该在这个阶段运行： 1# ceilometer-upgrade 完成安装启动Ceilometer服务并将其配置为在系统引导时启动： 1234# systemctl enable openstack-ceilometer-notification.service \ openstack-ceilometer-central.service# systemctl start openstack-ceilometer-notification.service \ openstack-ceilometer-central.service glance neutron服务配置Image 编辑/etc/glance/glance-api.conf文件并完成以下操作：在[DEFAULT]，[oslo_messaging_notifications]部分中，配置通知和RabbitMQ消息代理访问： 1234[DEFAULT]transport_url = rabbit://openstack:123456@controller[oslo_messaging_notifications]driver = messagingv2 编辑/etc/glance/glance-registry.conf文件并完成以下操作：在[DEFAULT]，[oslo_messaging_notifications]部分中，配置通知和RabbitMQ消息代理访问： 1234[DEFAULT]transport_url = rabbit://openstack:123456@controller[oslo_messaging_notifications]driver = messagingv2 完成安装重新启动Image服务： 1# systemctl restart openstack-glance-api.service openstack-glance-registry.service Neutron 配置网络服务以使用Ceilometer 编辑/etc/neutron/neutron.conf并完成以下操作：在这些[oslo_messaging_notifications]部分中，启用通知：123[oslo_messaging_notifications]...driver = messagingv2 完成安装 重启网络服务：1# systemctl restart neutron-server.service 配置环境变量及gnocchi文件夹权限更改目录权限，否则gnocchi存储文件数据时报错，没有权限 1# chmod +777 /var/lib/gnocchi /root/admin-openrc添加gnocchi相关环境变量 1# export OS_AUTH_TYPE=password 监控项列表注意：使用ceilometer监控虚拟机的memory.usage，要求libvirt版本1.1.1+，qemu版本1.5+。并且需要镜像支持balloon，即镜像中安装有balloon的driver。（一般linux镜像都默认包含，但是windows镜像需要另行安装）虚拟机的Cpu：使用时间（cpu）,使用率（cpu_util），分配vcpu个数（vcpus）虚拟机的硬盘：分配总大小（disk.root.size），占用宿主机大小（disk.usage）虚拟机的内存：总大小（memory），使用大小（memory.usage）虚拟机的网络：网络流量（bandwidth），网络下ip个数（ip.floating）虚拟机的镜像：镜像大小（image.download）节点的cpu、硬盘、内存等使用信息可通过linux常用命令监视 nova实例监控项 Name Type Unit Resource Origin Support Note 翻译 memory Gauge MB instance ID Notification Libvirt, Hyper-V Volume of RAM allocated to the instance 分配给实例的RAM量 memory.usage Gauge MB instance ID Pollster Libvirt, Hyper-V, vSphere, XenAPI Volume of RAM used by the instance from the amount of its allocated memory 实例从其分配的内存量中使用的RAM量 … 参考：https://docs.openstack.org/ceilometer/latest/admin/telemetry-measurements.html 详细监控方法介绍采集信息查询方法此方案中采集信息以gnocchi+文件方式存储。获取采集信息有两种方式，分别为 gnocchi-api和gnocchi 命令。以下采用gnocchi命令做详细介绍：注：数据存储分级：(资源项)resource-&gt;(资源指标条目)metric-&gt;(实际数据)measure 获取权限 1# . admin-openrc 获取监控资源列表 1# gnocchi resource list 获取实例监控资源对象信息列表获取某一instance下所有监控条目 12345678910111213141516171819202122232425[root@controller ~]# gnocchi resource show 8bb00e90-7e3f-5ef6-bee5-00e7c6bbc5fc+-----------------------+-------------------------------------------------------------------+| Field | Value |+-----------------------+-------------------------------------------------------------------+| created_by_project_id | e06fb4ce67a24aa687dffb9d8dcc6b1e || created_by_user_id | 4895e340408e42c383ea8d82e459b182 || creator | 4895e340408e42c383ea8d82e459b182:e06fb4ce67a24aa687dffb9d8dcc6b1e || ended_at | None || id | 8bb00e90-7e3f-5ef6-bee5-00e7c6bbc5fc || metrics | disk.device.allocation: 427a316e-1ef9-4054-8253-604b80e8f003 || | disk.device.capacity: 6915cd9b-1346-46db-8e86-438fd1884b49 || | disk.device.latency: fcfbc2ae-eddf-4ff9-bda9-33b9a2ba9c3d || | disk.device.read.bytes: 6df3416c-ad02-401e-84e4-5ac0b75febf2 || | disk.device.read.latency: 4014d3c6-51ea-4e24-b8e6-649ed6ee896d || | disk.device.usage: 7cd08e21-a0e1-4fce-8dc8-0e8b96d711d4 || | disk.device.write.bytes: b29abf7c-a9c4-4afc-89a5-ef766739028b || | disk.device.write.latency: f82d69ec-98d6-45e8-bc13-cd040f8cc2ef || original_resource_id | 86d618b5-aadc-4346-b620-7f44fc35c7ad-vda || project_id | 40026f6973464ee9a19ad04f6221e213 || revision_end | None || revision_start | 2019-05-07T05:08:10.450142+00:00 || started_at | 2019-05-07T05:08:10.450123+00:00 || type | instance_disk || user_id | 5a4da861d8e84cbdabd98b9804bc1547 |+-----------------------+-------------------------------------------------------------------+ 获取实例监控条目详细信息 1# gnocchi measures show 897356e6-d0bb-43cd-9cbd-43ab2808384d]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（九）Cinder服务]]></title>
    <url>%2F2019%2F08%2F01%2FOpenstack%2FOpenstackQueens9%2F</url>
    <content type="text"><![CDATA[存储服务概念OpenStack块存储服务(Cinder)将持久性存储添加到一个虚拟机。块存储提供了管理卷的基础设施，并与OpenStack计算交互，为实例提供卷。该服务还支持卷快照和卷类型的管理。块存储服务由以下组件组成:cinder-api接收API请求，并将其路由到cinders -volume以进行操作。cinder-volume直接与块存储服务和进程(如cinders -scheduler)交互。它还可以通过消息队列与这些进程进行交互。cinders -volume服务响应发送到块存储服务的读写请求，以维护状态。它可以通过驱动程序体系结构与各种存储提供者交互。cinder-scheduler daemon选择要在其上创建卷的最佳存储提供程序节点。与nova-scheduler类似的组件。cinder-backup daemonCinder-backup服务向备份存储提供程序提供任何类型的备份卷。与cinders -volume服务一样，它可以通过驱动程序体系结构与各种存储提供者交互。Messaging queue在块存储进程之间路由信息。 Controller节点：基础配置在安装和配置块存储服务之前，必须创建数据库、服务凭据和API端点。 创建数据库，为cinder数据库授权1234# mysql -uroot -p123456MariaDB [(none)]&gt; create database cinder;MariaDB [(none)]&gt; grant all privileges on cinder.* to 'cinder'@'localhost' identified by '123456';MariaDB [(none)]&gt; grant all privileges on cinder.* to 'cinder'@'%' identified by '123456'; 创建服务凭据生成管理凭证，以获得访问只有管理CLI命令: 1# . admin-openrc 创建cinder用户： 1# openstack user create --domain default --password-prompt cinder 添加admin角色到cinder用户中： （无返回值） 1# openstack role add --project service --user cinder admin 创建cinder2和cinderv3服务实体:注：块存储服务需要两个服务实体。 1234# openstack service create --name cinderv2 \ --description "OpenStack Block Storage" volumev2# openstack service create --name cinderv3 \ --description "OpenStack Block Storage" volumev3 123456# openstack endpoint create --region RegionOne \ volumev3 public http://controller:8776/v3/%\(project_id\)s# openstack endpoint create --region RegionOne \ volumev3 internal http://controller:8776/v3/%\(project_id\)s# openstack endpoint create --region RegionOne \ volumev3 admin http://controller:8776/v3/%\(project_id\)s 安装配置组件1# yum install -y openstack-cinder 编辑 /etc/cinder/cinder.conf文件1# vi /etc/cinder/cinder.conf 在[database]选项，配置数据库访问:12[database]connection = mysql+pymysql://cinder:123456@controller/cinder 在[DEFAULT]部分，配置RabbitMQ消息队列访问: 12[DEFAULT]transport_url = rabbit://openstack:123456@controller 在[DEFAULT]和[keystone_authtoken]选项，配置身份服务访问: 123456789101112[DEFAULT]auth_strategy = keystone[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_id = defaultuser_domain_id = defaultproject_name = serviceusername = cinderpassword = 123456 在[DEFAULT]选项，配置my_ip选项，使用Controller节点的管理接口IP地址: 12[DEFAULT]my_ip = 192.100.200.68 在[oslo_concurrency]选项，配置lock路径: 12[oslo_concurrency]lock_path = /var/lib/cinder/tmp 同步块存储数据（忽略此输出中的任何弃用消息。） 1# su -s /bin//sh -c "cinder-manage db sync" cinder 配置计算服务以使用块存储编辑 /etc/nova/nova.conf 文件 123# vi /etc/nova/nova.conf[cinder]os_regioon_name = RegionOne 启动服务123# systemctl restart openstack-nova-api.service# systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service# systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service 存储节点：安装LVM包:1# yum install -y lvm2 启动LVM元数据服务，并将其配置为在系统启动时启动:注：一些发行版默认安装LVM。 12# systemctl enable lvm2-lvmetad.service# systemctl start lvm2-lvmetad.service 创建LVM物理卷/dev/sdb:12# pvcreate /dev/sdb Physical volume "/dev/sdb" successfully created. 创建LVM卷组cinder-volmes:注：块存储服务在此卷组中创建逻辑卷。 12# vgcreate cinder-volumes /dev/sdb Volume group "cinder-volumes" successfully created 只有实例可以访问块存储卷。然而，底层操作系统管理与卷相关联的设备。默认情况下，LVM卷扫描工具扫描/dev目录中包含卷的块存储设备。如果项目在其卷上使用LVM，那么扫描工具将检测这些卷并试图缓存它们，这会导致底层操作系统和项目卷出现各种问题。必须重新配置LVM，以便只扫描包含cinder-volume卷组的设备。 编辑 /etc/lvm/lvm.conf文件在devices选项，添加一个接受/dev/sdb设备并拒绝所有其他设备的过滤器:注：filter数组中的每个项都以for accept或r for reject开头，并包含一个用于设备名称的正则表达式。数组必须以r/结束。*/ 拒绝任何剩余设备。您可以使用vgs -vvvv命令来测试过滤器。 1234devices &#123;...filter = [ "a/sdb/", "r/.*/"]...&#125; 安装配置组件1# yum install -y openstack-cinder targetcli python-keystone 编辑/etc/cinder/cinder.conf 文件1# vi /etc/cinder/cinder.conf 在[database]选项，配置数据库访问 12[database]connection = mysql+pymysql://cinder:123456@controller/cinder 在[DEFAULT]选项，配置RabbitMQ消息队列访问: 12[DEFAULT]transport_url = rabbit://openstack:123456@controller 在[DEFAULT]和[keystone_authtoken]选项，配置身份服务访问: 123456789101112[DEFAULT]auth_strategy = keystone[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_id = defaultuser_domain_id = defaultproject_name = serviceusername = cinderpassword = 123456 在[DEFAULT]部分，配置my_ip选项: 1my_ip = 192.168.100.69 在[DEFAULT]选项，配置映像服务API的位置: 1glance_api_servers = http://controller:9292 在[lvm]选项，使用lvm驱动程序、Cinder卷组、iSCSI协议和iSCSI服务配置lvm后端。如果[lvm]部分不存在，则添加它: 12345[lvm]volume_driver = cinder.volume.drivers.lvm.LVMVolumeDrivervolume_group = cinder-volumesiscsi_protocol = iscsiiscsi_helper = lioadm 在[DEFAULT]部分，启用LVM后端: 12[DEFAULT]enabled_backends = lvm 在[oslo_concurrency]节中，配置lock路径 12[oslo_concurrency]lock_path = /var/lib/cinder/tmp 开启服务启动块存储卷服务，包括它的依赖项，并配置它们在系统启动时启动: 12# systemctl enable openstack-cinder-volume.service target.service# systemctl restart openstack-cinder-volume.service target.service 校验操作生成临时环境变量 1# . admin-openrc 列出服务组件以验证每个流程的成功启动: 1# openstack volume service list 创建一个1G的卷，并查看其状态 12# cinder create --display-name myVolume 1# cinder list]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（八）计算节点实例首次孵化优化]]></title>
    <url>%2F2019%2F07%2F29%2FOpenstack%2FOpenstackQueens8%2F</url>
    <content type="text"><![CDATA[Controller节点：创建镜像缓存目录，并调整权限123# mkdir -p /var/lib/glance/imagecache# chmod -R 777 /var/lib/glance/images# chmod -R 777 /var/lib/glance/imagecache 配置共享文件夹，将与控制节点管理网卡同网段的CIDR配置入文件，并赋读写权限123# vim /etc/exports/var/lib/glance/imagecache 192.100.10.0/24(rw) 加载刚才的配置文件1# exportfs -e 注意控制节点的iptables，要放开111（rpc）、2049(nfs)和892(nfs挂载)端口，一般在OpenStack中这几个端口都是默认放开的。设置nfs服务开机启动，并启动nfs1234# systemctl enable rpcbind# systemctl enable nfs# systemctl restart rpcbind# systemctl restart nfs 确认本地共享目录是否正确（showmount -e）计算节点计算节点配置nfs挂载以及系统开机自动挂载有脚本实现在计算节点创建文件夹，并将项目源码中的脚本拷贝上去1# mkdir -p /var/www/kdpa/bin 将项目源码中/kdpa/bin/目录下的sed_rclocal.sh、mount_nfs.sh脚本拷贝到计算节点新创建的目录下1234567891011121314151617sed_rclocal.sh#!/usr/bin/env bashrc_local_file="/etc/rc.d/rc.local"chmod 755 $&#123;rc_local_file&#125;# add mount nfs shell in rc.localmount_nfs_sh="/var/www/kdpa/bin/mount_nfs.sh"chmod 755 $&#123;mount_nfs_sh&#125;echo "/usr/bin/sh $&#123;mount_nfs_sh&#125;"&gt;&gt;$&#123;rc_local_file&#125;# add ovs set-manager shell in rc.localovs_set_manager_sh="/var/www/kdpa/bin/ovs_set_manager.sh"chmod 755 $&#123;ovs_set_manager_sh&#125;echo "/usr/bin/sh $&#123;ovs_set_manager_sh&#125;"&gt;&gt;$&#123;rc_local_file&#125; 123456789101112mount_nfs.sh#!/usr/bin/env bashnfs_service_image_cache_path="/var/lib/glance/imagecache"local_image_cache_path="/var/lib/nova/instances/_base"controller_host=$(cat /etc/hosts | grep controller | awk '&#123;print $1&#125;')mkdir -p $&#123;local_image_cache_path&#125;chmod -R 777 $&#123;local_image_cache_path&#125;mount -t nfs4 $&#123;controller_host&#125;:$&#123;nfs_service_image_cache_path&#125; $&#123;local_image_cache_path&#125; 执行脚本mount_nfs.sh挂载控制节点nfs共享目录1# sh /var/www/kdpa/bin/mount_nfs.sh 验证挂载是否成功1# mount -l | grep 服务端IP 执行脚本sed_rclocal.sh调整系统开机启动脚本1# sh /var/www/kdpa/bin/sed_rclocal.sh 最终查看/etc/rc.d/rc.local文件是否添加成功]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAlchemy 中的 Engine 是什么]]></title>
    <url>%2F2019%2F07%2F17%2FMysql%2FSQLAlchemyEngine%2F</url>
    <content type="text"><![CDATA[连接池很重要，因为每次发送sql查询的时候都需要先建立连接，如果程序启动的时候事先就初始化一批连接放在连接池，每次用完后又放回连接池给其它请求使用，就能大大提高查询的效率。 Engine 初始化Engine 的初始化非常简单，通过工厂函数 create_engine 就可以创建。 123from sqlalchemy import create_engineengine = create_engine('mysql://user:password@localhost:3306/test?charset=utf8') 构建好 Engine 对象的同时，连接池和Dialect也创建好了，但是这时候并不会立马与数据库建立真正的连接，只有你调用 Engine.connect() 或者 Engine.execute(sql) 执行SQL请求的时候，才会建立真正的连接。因此 Engine 和 Pool 的行为称之为延迟初始化，等真正要派上用场的时候才去建立连接。 需要注意的是，创建引擎时，如果数据库的密码含有特殊字符，需要先编码处理 123&gt;&gt;&gt; import urllib.parse&gt;&gt;&gt; urllib.parse.quote_plus("kx%jj5/g")'kx%25jj5%2Fg' 其它数据库方言初始化 engine 的方式可参考官方文档： https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls create_engine 还有很多可选参数，这里介绍几个重要的参数。 12345engine = create_engine('mysql://user:password@localhost:3306/test?charset=utf8', echo=False pool_size=100, pool_recycle=3600, pool_pre_ping=True) echo ：为 True 时候会把sql语句打印出来，当然，你可以通过配置logger来控制输出，这里不做讨论。 pool_size： 是连接池的大小，默认为5个，0表示连接数无限制 pool_recycle： MySQL 默认情况下如果一个连接8小时内容没有任何动作（查询请求）就会自动断开链接，出现 MySQL has gone away的错误。设置了 pool_recycle 后 SQLAlchemy 就会在指定时间内回收连接。如果设置为3600 就表示 1小时后该连接会被自动回收。 pool_pre_ping ： 这是1.2新增的参数，如果值为True，那么每次从连接池中拿连接的时候，都会向数据库发送一个类似 select 1 的测试查询语句来判断服务器是否正常运行。当该连接出现 disconnect 的情况时，该连接连同pool中的其它连接都会被回收。 参考链接： https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls https://stackoverflow.com/questions/34322471/sqlalchemy-engine-connection-and-session-difference https://docs.sqlalchemy.org/en/13/core/pooling.html#dealing-with-disconnects]]></content>
      <categories>
        <category>SQLAlchemy</category>
      </categories>
      <tags>
        <tag>sqlalchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux top 命令详解]]></title>
    <url>%2F2019%2F07%2F12%2FLinux%2Ftop%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425$ toptop - 10:14:44 up 15 days, 20:18, 8 users, load average: 6.99, 3.36, 2.62Tasks: 985 total, 2 running, 983 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.7 us, 13.2 sy, 7.2 ni, 78.7 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16142800 total, 1201456 free, 14020500 used, 920844 buff/cacheKiB Swap: 8191996 total, 6339272 free, 1852724 used. 1396492 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND22195 root 20 0 4995348 264576 18712 S 7.9 1.6 26:02.20 gnome-shell28393 root 26 6 438932 95064 6416 S 3.3 0.6 16:52.90 python25155 root 20 0 163096 3436 1684 S 1.7 0.0 0:22.93 top 4092 root 20 0 413152 96096 4812 S 1.3 0.6 33:59.19 Xvnc23570 nova 26 6 456196 29632 4524 S 1.3 0.2 131:28.54 nova-conductor23724 nova 26 6 513364 42712 4908 S 1.3 0.3 135:03.59 nova-api12833 neutron 26 6 497996 135052 4608 S 1.0 0.8 59:59.61 neutron-dhcp-ag20537 nobody 20 0 254952 10144 4152 S 1.0 0.1 0:01.45 php-fpm28987 root 20 0 162940 3248 1620 R 1.0 0.0 0:00.22 top 5016 root 20 0 527732 3760 1500 S 0.7 0.0 0:34.49 ibus-daemon 7012 root 20 0 928104 26384 8988 S 0.7 0.2 9:19.03 gnome-terminal- 8040 openvsw+ 26 6 1316280 160352 12192 S 0.7 1.0 170:13.54 ovs-vswitchd 9408 etcd 26 6 11.6g 9896 2052 S 0.7 0.1 176:00.49 etcd23586 glance 26 6 502376 13540 4984 R 0.7 0.1 99:49.88 glance-api 1 root 26 6 201696 5700 2100 S 0.3 0.0 5:16.81 systemd 3 root 20 0 0 0 0 S 0.3 0.0 1:49.34 ksoftirqd/0 统计信息区前五行是系统整体的统计信息。 第一行是任务队列信息，同 uptime。 命令的执行结果。其内容如下： 10:14:44 系统当前时间 up 15 days, 20:18 系统运行时间，格式为时:分 8 users 当前登录用户数 load average: 6.99, 3.36, 2.62 系统负载，即任务队列的平均长度。 三个数值分别为1分钟、5分钟、15分钟前到现在的平均值。 第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下： Tasks: 985 total 进程总数 2 running 正在运行的进程数 983 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s): 0.7% us 用户空间占用CPU百分比 13.2% sy 内核空间占用CPU百分比 7.2% ni 用户进程空间内改变过优先级的进程占用CPU百分比 78.7% id 空闲CPU百分比 0.1% wa 等待输入输出的CPU时间百分比 0.0% hi 0.0% si 最后两行为内存信息。内容如下： Mem: 16142800 total 物理内存总量 14020500 used 使用的物理内存总量 1201456 free 空闲内存总量 920844 buff/cache 用作内核缓存的内存量 Swap: 8191996 total 交换区总量 1852724k used 使用的交换区总量 6339272 free 空闲交换区总量 1396492 avail Mem 统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态。 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 默认情况下仅显示比较重要的PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND列。可以通过下面的快捷键来更改显示内容。更改显示内容通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z可以将相应的列向左移动。最后按回车键确定。按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转。 命令使用1．工具（命令）名称top 2．工具（命令）作用显示系统当前的进程和其他状况；top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定. 3．环境设置在Linux下使用。 4．使用方法4．1使用格式top [-][d][p][q][c][C][S][s][n] 4．2参数说明 d 指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。 p 通过指定监控进程ID来仅仅监控某个进程的状态。 q 该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。 S 指定累计模式 s 使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。 i 使top不显示任何闲置或者僵死进程。 c 显示整个命令行而不只是显示命令名 4.3其他下面介绍在top命令执行过程中可以使用的一些交互命令。从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。 Ctrl+L 擦除并且重写屏幕。 h或者? 显示帮助画面，给出一些简短的命令总结说明。 k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。 i 忽略闲置和僵死进程。这是一个开关式命令。 q 退出程序。 r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。 S 切换到累计模式。 s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成ms。输入0值则系统将不断刷新，默认值是5s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。 f或者F 从当前显示中添加或者删除项目。 o或者O 改变显示项目的顺序。 l 切换显示平均负载和启动时间信息。 m 切换显示内存信息。 t 切换显示进程和CPU状态信息。 c 切换显示命令名称和完整命令行。 M 根据驻留内存大小进行排序。 P 根据CPU使用百分比大小进行排序。 T 根据时间/累计时间进行排序。 W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack命令行]]></title>
    <url>%2F2019%2F07%2F11%2FOpenstack%2FOpenstackTerminal%2F</url>
    <content type="text"><![CDATA[Keystone列出所有的用户123456789101112$ openstack user list+----------------------------------+-----------+| ID | Name |+----------------------------------+-----------+| 2ac5fe07105a43518ae444a37640222b | demo || 5bc73e84451b4e71906232bd3849422d | neutron || 84b0b75df69f4413a1380c9efc249b2d | placement || 87bf7fb4671f4524a6fa64ad75856594 | admin || 9aaa5aa26b414d35b37b851ccf749a55 | nova || eee2818e703e47c5a434e5926c90e7fb | glance |+----------------------------------+-----------+ 列出认证服务目录1234567891011121314151617181920212223242526272829303132333435363738394041$ openstack catalog list+-----------+-----------+-----------------------------------------+| Name | Type | Endpoints |+-----------+-----------+-----------------------------------------+| placement | placement | RegionOne || | | internal: http://controller:8778 || | | RegionOne || | | public: http://controller:8778 || | | RegionOne || | | admin: http://controller:8778 || | | || keystone | identity | RegionOne || | | internal: http://controller:5000/v3/ || | | RegionOne || | | public: http://controller:5000/v3/ || | | RegionOne || | | admin: http://controller:5000/v3/ || | | || neutron | network | RegionOne || | | public: http://controller:9696 || | | RegionOne || | | admin: http://controller:9696 || | | RegionOne || | | internal: http://controller:9696 || | | || glance | image | RegionOne || | | admin: http://controller:9292 || | | RegionOne || | | internal: http://controller:9292 || | | RegionOne || | | public: http://controller:9292 || | | || nova | compute | RegionOne || | | internal: http://controller:8774/v2.1 || | | RegionOne || | | admin: http://controller:8774/v2.1 || | | RegionOne || | | public: http://controller:8774/v2.1 || | | |+-----------+-----------+-----------------------------------------+ Glance列出您可以访问的镜像123456789101112131415161718$ openstack image list+--------------------------------------+---------------------+--------+| ID | Name | Status |+--------------------------------------+---------------------+--------+| 70d455f6-1a00-48f5-9b21-5f8fca019014 | centos7-mini | active || 1a7e4d60-3c26-41bb-be0c-34c467b2d3c3 | pstunnel | active || b2464312-8acb-4ff9-ba20-75560e5577f4 | pstunnelA | active || 705c7007-8a28-49e8-8df7-61bbfbf41bbd | pstunnelB | active || ad02946e-9c1f-42f0-9a9e-235ae7012bc3 | router | active || ae8c618d-3c6e-449c-9d2a-3f08bf84cc5e | router22 | active || b54361d4-bc24-46cb-94b2-b1f672b01c2a | sw-f-in-centos7_ext | active || 3a1adf75-c82e-4540-91e0-2167cb921612 | sw-f-in-centos7_int | active || ebfc7c40-4ac3-42ab-96ae-65e3c17af194 | sw-z-in-centos7_ext | active || 7355a66c-3f05-4ed5-9088-540faf71ebf8 | sw-z-in-centos7_int | active || 3b19c8ad-6012-406a-9e7f-e66416deeb1e | testforimage | active || 436c5ab5-14e7-4eb8-95b9-e47d85e60e83 | win7 | active |+--------------------------------------+---------------------+--------+ 查看一个指定的镜像12345678910111213141516171819202122232425$ openstack image show [IMAGE-ID/IMAGE-Name]$ openstack image show 70d455f6-1a00-48f5-9b21-5f8fca019014+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | f3ab346b3ca2b88d1347c24adf0b234b || container_format | bare || created_at | 2019-06-26T09:08:51Z || disk_format | qcow2 || file | /v2/images/70d455f6-1a00-48f5-9b21-5f8fca019014/file || id | 70d455f6-1a00-48f5-9b21-5f8fca019014 || min_disk | 0 || min_ram | 0 || name | centos7-mini || owner | 2e69bc10ab5f427bbbd6d40148d96309 || protected | False || schema | /v2/schemas/image || size | 3758882816 || status | active || tags | || updated_at | 2019-06-26T09:09:32Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 上传QCOW2镜像123456789101112131415161718192021222324$ openstack image create "centos7-mini2" --file centos7-mini.qcow2 --disk-format qcow2 --container-format bare --public+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | f3ab346b3ca2b88d1347c24adf0b234b || container_format | bare || created_at | 2019-07-11T07:56:51Z || disk_format | qcow2 || file | /v2/images/4072bdfb-f727-4e3f-a1f5-c3467b12a15e/file || id | 4072bdfb-f727-4e3f-a1f5-c3467b12a15e || min_disk | 0 || min_ram | 0 || name | centos7-mini2 || owner | 2e69bc10ab5f427bbbd6d40148d96309 || protected | False || schema | /v2/schemas/image || size | 3758882816 || status | active || tags | || updated_at | 2019-07-11T07:57:54Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 删除指定的镜像123$ openstack image delete [IMAGE-ID/IMAGE-Name]$ openstack image delete 4072bdfb-f727-4e3f-a1f5-c3467b12a15e Nova列出实例1234567891011121314$ openstack server list+--------------------------------------+-------------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+---------------------+| ID | Name | Status | Networks | Image | Flavor |+--------------------------------------+-------------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+---------------------+| 2ec1ace1-ef83-4d30-837e-f7f2df344a6c | n-UDYIQCS6 | SHUTOFF | network_5261=192.168.1.3 | win7 | win7 || 88a7d91d-3c29-461e-8d07-a0d272697a61 | n-L9QGOHRE | SHUTOFF | network_12177=192.168.1.19 | win7 | win7 || 274543b3-7890-4446-a5d0-1c6acfb9e1f4 | vm_n-4ejn7bk2c9o@28 | ACTIVE | network_10888=192.168.1.18 | win7 | win7 || c2cb7d6c-4f3e-4f32-bbd5-19639d415481 | sw_n-pf6p66vh4f_ext@33 | SHUTOFF | network_10360=192.168.1.3; n-XH29F3CG-net=8.8.8.9; network_21065=192.168.1.6; network_16174=192.168.1.5 | sw-z-in-centos7_ext | sw-z-in-centos7_ext || 5e009b71-4a8b-478a-9f17-349153a26ad4 | n-UE0N48YS | SHUTOFF | network_11645=192.168.1.4; network_14835=192.168.1.13; network_20101=192.168.1.9; internal=20.0.0.23, 192.100.200.225; network_18377=192.168.1.3; network_8075=192.168.1.10 | pstunnel | pstunnel || 374aedbe-d7c3-4f89-a66d-020401a257dc | n-MF9XYLTQ_int | SHUTOFF | network_23143=192.168.1.7; network_14693=192.168.1.7; network_13651=192.168.1.11 | sw-z-in-centos7_int | sw-z-in-centos7_int || acd8efcb-9350-4e19-a105-a1bcfb529697 | rt_n-une1ph6cts@20 | SHUTOFF | Rnet_n-une1ph6cts_0=192.168.3.1; Rnet_n-une1ph6cts_1=192.168.2.1 | router | router || 1efe6a9a-d005-4b32-926f-bb94fb702a05 | vm_n-vp0eo8lm0c@20 | SHUTOFF | network_14083=192.168.1.10 | | |+--------------------------------------+-------------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+---------------------+ 显示实例详细信息1234567891011121314151617181920212223242526272829303132333435$ openstack server show [SERVER-ID/SERVER-Name]$ openstack server show 2ec1ace1-ef83-4d30-837e-f7f2df344a6c+-------------------------------------+----------------------------------------------------------+| Field | Value |+-------------------------------------+----------------------------------------------------------+| OS-DCF:diskConfig | MANUAL || OS-EXT-AZ:availability_zone | nova || OS-EXT-SRV-ATTR:host | compute || OS-EXT-SRV-ATTR:hypervisor_hostname | compute || OS-EXT-SRV-ATTR:instance_name | instance-00000294 || OS-EXT-STS:power_state | Shutdown || OS-EXT-STS:task_state | None || OS-EXT-STS:vm_state | stopped || OS-SRV-USG:launched_at | 2019-07-11T06:30:19.000000 || OS-SRV-USG:terminated_at | None || accessIPv4 | || accessIPv6 | || addresses | network_5261=192.168.1.3 || config_drive | || created | 2019-07-11T06:30:12Z || flavor | win7 (fd8297ef-d7ac-4b4f-8c1e-1c90fcce488c) || hostId | 37f71a5ebb11ac3ed0f0496a313bb9246829f1da1839c8fd3dc4f98b || id | 2ec1ace1-ef83-4d30-837e-f7f2df344a6c || image | win7 (436c5ab5-14e7-4eb8-95b9-e47d85e60e83) || key_name | None || name | n-UDYIQCS6 || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || properties | || security_groups | name='default' || status | SHUTOFF || updated | 2019-07-11T06:31:30Z || user_id | 87bf7fb4671f4524a6fa64ad75856594 || volumes_attached | |+-------------------------------------+----------------------------------------------------------+ Neutron列出所有网络12345678$ openstack network list+--------------------------------------+----------------------+--------------------------------------+| ID | Name | Subnets |+--------------------------------------+----------------------+--------------------------------------+| 01e6c390-1d5e-4140-9ea3-98754bd0c58f | network_29287 | 8ed09dee-0e16-4514-8821-9a8e1f77c43a || 030f303e-e3d3-46e1-a85a-5ea6cea4d3ba | n-69PSABRW-net | e2ea53d0-1b29-43d3-910b-3296d96d004f |+--------------------------------------+----------------------+--------------------------------------+ 查看网络12345678910111213141516171819202122232425262728293031323334$ openstack network show NETWORK-ID$ openstack network show 01e6c390-1d5e-4140-9ea3-98754bd0c58f+---------------------------+--------------------------------------+| Field | Value |+---------------------------+--------------------------------------+| admin_state_up | UP || availability_zone_hints | || availability_zones | nova || created_at | 2019-06-19T02:16:06Z || description | || dns_domain | None || id | 01e6c390-1d5e-4140-9ea3-98754bd0c58f || ipv4_address_scope | None || ipv6_address_scope | None || is_default | None || is_vlan_transparent | None || mtu | 1500 || name | network_29287 || port_security_enabled | True || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || provider:network_type | vxlan || provider:physical_network | None || provider:segmentation_id | 29287 || qos_policy_id | None || revision_number | 3 || router:external | Internal || segments | None || shared | True || status | ACTIVE || subnets | 8ed09dee-0e16-4514-8821-9a8e1f77c43a || tags | || updated_at | 2019-06-19T02:16:07Z |+---------------------------+--------------------------------------+ 列出所有子网12345678$ openstack subnet list+--------------------------------------+-----------------------+--------------------------------------+------------------+| ID | Name | Network | Subnet |+--------------------------------------+-----------------------+--------------------------------------+------------------+| 00414731-ab21-4ee8-8bf2-86d960cc4339 | network_sub_18721 | 84d6ee39-77b3-4a0b-80f8-67922b63079a | 192.168.1.0/24 || 014cb2e2-bdbe-4849-aec7-5fe0581e3b67 | network_sub_20494 | 6eb235c5-798c-49de-8fd3-08aa64f9abaa | 192.168.1.0/24 |+--------------------------------------+-----------------------+--------------------------------------+------------------+ 查看子网12345678910111213141516171819202122232425262728$ openstack subnet show SUBNET-ID$ openstack subnet show 00414731-ab21-4ee8-8bf2-86d960cc4339+-------------------+--------------------------------------+| Field | Value |+-------------------+--------------------------------------+| allocation_pools | 192.168.1.2-192.168.1.254 || cidr | 192.168.1.0/24 || created_at | 2019-07-11T02:09:49Z || description | || dns_nameservers | || enable_dhcp | True || gateway_ip | 192.168.1.1 || host_routes | || id | 00414731-ab21-4ee8-8bf2-86d960cc4339 || ip_version | 4 || ipv6_address_mode | None || ipv6_ra_mode | None || name | network_sub_18721 || network_id | 84d6ee39-77b3-4a0b-80f8-67922b63079a || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || revision_number | 0 || segment_id | None || service_types | || subnetpool_id | None || tags | || updated_at | 2019-07-11T02:09:49Z |+-------------------+--------------------------------------+ 列出所有port12345678$ openstack port list+--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+| ID | Name | MAC Address | Fixed IP Addresses | Status |+--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+| 01f86921-016b-4df8-b526-ec81418b5df5 | | fa:16:3e:b9:c8:a8 | ip_address='20.0.0.2', subnet_id='c00a64e4-8921-427c-aa71-74f7a2c55954' | ACTIVE || 0280ba23-7a51-483c-a7a4-2351f277f739 | | fa:16:3e:ab:63:69 | ip_address='192.168.2.1', subnet_id='c4b84a4b-ce15-49e8-ae6b-72566224682c' | DOWN |+--------------------------------------+------+-------------------+--------------------------------------------------------------------------------+--------+ 查看port12345678910111213141516171819202122232425262728293031323334353637383940$ openstack port show PORT-ID$ openstack port show 01f86921-016b-4df8-b526-ec81418b5df5+-----------------------+-------------------------------------------------------------------------------+| Field | Value |+-----------------------+-------------------------------------------------------------------------------+| admin_state_up | UP || allowed_address_pairs | || binding_host_id | controller || binding_profile | || binding_vif_details | datapath_type='system', ovs_hybrid_plug='True', port_filter='True' || binding_vif_type | ovs || binding_vnic_type | normal || created_at | 2019-06-19T01:41:33Z || data_plane_status | None || description | || device_id | dhcpd3377d3c-a0d1-5d71-9947-f17125c357bb-361f196b-154a-4e51-bc34-7162d043be1b || device_owner | network:dhcp || dns_assignment | None || dns_name | None || extra_dhcp_opts | || fixed_ips | ip_address='20.0.0.2', subnet_id='c00a64e4-8921-427c-aa71-74f7a2c55954' || id | 01f86921-016b-4df8-b526-ec81418b5df5 || ip_address | None || mac_address | fa:16:3e:b9:c8:a8 || name | || network_id | 361f196b-154a-4e51-bc34-7162d043be1b || option_name | None || option_value | None || port_security_enabled | False || project_id | 2e69bc10ab5f427bbbd6d40148d96309 || qos_policy_id | None || revision_number | 6 || security_group_ids | || status | ACTIVE || subnet_id | None || tags | || trunk_details | None || updated_at | 2019-06-19T01:41:35Z |+-----------------------+-------------------------------------------------------------------------------+ 摘自：Openstack官方文档 https://docs.openstack.org/zh_CN/user-guide/cli-cheat-sheet.html]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack修改系统网络配额]]></title>
    <url>%2F2019%2F07%2F11%2FOpenstack%2FOpenstackNeutronQuotas%2F</url>
    <content type="text"><![CDATA[前言neutron在安装配置完成之后，openstack为了实现对所有tenant对网络资源的使用，针对neutron设置有专门的配额，以防止租户使用过多的资源，而对其他的tenant造成影响。和nova的quota相类似，neutron也使用单独的一个驱动来实现网络neutron的配额控制。 neutron默认的配额neutron默认的配额针对network，port，router，subnet，floatingip做了配额方面的限定，参考neutron的配置文件，获取quota的配额内容为: 12345678910111213141516[root@controller ~]# vim /etc/neutron/neutron.conf[quotas]quota_driver = neutron.db.quota_db.DbQuotaDriver 配额驱动quota_items = network,subnet,port quota限定的范畴default_quota = -1 默认的quota，-1表示没有限制(未启用)quota_network = 10 建立的network个数quota_subnet = 10 建立的subnet个数quota_port = 50 允许的port个数quota_security_group = 10 安全组的个数quota_security_group_rule = 100 安全组规规则条数quota_vip = 10 vip个数，以下的quota_member和quota_health_monitors 都用于LBaaS场景quota_pool = 10 pool个数quota_member = -1 member个数quota_health_monitors = -1 monitor个数quota_router = 10 router的个数quota_floatingip = 50 floating-ip个数 修改neutron的配额查看neutron默认的配额 123456789[root@controller ~]# keystone tenant-list+----------------------------------+----------+---------+| id | name | enabled |+----------------------------------+----------+---------+| 842ab3268a2c47e6a4b0d8774de805ae | admin | True || 7ff1dfb5a6f349958c3a949248e56236 | companyA | True | #得到tenant的uuid号| 10d1465c00d049fab88dec1af0f56b1b | demo | True || 3b57a14f7c354a979c9f62b60f31a331 | service | True |+----------------------------------+----------+---------+ 12345678910111213141516[root@controller ~]# neutron quota-show --tenant-id 7ff1dfb5a6f349958c3a949248e56236+---------------------+-------+| Field | Value |+---------------------+-------+| floatingip | 50 || health_monitor | -1 || member | -1 || network | 10 || pool | 10 || port | 50 | #port，每台虚拟机都需要一个ip，即一个port，很容易就超过配额| router | 10 || security_group | 10 || security_group_rule | 100 || subnet | 10 || vip | 10 |+---------------------+-------+ 修改neutron配额 12345678910111213141516[root@controller ~]# neutron quota-update --network 20 --subnet 20 --port 100 --router 5 --floatingip 100 --security-group 10 --security-group-rule 100 --tenant-id 7ff1dfb5a6f349958c3a949248e56236+---------------------+-------+| Field | Value |+---------------------+-------+| floatingip | 100 || health_monitor | -1 || member | -1 || network | 20 || pool | 10 || port | 100 || router | 5 || security_group | 10 || security_group_rule | 100 || subnet | 20 || vip | 10 |+---------------------+-------+ 校验neutron的quota配置 12345678910111213141516[root@controller ~]# neutron quota-show --tenant-id 7ff1dfb5a6f349958c3a949248e56236+---------------------+-------+| Field | Value |+---------------------+-------+| floatingip | 100 || health_monitor | -1 || member | -1 || network | 20 || pool | 10 || port | 100 || router | 5 || security_group | 10 || security_group_rule | 100 || subnet | 20 || vip | 10 |+---------------------+-------+ 统计port的个数1234567891011[root@controller ~]# neutron port-list+--------------------------------------+------+-------------------+---------------------------------------------------------------------------------------+| id | name | mac_address | fixed_ips |+--------------------------------------+------+-------------------+---------------------------------------------------------------------------------------+| 0060ec4a-957d-4571-b730-6b4a9bb3baf8 | | fa:16:3e:48:42:3d | &#123;"subnet_id": "9654a807-d4fa-49f1-abb6-2e45d776c69f", "ip_address": "10.16.4.19"&#125; || 00942be0-a3a9-471d-a4ba-336db0ee1539 | | fa:16:3e:73:75:03 | &#123;"subnet_id": "ad4a5ffc-3ccc-42c4-89a1-61e7b18632a3", "ip_address": "10.16.6.96"&#125; || 0119045c-8219-4744-bd58-a7e77294832c | | fa:16:3e:10:ed:7f | &#123;"subnet_id": "9654a807-d4fa-49f1-abb6-2e45d776c69f", "ip_address": "10.16.4.71"&#125; || 04f7d8ea-1849-4938-9ef7-e8114893132f | | fa:16:3e:50:86:1b | &#123;"subnet_id": "ad4a5ffc-3ccc-42c4-89a1-61e7b18632a3", "ip_address": "10.16.6.27"&#125; |[root@controller ~]# neutron port-list |wc -l #超过配额时，需要修改194 总结随着时间的推移，当越来越多的instance加入到openstack中，port也会相应增加，一个ip对应一个port，所以当port达到配额时，openstack会组织用户继续分配虚拟机，此时，就需要修改neutron的配额了，关于neutron配额的报错，可以参考neutron的日志/var/log/neutron/neutron-server.log，可以根据日志的信息，定位到报错的原因，具体不赘述。 附录neutron实现quota的代码解读 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197[root@controller ~]# vim /usr/lib/python2.6/site-packages/neutron/db/quota_db.pyimport sqlalchemy as safrom neutron.common import exceptionsfrom neutron.db import model_basefrom neutron.db import models_v2'''quota数据库表的表结构，tenant默认集成的配额从这里获取mysql&gt; desc quotas;+-----------+--------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-----------+--------------+------+-----+---------+-------+| id | varchar(36) | NO | PRI | NULL | || tenant_id | varchar(255) | YES | MUL | NULL | || resource | varchar(255) | YES | | NULL | || limit | int(11) | YES | | NULL | |+-----------+--------------+------+-----+---------+-------+'''class Quota(model_base.BASEV2, models_v2.HasId): """Represent a single quota override for a tenant. If there is no row for a given tenant id and resource, then the default for the quota class is used. """ tenant_id = sa.Column(sa.String(255), index=True) resource = sa.Column(sa.String(255)) limit = sa.Column(sa.Integer)'''quota配额的具体实现，根据数据库的配置内容，实现quota的控制，即quota的增删改查方法'''class DbQuotaDriver(object): """Driver to perform necessary checks to enforce quotas and obtain quota information. The default driver utilizes the local database. """ ''' 得到租户tenant的quota，执行neutron quota-show --tenant-id uuid时调用的方法 ''' @staticmethod def get_tenant_quotas(context, resources, tenant_id): """Given a list of resources, retrieve the quotas for the given tenant. :param context: The request context, for access checks. :param resources: A dictionary of the registered resource keys. :param tenant_id: The ID of the tenant to return quotas for. :return dict: from resource name to dict of name and limit """ # init with defaults 得到quota默认的配额项item，即所谓的network，subnet，port和router等，以及对应的值 tenant_quota = dict((key, resource.default) for key, resource in resources.items()) # update with tenant specific limits 从数据库中获取最新的quota配置信息，并更新 q_qry = context.session.query(Quota).filter_by(tenant_id=tenant_id) tenant_quota.update((q['resource'], q['limit']) for q in q_qry) return tenant_quota ''' quota的删除，即执行neutron quota-delete 的方法，删除之后，tenant将会集成默认的的quota配置 ''' @staticmethod def delete_tenant_quota(context, tenant_id): """Delete the quota entries for a given tenant_id. Atfer deletion, this tenant will use default quota values in conf. """ #从neutron。quotas数据库中查询到所有的quota配置之后，过略某个具体的tenant的quota，之后执行delete()方法将其删除 with context.session.begin(): tenant_quotas = context.session.query(Quota) tenant_quotas = tenant_quotas.filter_by(tenant_id=tenant_id) tenant_quotas.delete() ''' 得到所有租户tenant的配额资源，即执行neutron quota-list所查看的内容 ''' @staticmethod def get_all_quotas(context, resources): """Given a list of resources, retrieve the quotas for the all tenants. :param context: The request context, for access checks. :param resources: A dictionary of the registered resource keys. :return quotas: list of dict of tenant_id:, resourcekey1: resourcekey2: ... """ tenant_default = dict((key, resource.default) for key, resource in resources.items()) all_tenant_quotas = &#123;&#125; for quota in context.session.query(Quota): tenant_id = quota['tenant_id'] # avoid setdefault() because only want to copy when actually req'd #如果quotas表中，没有找到配置选项，说明使用默认的quota配置，直接用默认的copy过来即可，有配置则继承quotas表中的配置 tenant_quota = all_tenant_quotas.get(tenant_id) if tenant_quota is None: tenant_quota = tenant_default.copy() tenant_quota['tenant_id'] = tenant_id all_tenant_quotas[tenant_id] = tenant_quota tenant_quota[quota['resource']] = quota['limit'] return all_tenant_quotas.values() ''' 更新quota的配置，即执行neutron quota-update命令的具体实现 ''' @staticmethod def update_quota_limit(context, tenant_id, resource, limit): with context.session.begin(): tenant_quota = context.session.query(Quota).filter_by( tenant_id=tenant_id, resource=resource).first() #有配置内容，则更新，没有则根据资源的配置内容，在数据库中添加对应的条目 if tenant_quota: tenant_quota.update(&#123;'limit': limit&#125;) else: tenant_quota = Quota(tenant_id=tenant_id, resource=resource, limit=limit) context.session.add(tenant_quota) def _get_quotas(self, context, tenant_id, resources, keys): """Retrieves the quotas for specific resources. A helper method which retrieves the quotas for the specific resources identified by keys, and which apply to the current context. :param context: The request context, for access checks. :param tenant_id: the tenant_id to check quota. :param resources: A dictionary of the registered resources. :param keys: A list of the desired quotas to retrieve. """ desired = set(keys) sub_resources = dict((k, v) for k, v in resources.items() if k in desired) # Make sure we accounted for all of them... if len(keys) != len(sub_resources): unknown = desired - set(sub_resources.keys()) raise exceptions.QuotaResourceUnknown(unknown=sorted(unknown)) # Grab and return the quotas (without usages) quotas = DbQuotaDriver.get_tenant_quotas( context, sub_resources, tenant_id) return dict((k, v) for k, v in quotas.items()) ''' neutron quota的校验，即在执行过程中，调用该方法，确认tenant的quota是否在合理的范围内 ''' def limit_check(self, context, tenant_id, resources, values): """Check simple quota limits. For limits--those quotas for which there is no usage synchronization function--this method checks that a set of proposed values are permitted by the limit restriction. This method will raise a QuotaResourceUnknown exception if a given resource is unknown or if it is not a simple limit resource. If any of the proposed values is over the defined quota, an OverQuota exception will be raised with the sorted list of the resources which are too high. Otherwise, the method returns nothing. :param context: The request context, for access checks. :param tenant_id: The tenant_id to check the quota. :param resources: A dictionary of the registered resources. :param values: A dictionary of the values to check against the quota. """ # Ensure no value is less than zero quota的配置值不能为负数 unders = [key for key, val in values.items() if val &lt; 0] if unders: raise exceptions.InvalidQuotaValue(unders=sorted(unders)) # Get the applicable quotas quotas = self._get_quotas(context, tenant_id, resources, values.keys()) # Check the quotas and construct a list of the resources that # would be put over limit by the desired values overs = [key for key, val in values.items() if quotas[key] &gt;= 0 and quotas[key] &lt; val] if overs: raise exceptions.OverQuota(overs=sorted(overs)) 摘自：https://segmentfault.com/a/1190000018750816]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中InnoDB和MyISAM的存储引擎区别]]></title>
    <url>%2F2019%2F07%2F10%2FMysql%2FMysqlEngine%2F</url>
    <content type="text"><![CDATA[InnoDB存储引擎：InnoDB存储引擎支持事务，其设计目标主要就是面向OLTP（On Line Transaction Processing 在线事务处理）的应用。特点为行锁设计、支持外键，并支持非锁定读。从5.5.8版本开始，InnoDB成为了MySQL的默认存储引擎。 InnoDB存储引擎采用聚集索引（clustered）的方式来存储数据，因此每个表都是按照主键的顺序进行存放，如果没有指定主键，InnoDB会为每行自动生成一个6字节的ROWID作为主键。 MyISAM存储引擎：MyISAM存储引擎不支持事务、表锁设计，支持全文索引，主要面向OLAP（On Line Analytical Processing 联机分析处理）应用，适用于数据仓库等查询频繁的场景。在5.5.8版本之前，MyISAM是MySQL的默认存储引擎。该引擎代表着对海量数据进行查询和分析的需求。它强调性能，因此在查询的执行速度比InnoDB更快。 MyISAM存储引擎还有一个特点是只缓存索引文件，而不缓存数据文件，这点非常独特。 InnoDB和MyISAM的区别:事务为了数据库操作的原子性，我们需要事务。保证一组操作要么都成功，要么都失败，比如转账的功能。我们通常将多条SQL语句放在begin和commit之间，组成一个事务。 InnoDB支持，MyISAM不支持。 主键由于InnoDB的聚集索引，其如果没有指定主键，就会自动生成主键。MyISAM支持没有主键的表存在。 外键为了解决复杂逻辑的依赖，我们需要外键。比如高考成绩的录入，必须归属于某位同学，我们就需要高考成绩数据库里有准考证号的外键。 InnoDB支持，MyISAM不支持。 索引为了优化查询的速度，进行排序和匹配查找，我们需要索引。比如所有人的姓名从a-z首字母进行顺序存储，当我们查找zhangsan或者第44位的时候就可以很快的定位到我们想要的位置进行查找。 InnoDB是聚集索引，数据和主键的聚集索引绑定在一起，通过主键索引效率很高。如果通过其他列的辅助索引来进行查找，需要先查找到聚集索引，再查询到所有数据，需要两次查询。 MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据的指针。 从InnoDB 1.2.x版本，MySQL5.6版本后，两者都支持全文索引。 auto_increment对于自增数的字段，InnoDB要求必须有只有该字段的索引。但MyISAM可以将该字段与其他字段组成联合索引。 表行数很常见的需求是看表中有多少条数据，此时我们需要 1select count(*) from table_name; InnoDB不保存表行数，需要进行全表扫描。MyISAM用一个变量保存，直接读取该值，更快。当时当带有where查询的时候，两者一样。 存储数据库的文件都是需要在磁盘中进行存储，当应用需要时再读取到内存中。一般包含数据文件、索引文件。 InnoDB分为：.frm表结构文件.ibdata1共享表空间.ibd表独占空间.redo日志文件 MyISAM分为三个文件：.frm存储表定义.MYD存储表数据.MYI存储表索引 执行速度如果你的操作是大量的查询操作，如SELECT，使用MyISAM性能会更好。如果大部分是删除和更改的操作，使用InnoDB。 delete调用delete from table时，MyISAM会直接重建表，InnoDB会一行一行的删除，但是可以用truncate table代替。 锁MyISAM仅支持表锁，每次操作锁定整张表。InnoDB支持行锁，每次操作锁住最小数量的行数据。 表锁相比于行锁消耗的资源更少，且不会出现死锁，但同时并发性能差。行锁消耗更多的资源，速度较慢，且可能发生死锁，但是因为锁定的粒度小、数据少，并发性能好。如果InnoDB的一条语句无法确定要扫描的范围，也会锁定整张表。 当行锁发生死锁的时候，会计算每个事务影响的行数，然后回滚行数较少的事务。 数据恢复MyISAM崩溃后无法快速的安全恢复。InnoDB有一套完善的恢复机制。 数据缓存MyISAM仅缓存索引数据，通过索引查询数据。InnoDB不仅缓存索引数据，同时缓存数据信息，将数据按页读取到缓存池，按LRU（Latest Rare Use 最近最少使用）算法来进行更新。 如何选择存储引擎创建表的语句都是相同的，只有最后的type来指定存储引擎。 MyISAM1.大量查询总count2.查询频繁，插入不频繁3.没有事务操作 InnoDB1.需要高可用性，或者需要事务2.表更新频繁 摘自：https://segmentfault.com/a/1190000019713794]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 1040 Too many connections 错误与解决办法]]></title>
    <url>%2F2019%2F07%2F01%2FMysql%2FTooManyConnections%2F</url>
    <content type="text"><![CDATA[日志报如下错误: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364Traceback (most recent call last): File &quot;/var/www/kdpa/project/api/host.py&quot;, line 339, in showInstanceConsole File &quot;/var/www/kdpa/project/api/hostImpl.py&quot;, line 500, in showInstanceConsoleImpl opsVmId = self.hostDao.getOpsVmIdByUuid(uuid) File &quot;/var/www/kdpa/project/core/modifier.py&quot;, line 46, in _dao return daoFn(*args, **kwargs) File &quot;/var/www/kdpa/project/dao/host/hostDao.py&quot;, line 168, in getOpsVmIdByUuid host = session.query(Host).filter(Host.uuid == str(uuid)).first() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3222, in first ret = list(self[0:1]) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3012, in __getitem__ return list(res) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3324, in __iter__ return self._execute_and_instances(context) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3346, in _execute_and_instances querycontext, self._connection_from_session, close_with_result=True File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3361, in _get_bind_args mapper=self._bind_mapper(), clause=querycontext.statement, **kw File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/query.py&quot;, line 3339, in _connection_from_session conn = self.session.connection(**kw) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/session.py&quot;, line 1124, in connection execution_options=execution_options, File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/session.py&quot;, line 1130, in _connection_for_bind engine, execution_options File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/orm/session.py&quot;, line 431, in _connection_for_bind conn = bind._contextual_connect() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 2226, in _contextual_connect self._wrap_pool_connect(self.pool.connect, None), File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 2266, in _wrap_pool_connect e, dialect, self File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 1536, in _handle_dbapi_exception_noconnection util.raise_from_cause(sqlalchemy_exception, exc_info) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/util/compat.py&quot;, line 399, in raise_from_cause reraise(type(exception), exception, tb=exc_tb, cause=cause) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/base.py&quot;, line 2262, in _wrap_pool_connect return fn() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 363, in connect return _ConnectionFairy._checkout(self) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 760, in _checkout fairy = _ConnectionRecord.checkout(pool) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 492, in checkout rec = pool._do_get() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/impl.py&quot;, line 139, in _do_get self._dec_overflow() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/util/langhelpers.py&quot;, line 68, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/impl.py&quot;, line 136, in _do_get return self._create_connection() File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 308, in _create_connection return _ConnectionRecord(self) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 437, in __init__ self.__connect(first_connect_check=True) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/pool/base.py&quot;, line 639, in __connect connection = pool._invoke_creator(self) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/strategies.py&quot;, line 114, in connect return dialect.connect(*cargs, **cparams) File &quot;/usr/lib64/python2.7/site-packages/sqlalchemy/engine/default.py&quot;, line 451, in connect return self.dbapi.connect(*cargs, **cparams) File &quot;build/bdist.linux-x86_64/egg/MySQLdb/__init__.py&quot;, line 81, in Connect return Connection(*args, **kwargs) File &quot;build/bdist.linux-x86_64/egg/MySQLdb/connections.py&quot;, line 187, in __init__ super(Connection, self).__init__(*args, **kwargs2)OperationalError: (_mysql_exceptions.OperationalError) (1040, &apos;Too many connections&apos;)(Background on this error at: http://sqlalche.me/e/e3q8) 解决方式： 查看当前数据库最大连接数： 1234567MariaDB [(none)]&gt; select VARIABLE_VALUE from information_schema.GLOBAL_VARIABLES where VARIABLE_NAME='MAX_CONNECTIONS';+----------------+| VARIABLE_VALUE |+----------------+| 214 |+----------------+1 row in set (0.00 sec) 12345vi /etc/systemd/system/mariadb.service.d/limits.conf[Service]LimitNOFILE=65535LimitNPROC=65535 保存，退出。 12systemctl daemon-reloadsystemctl restart mariadb.service 重启后查看： 1234567MariaDB [(none)]&gt; select VARIABLE_VALUE from information_schema.GLOBAL_VARIABLES where VARIABLE_NAME='MAX_CONNECTIONS';+----------------+| VARIABLE_VALUE |+----------------+| 4096 |+----------------+1 row in set (0.00 sec) 4096配置在Openstack的mysql配置 /etc/my.cnf.d/openstack.cnf中max_connections = 4096。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[压力测试工具ab使用方法]]></title>
    <url>%2F2019%2F06%2F28%2FLinux%2Fab%2F</url>
    <content type="text"><![CDATA[安装在CentOS7-mini环境下，ab运行需要依赖apr-util，httpd-tools包，安装命令为： 1yum install apr-util httpd-tools -y 执行测试12#vi post.txtuuid=n-vp0eo8lm0c&amp; 1ab -c 10 -n 10 -p 'post.txt' -T 'application/x-www-form-urlencoded' http://192.100.200.140:8000/api/instance/show 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.100.200.140 (be patient).....doneServer Software: nginx/1.9.9Server Hostname: 192.100.200.140Server Port: 8000Document Path: /api/instance/showDocument Length: 23 bytesConcurrency Level: 10Time taken for tests: 1.378 secondsComplete requests: 10Failed requests: 6 (Connect: 0, Receive: 0, Length: 6, Exceptions: 0)Write errors: 0Non-2xx responses: 3Total transferred: 3398 bytesTotal body sent: 1940HTML transferred: 1787 bytesRequests per second: 7.26 [#/sec] (mean)Time per request: 1377.853 [ms] (mean)Time per request: 137.785 [ms] (mean, across all concurrent requests)Transfer rate: 2.41 [Kbytes/sec] received 1.37 kb/s sent 3.78 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.1 0 1Processing: 68 543 548.0 246 1256Waiting: 68 543 548.0 246 1256Total: 69 544 548.0 247 1257Percentage of the requests served within a certain time (ms) 50% 247 66% 1095 75% 1157 80% 1196 90% 1257 95% 1257 98% 1257 99% 1257 100% 1257 (longest request) 参数说明：-n 10 表示请求总数为10 -c 10 表示并发用户数为10 http://192.100.200.140:8000/api/instance/show 表示这写请求的目标URL 测试结果也一目了然，测试出的吞吐率为：Requests per second: 2015.93 [#/sec] (mean) 初次之外还有其他一些信息。 Server Software 表示被测试的Web服务器软件名称 Server Hostname 表示请求的URL主机名 Server Port 表示被测试的Web服务器软件的监听端口 Document Path 表示请求的URL中的根绝对路径，通过该文件的后缀名，我们一般可以了解该请求的类型 Document Length 表示HTTP响应数据的正文长度 Concurrency Level 表示并发用户数，这是我们设置的参数之一 Time taken for tests 表示所有这些请求被处理完成所花费的总时间 Complete requests 表示总请求数量，这是我们设置的参数之一 Failed requests 表示失败的请求数量，这里的失败是指请求在连接服务器、发送数据等环节发生异常，以及无响应后超时的情况。如果接收到的HTTP响应数据的头信息中含有2XX以外的状态码，则会在测试结果中显示另一个名为 “Non-2xx responses”的统计项，用于统计这部分请求数，这些请求并不算在失败的请求中。 Total transferred 表示所有请求的响应数据长度总和，包括每个HTTP响应数据的头信息和正文数据的长度。注意这里不包括HTTP请求数据的长度，仅仅为web服务器流向用户PC的应用层数据总长度。 HTML transferred 表示所有请求的响应数据中正文数据的总和，也就是减去了Total transferred中HTTP响应数据中的头信息的长度。 Requests per second 吞吐率，计算公式：Complete requests / Time taken for tests Time per request 用户平均请求等待时间，计算公式：Time token for tests/（Complete requests/Concurrency Level） Time per requet(across all concurrent request) 服务器平均请求等待时间，计算公式：Time taken for tests/Complete requests，正好是吞吐率的倒数。也可以这么统计：Time per request/Concurrency Level Transfer rate 表示这些请求在单位时间内从服务器获取的数据长度，计算公式：Total trnasferred/ Time taken for tests，这个统计很好的说明服务器的处理能力达到极限时，其出口宽带的需求量。 Percentage of requests served within a certain time（ms） 这部分数据用于描述每个请求处理时间的分布情况，比如以上测试，80%的请求处理时间都不超过6ms，这个处理时间是指前面的Time per request，即对于单个用户而言，平均每个请求的处理时间。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验室虚拟化主站厂站拓扑搭建]]></title>
    <url>%2F2019%2F06%2F25%2FOther%2FkdpaTopo%2F</url>
    <content type="text"><![CDATA[虚拟化正向隔离①创建虚拟化正向隔离组件 SW_1，开机②创建虚拟交换机 Switch_2，开机③创建虚拟交换机 Switch_3，开机④创建虚拟主机[win7-2-ok]-主站PC PC_4，开机⑤创建虚拟主机[win7-2-ok]-安全三区PC PC_5，开机⑥创建虚拟主机[win7-2-ok]-隔离SW_1管理工具 PC_6，开机⑦配置PC_4IP地址：192.168.1.10 255.255.255.0 192.168.1.1⑧配置PC_5IP地址：192.168.1.20 255.255.255.0 192.168.1.1⑨配置Switch_2：1-4口配置VLAN1001⑩配置Switch_3：1-4口配置VLAN1002⑪创建串口线，连接SW_1串口（内）与PC_6⑫创建网线，连接SW_1网卡0（内）与Switch_2网口1⑬创建网线，连接SW_1网卡0（外）与Switch_3网口1⑭创建网线，连接PC_4网卡0与Switch_2网口2⑮创建网线，连接PC_5网卡0与Switch_3网口2⑯配置正向隔离管理工具PC_6：配置管理工具。 PC_6右键 -&gt; 上传/下载 -&gt; 传入vc_redist.2015.x64与全QT界面隔离管理工具中包含vcruntime140.dll，libcrypto-1_1.dll。 -&gt; 关闭 安装vc_redist.2015.x64 打开全QT界面隔离管理工具Stonewall.exe 屏幕分辨率 -&gt; 1024×768 用户名：admin 密码：111111 串口登录。 串口：COM1。 频率：115200。 权限：管理员。 √ 正向隔离。 设备配置 -&gt; 基本配置 管理IP： 无 -&gt; 不填 设备名称： zsw -&gt; 自定义 点击写入 规则配置 -&gt; 主机信息1 -&gt; 添加 SW_1 -&gt; 进入内网隔离系统 -&gt; 清除主机信息与连接信息 -&gt; 删除/etc/mac.conf 和 /etc/rules √ IP和MAC地址绑定 主机名： PC_4 -&gt; 自定义 MAC1： FA:16:3E:40:11:01 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.10 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.11 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 主机信息2 -&gt; 添加 √ IP和MAC地址绑定 主机名： PC_5 -&gt; 自定义 MAC1： FA:16:3E:40:11:02 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.20 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.21 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 连接信息 规则名： rule -&gt; 自定义 (内网)IP地址： 192.100.1.10 (内网)虚拟IP： 192.100.1.11 (内网)网口号： ETH0/网口0 (外网)IP地址： 192.100.1.20 (外网)虚拟IP： 192.100.1.21 (外网)网口号： ETH0/网口0 协议： TCP ⑰配置后查看SW_1 /etc/mac.conf和/etc/rules是否与配置相同。重启SW_1内网隔离与外网隔离。 正向隔离： 发送端为内网 接收端为外网 sender：PC_4 receiver：PC_5 ⑱配置及启动正向隔离外网接收端工具。 PC_5 -&gt; 进入系统 -&gt; 右键 -&gt; Terminal -&gt; 以管理员身份运行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\正向\receive 以jar包方式运行 java -jar StoneWall-recv.jar ⑲配置及启动正向隔离内网发送端工具。 PC_4 -&gt; 进入系统 -&gt; 右键 -&gt; Terminal -&gt; 以管理员身份运行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\send 以jar包方式运行 java -jar StoneWall-send.jar 待发送的文件（任何类型）-&gt; 右键 -&gt; 发送 任务名称： task √ 主任务 目的IP地址： 192.168.1.21 -&gt; 接收端虚拟IP地址 目的端口号： 7777 目的文件夹： d:/test -&gt; 自定义 √ 立即发送 查看日志及接收端是否发送成功。 虚拟化反向隔离⑳创建虚拟化反向隔离组件 SW_2，开机㉑创建虚拟主机[win7-2-ok]-隔离SW_2管理工具 PC_7，开机㉒创建串口线，连接SW_2串口（外）与PC_7㉓创建网线，连接SW_2网卡0（内）与Switch_2网口3㉔创建网线，连接SW_2网卡0（外）与Switch_3网口3㉕⑯配置反向隔离管理工具PC_7：配置管理工具。 PC_7右键 -&gt; 上传/下载 -&gt; 传入vc_redist.2015.x64与全QT界面隔离管理工具中包含vcruntime140.dll，libcrypto-1_1.dll。 -&gt; 关闭 安装vc_redist.2015.x64 打开全QT界面隔离管理工具Stonewall.exe 屏幕分辨率 -&gt; 1024×768 用户名：admin 密码：111111 串口登录。 串口：COM1。 频率：115200。 权限：管理员。 √ 反向隔离。 设备配置 -&gt; 基本配置 管理IP： 无 -&gt; 不填 设备名称： fsw -&gt; 自定义 ETH0协商IP： 192.168.1.200 -&gt; 与发送端须配置成相同网段 ETH1协商IP： 0.0.0.0 -&gt; 可不做配置 规则配置 -&gt; 主机信息1 -&gt; 添加 SW_2 -&gt; 进入外网隔离系统 -&gt; 清除主机信息与连接信息 -&gt; 删除/etc/mac.conf 和 /etc/rules √ IP和MAC地址绑定 主机名： PC_5 -&gt; 自定义 MAC1： FA:16:3E:40:11:02 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.20 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.22 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 主机信息2 -&gt; 添加 √ IP和MAC地址绑定 主机名： PC_4 -&gt; 自定义 MAC1： FA:16:3E:40:11:01 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.10 -&gt; 主机网卡ip地址 主机虚拟IP1：192.168.1.12 -&gt; ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 连接信息 规则名： rule -&gt; 自定义 (内网)IP地址： 192.100.1.10 (内网)虚拟IP： 192.100.1.12 (内网)网口号： ETH0/网口0 (外网)IP地址： 192.100.1.20 (外网)虚拟IP： 192.100.1.22 (外网)网口号： ETH0/网口0 协议： UDP 证书秘钥 -&gt; 设备秘钥 设备密钥 √ RSA -&gt; 导出设备证书文件 -&gt; fsw.cer 上传/下载 -&gt; fsw.cer导出到本地 ㉖配置及启动反向隔离内网接收端工具。 上传/下载 -&gt; 新的隔离接收端工具new_udp_recv_4.2.2.jar -&gt; 复制到目录D:\software\隔离传输软件\反向\receive\下 右键 -&gt; Terminal -&gt; 以管理员身份运行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\反向\receive 以jar包方式运行 java -jar new_udp_recv_4.2.2.jar ㉗配置及启动反向隔离外网发送端工具。 上传/下载 -&gt; 新的隔离接收端工具new_udp_send_4.2.2.jar -&gt; 复制到目录D:\software\隔离传输软件\反向\send\下 上传/下载 -&gt; 反向隔离端证书 fsw.cer 检查config目录下是否有**.p12文件，若存在，则删除。 启动传输软件。 new_udp_recv_4.2.2.jar 右键 -&gt; 以管理员身份运行 -&gt; 命令行 -&gt; 进入目录 -&gt; D:\software\隔离传输软件\反向\send 12java -jar new_udp_recv_4.2.2.jar设置密码口令保护窗口如果报错，需先运行jreUpdate1.8.jar 出现提示：系统检测到密钥尚未存在，是否需要生成密钥？ -&gt; 是 创建登录口令：123456。 确定，提示操作成功。 登录窗口： 操作员名称： administrator 操作员密码： 12345678 密钥保护口令： 123456 管理 -&gt; 密钥管理 -&gt; 导出密钥。 -&gt; sender.cer 上传/下载 -&gt; 反向隔离发送端证书 sender.cer 设定 -&gt; 配置加密隧道 隧道名称： Tunnel-1 隧道的协商IP地址： 192.168.1.200 -&gt; 设备ETH0协商IP 隧道的协商端口： 4558 隧道每次通过的文件数： 100 隔离设备证书路径： ../.. fsw.cer 设定 -&gt; 配置链路信息 链路名称： Link-1 目的IP地址： 192.168.1.12 -&gt; 接收端IP地址，正反向隔离在相同环境的情况下，配置虚拟IP。 目的端口： 7777 发送失败等待周期(秒)： 30 使用隧道： Tunnel-1 ㉘PC_7导入发送端证书。 发送端证书 -&gt; 删除其他 发送端证书 -&gt; 添加 发送端IP： 192.168.1.20 -&gt; 此处为发送端IP，不为虚拟IP 证书标识： sender.cer ㉙重启SW_2内网隔离与外网隔离。㉚PC_5发送E文本。 待发送的文件（E文本）-&gt; 右键 -&gt; 发送 任务名称： task1 目的文件夹： d:/test -&gt; 自定义 选择链路 -&gt; Link-1 -&gt; 添加 不符合发送条件的文件备份至 -&gt; 当前文档目录 查看日志及接收端是否发送成功。 如果发现隔离发送进行中一直在校验E文本规范，不发送的情况，重新打开发送端工具。 虚拟化纵向㉛创建虚拟化纵向[电力纵向]PS_1，开机㉜创建虚拟化纵向[电力纵向]PS_2，开机㉝创建虚拟路由器R，配置：网卡1：192.168.1.0/24 网卡2：192.168.2.0/24，开机㉞创建虚拟交换机 Switch_1，开机㉟创建虚拟主机[win7-2]PC_3，开机㊱创建虚拟主机[win7-2]PC_2，开机㊲创建虚拟主机[win7-2]PC_1，开机㊳创建虚拟USB-KEY UK_1，插入PS_1㊴创建虚拟USB-KEY UK_2，插入PS_2㊵配置Switch_1：1-2口配置VLAN1003㊶配置PC_3IP地址：169.254.200.201 255.255.255.0 169.254.200.1㊷配置PC_2IP地址：169.254.200.201 255.255.255.0 169.254.200.1㊸配置PC_1IP地址：192.168.2.20 255.255.255.0 192.168.2.1㊹创建网线，连接PS_1网口0与Switch_2网口4㊺创建网线，连接PS_1网口1与R网口1㊻创建网线，连接PS_2网口1与R网口2㊼创建网线，连接PS_2网口0与Switch_1网口1㊽创建网线，连接PC_1网卡0与Switch_1网口2㊾创建网线，连接PC_2网卡0与PS_2网卡4㊿创建网线，连接PC_3网卡0与PS_1网卡4(51)PC_3本地安装及配置纵向PS_1：安装纵向管理工具： 目录地址：d:/software/PSTunnel2000加密装置千兆管理工具.exe 屏幕分辨率 -&gt; 1024×768添加新操作员： 管理工具 -&gt; 右键 -&gt; 以管理员身份运行 操作员：init 密码：Tun-2000 设备IP：169.254.200.200 -&gt; 操作员 -&gt; 操作员管理 -&gt; 添加：+操作员： user -&gt; 确定导出导入证书： 初始化 -&gt; 生成设备密钥及证书请求 -&gt; 下一步 -&gt; 填写省/市/设备名 -&gt; 下一步 -&gt; 生成.csr证书 证书转换。使用证书工具2.0将.csr证书转换为.cer证书。传入对端。 证书 -&gt; 证书导入 -&gt; 远程设备证书 -&gt; 选择证书 -&gt; 确定VLAN配置： 本地ETH1：192.168.1.50 255.255.255.0 VLAN：0 远程ETH1：192.168.2.50 255.255.255.0 VLAN：0路由配置： 目的地址：192.168.2.50 子网掩码：255.255.255.0 网关地址：192.168.1.1安全隧道: -&gt; 恢复隧道配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改隧道 -&gt; 确定 隧道名标识： 11 -&gt; 不支持修改 本地IP： 192.168.1.50 -&gt; 本地ETH1 远程IP： 192.168.2.50 -&gt; 远程ETH1 255.255.255.0 0.0.0.0 0.0.0.0 MTU： 1500安全策略： -&gt; 恢复策略配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改策略 -&gt; 确定 标识id：0 本地IP： 192.168.1.50 -&gt; 本地ETH1 远程IP： 192.168.2.50 -&gt; 远程ETH1 本地起始IP：192.168.1.1 本地终止IP：192.168.1.254 远程起始IP：192.168.2.1 远程终止IP：192.168.2.254 方向：双向 重置隧道： -&gt; 管理 -&gt; 重置隧道 -&gt; OPENED 注意： *新纵向的用户名,密码：root, Tun-2000 纵向内部查询路由命令：1$ monipead.arm -all (52)PC_2本地安装及配置纵向PS_2：配置与以上相同，反向。 (53)PC_4配置静态路由：1route add -p 192.168.2.0 mask 255.255.255.0 192.168.1.1 (54)PC_1配置静态路由：1route add -p 192.168.1.0 mask 255.255.255.0 192.168.2.1 (55)验证纵向的功能：使用PC_4 ping PC_1 1ping 192.168.2.50 查看PS_2的eth1口是否抓到ESP报文包。]]></content>
      <categories>
        <category>Kedong</category>
      </categories>
      <tags>
        <tag>kedong</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化隔离安装配置说明]]></title>
    <url>%2F2019%2F06%2F21%2FOther%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E9%9A%94%E7%A6%BB%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[虚拟化隔离安装配置说明创建纵向隔离组件[反向隔离] SW。创建主机组件[win7] PC。SW与PC通过串口线连接。 配置管理工具。打开QT界面隔离管理工具。 前提：windows虚拟机已经安装vc_redist.2015.x64 且QT管理工具中包含vcruntime140.dll，libcrypto-1_1.dll。 用户名：admin 密码：111111 串口登录。 串口：COM1。 频率：115200。 √ 反向隔离。 设备配置 -&gt; 基本配置 管理IP： 无 -&gt; 不填 设备名称： dev -&gt; 自定义 ETH0协商IP： 192.168.1.100 -&gt; 与发送端须配置成相同网段 ETH1协商IP： 0.0.0.0 -&gt; 可不做配置 规则配置 -&gt; 主机信息1 -&gt; 添加 √ IP和MAC地址绑定 主机名： sender -&gt; 自定义 MAC1： FA:16:3E:40:11:01 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.10 -&gt; 主机网卡ip地址 主机虚拟IP1：ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 主机信息2 -&gt; 添加 √ IP和MAC地址绑定 主机名： receiver -&gt; 自定义 MAC1： FA:16:3E:40:11:02 -&gt; 主机网卡MAC地址 主机IP： 192.168.1.20 -&gt; 主机网卡ip地址 主机虚拟IP1：ETH0协商IP与主机同网段时自动生成,不通网段时填写一个ETH0所在网段下任意IP地址 主机虚拟ip2：可以不填 规则配置 -&gt; 连接信息 规则名： rule -&gt; 自定义 (内网)IP地址： 192.100.1.10 (内网)虚拟IP： 192.100.1.10 (内网)网口号： ETH0/网口0 (外网)IP地址： 192.100.1.20 (外网)虚拟IP： 192.100.1.20 (外网)网口号： ETH0/网口0 协议： UDP（反向） TCP正向 证书互导 设备密钥 √ RSA -&gt; 导出设备证书文件 -&gt; dev.cer 发送端证书 -&gt; 添加 发送端IP： 192.168.1.14 -&gt; 此处为发送端IP，不为虚拟IP 证书标识： sender.cer 管理工具配置好隔离之后，正反向隔离需重启生效。主机信息位置：/etc/mac.conf连接信息位置：/etc/rules 传输软件配置 检查config目录下是否有**.p12文件，若存在，则删除。 启动传输软件。 Stonewall-2000-Send.jar 右键 -&gt; 以管理员身份运行 -&gt; 命令行 -&gt; 12java -jar Stonewall-2000-Send.jar设置密码口令保护窗口如果报错，需先运行jreUpdate1.8.jar 出现提示：系统检测到密钥尚未存在，是否需要生成密钥？ -&gt; 是 创建登录口令：123456。 确定，提示操作成功。 登录窗口： 操作员名称： administrator 操作员密码： 12345678 密钥保护口令： 123456 管理 -&gt; 密钥管理 -&gt; 导出密钥。 -&gt; sender.cer 设定 -&gt; 配置加密隧道 隧道名称： Tunnel-1 隧道的协商IP地址： 192.168.1.100 -&gt; 设备ETH0协商IP 隧道的协商端口： 4558 隧道每次通过的文件数： 100 隔离设备证书路径： ../.. dev.cer 设定 -&gt; 配置链路信息 链路名称： Link-1 目的IP地址： 192.168.1.13 -&gt; 接收端IP地址，正反向隔离在相同环境的情况下，配置虚拟IP。 目的端口： 7777 发送失败等待周期(秒)： 30 使用隧道： Tunnel-1]]></content>
      <categories>
        <category>Eletric Power</category>
      </categories>
      <tags>
        <tag>eletric power</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Too many open files 错误与解决办法]]></title>
    <url>%2F2019%2F06%2F20%2FOpenstack%2FTooManyFiles%2F</url>
    <content type="text"><![CDATA[Openstack WebUI页面无法打开，页面报500错误，查看httpd-&gt;error_log日志报如下错误: 1234567891011[Tue Apr 02 14:01:05.658276 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/sessions.py&quot;, line 518, in request[Tue Apr 02 14:01:05.658280 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/sessions.py&quot;, line 639, in send[Tue Apr 02 14:01:05.658284 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/adapters.py&quot;, line 438, in send[Tue Apr 02 14:01:05.658287 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py&quot;, line 588, in urlopen[Tue Apr 02 14:01:05.658291 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py&quot;, line 241, in _get_conn[Tue Apr 02 14:01:05.658296 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/connection.py&quot;, line 27, in is_connection_dropped[Tue Apr 02 14:01:05.658300 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.py&quot;, line 33, in wait_for_read[Tue Apr 02 14:01:05.658304 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.py&quot;, line 22, in _wait_for_io_events[Tue Apr 02 14:01:05.658308 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.py&quot;, line 581, in DefaultSelector[Tue Apr 02 14:01:05.658312 2019] [:error] [pid 9245] File &quot;/usr/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.py&quot;, line 394, in __init__[Tue Apr 02 14:01:05.658316 2019] [:error] [pid 9245] IOError: [Errno 24] Too many open files 解决方式：修改操作系统打开的文件数；登录到Controller节点，执行: 1234567891011121314151617[root@controller ~]# ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 60587max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 60587virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 系统默认设置为1024。 使用命令查看当前打开文件数: 12[root@controller ~]# lsof | wc -l174911 修改vim /etc/security/limits.conf，在文件最后加入如下信息： 12* soft nofile 1024000* hard nofile 1024000 *表示所有用户，修改后重启服务器，配置生效。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟化纵向安装配置说明]]></title>
    <url>%2F2019%2F06%2F20%2FOther%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E7%BA%B5%E5%90%91%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[虚拟化纵向安装配置说明创建纵向组件[电力纵向] PS。创建主机组件[win7] PC。创建UKey组件 UKey。UKey插入PS。 配置PC。 IP地址：169.254.200.201 掩码：255.255.255.0 网关：169.254.200.1 PC网卡0与PS网卡4连接网线。PC本地安装纵向管理工具。 目录地址：d:/software/PSTunnel2000加密装置千兆管理工具.exe 添加新操作员。 右键 -&gt; 以管理员身份运行 -&gt; 操作员 -&gt; 操作员管理 -&gt; 添加：+操作员： user -&gt; 确定 导出导入证书。 -&gt; 初始化 -&gt; 生成设备密钥及证书请求 -&gt; 下一步 -&gt; 填写省/市/设备名 -&gt; 下一步 -&gt; 生成.csr证书 证书转换。使用证书工具2.0将.csr证书转换为.cer证书。传入对端。 -&gt; 证书 -&gt; 证书导入 -&gt; 远程设备证书 -&gt; 选择证书 -&gt; 确定 VLAN配置。 本地ETH1：192.168.1.100 255.255.255.0 VLAN：0 远程ETH1：192.168.1.200 255.255.255.0 VLAN：0 安全隧道。 -&gt; 恢复隧道配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改隧道 -&gt; 确定 隧道名标识： 11 -&gt; 不支持修改 本地IP： 192.168.1.100 -&gt; 本地ETH1 远程IP： 192.168.1.200 -&gt; 远程ETH1 255.255.255.0 0.0.0.0 0.0.0.0 MTU： 1500 安全策略。 -&gt; 恢复策略配置 -&gt; 11.pbak -&gt; 配置写入装置 -&gt; 确定 -&gt; 修改策略 -&gt; 确定 标识id：0 本地IP： 192.168.1.100 -&gt; 本地ETH1 远程IP： 192.168.1.200 -&gt; 远程ETH1 本地起始IP：192.168.1.1 本地终止IP：192.168.1.254 远程起始IP：192.168.1.1 远程终止IP：192.168.1.254 方向：双向 重置隧道。 -&gt; 管理 -&gt; 重置隧道 -&gt; OPENED 注意： *新纵向的用户名,密码：root, Tun-2000 纵向内部查询路由命令：1$ monipead.arm -all]]></content>
      <categories>
        <category>Eletric Power</category>
      </categories>
      <tags>
        <tag>eletric power</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（七）Horizon服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens7%2F</url>
    <content type="text"><![CDATA[Controller节点：安装及配置：12345678910111213141516171819202122# yum install openstack-dashboard# vi /etc/openstack-dashboard/local_settingsOPENSTACK_HOST = "controller"ALLOWED_HOSTS = ['*']SESSION_ENGINE = 'django.contrib.sessions.backends.cache'CACHES = &#123; 'default': &#123; 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', &#125;&#125;OPENSTACK_KEYSTONE_URL = "http://%s:5000/v3" % OPENSTACK_HOSTOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = TrueOPENSTACK_API_VERSIONS = &#123; "identity": 3, "image": 2, "volume": 2,&#125;OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = "Default"OPENSTACK_KEYSTONE_DEFAULT_ROLE = "user"TIME_ZONE = "Asia/Shanghai" 123# vi /etc/httpd/conf.d/openstack-dashboard.conf 在文件开头添加WSGIApplicationGroup %&#123;GLOBAL&#125;... 完成安装：1# systemctl restart httpd.service memcached.service 使用 http://controller/dashboard 上的Web浏览器访问Dashboard。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（六）Neutron服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens6%2F</url>
    <content type="text"><![CDATA[Controller节点：Neutron服务安装网络类型：vxlanLayer2 二层插件采用：openvswitch 创建neutron数据库，授予权限：123456$ mysql -u root -pMariaDB [(none)] CREATE DATABASE neutron;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 创建neutron用户：1234567891011121314151617$ . admin-openrc$ openstack user create --domain default --password-prompt neutronUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 463fd14bf95b4cc49c0378623de56ffa || name | neutron || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user neutron admin 创建neutron服务实体：12345678910$ openstack service create --name neutron --description "OpenStack Networking" network+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Networking || enabled | True || id | e10e48790ede425ea81e1a62250f124a || name | neutron || type | network |+-------------+----------------------------------+ 创建网络服务API端点：1234567891011121314$ openstack endpoint create --region RegionOne network public http://controller:9696+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | f688ed8f1bf340d78794b600fa512145 || interface | public || region | RegionOne || region_id | RegionOne || service_id | e10e48790ede425ea81e1a62250f124a || service_name | neutron || service_type | network || url | http://controller:9696 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne network internal http://controller:9696+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 571a008230c54cf8bcb1e38a75787c3f || interface | internal || region | RegionOne || region_id | RegionOne || service_id | e10e48790ede425ea81e1a62250f124a || service_name | neutron || service_type | network || url | http://controller:9696 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne network admin http://controller:9696+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | a8d654c1c878423789aab3fa7cf634cb || interface | admin || region | RegionOne || region_id | RegionOne || service_id | e10e48790ede425ea81e1a62250f124a || service_name | neutron || service_type | network || url | http://controller:9696 |+--------------+----------------------------------+ 安装及配置：12345678910111213141516171819202122232425262728293031323334# yum install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch ebtables# vi /etc/neutron/neutron.conf[DEFAULT]auth_strategy = keystonecore_plugin = ml2service_plugins = routerallow_overlapping_ips = Truetransport_url = rabbit://openstack:123456@controllernotify_nova_on_port_status_changes = truenotify_nova_on_port_data_changes = true[database]connection = mysql+pymysql://neutron:123456@controller/neutron[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:35357memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = 123456[nova]auth_url = http://controller:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = novapassword = 123456[oslo_concurrency]lock_path = /var/lib/neutron/tmp 1234567891011121314# vi /etc/neutron/plugins/ml2/ml2_conf.ini[ml2]type_drivers = flat,vlan,vxlantenant_network_types = vxlanmechanism_drivers = openvswitch,l2populationextension_drivers = port_security[ml2_type_flat]flat_networks = provider[ml2_type_vlan]#network_vlan_ranges = provider:1:1000[ml2_type_vxlan]vni_ranges = 1:1000[securitygroup]enable_ipset = true 123# vi /etc/sysctl.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1 1234# vi /etc/neutron/l3_agent.ini[DEFAULT]interface_driver = openvswitchexternal_network_bridge = 12345# vi /etc/neutron/dhcp_agent.ini[DEFAULT]interface_driver = openvswitchdhcp_driver = neutron.agent.linux.dhcp.Dnsmasqenable_isolated_metadata = true 1234# vi /etc/neutron/metadata_agent.ini[DEFAULT]nova_metadata_host = controllermetadata_proxy_shared_secret = 123456 123456789# vi /etc/neutron/plugins/ml2/openvswitch_agent.ini[agent]tunnel_types = vxlanl2_population = True[ovs]bridge_mappings = provider:br-providerlocal_ip = 10.0.0.11[securitygroup]firewall_driver = iptables_hybrid 完成安装：123456789101112131415161718# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini# su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron# systemctl restart openstack-nova-api.service# systemctl start neutron-server.service# systemctl start neutron-openvswitch-agent.service# ovs-vsctl add-br br-provider# ifconfig eth0 0.0.0.0# ifconfig br-provider 192.100.10.160/24# route add default gw 192.100.10.1# systemctl restart neutron-server.service# systemctl restart neutron-openvswitch-agent.service# systemctl enable neutron-server.service neutron-openvswitch-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service# systemctl start neutron-dhcp-agent.service neutron-metadata-agent.service# systemctl enable neutron-l3-agent.service# systemctl start neutron-l3-agent.service Compute节点：安装及配置：123456789101112131415161718# yum install openstack-neutron-openvswitch ebtables ipset# vi /etc/neutron/neutron.conf[DEFAULT]transport_url = rabbit://openstack:123456@controllerauth_strategy = keystone[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:35357memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = 123456[oslo_concurrency]lock_path = /var/lib/neutron/tmp 12345678# vi /etc/neutron/plugins/ml2/openvswitch_agent.ini[ovs]local_ip = 10.0.0.21[agent]tunnel_types = vxlanl2_population = True# systemctl restart neutron-openvswitch-agent.service 123456789101112# vi /etc/nova/nova.conf...[neutron]url = http://controller:9696auth_url = http://controller:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = 123456 完成安装：123# systemctl restart openstack-nova-compute.service# systemctl enable neutron-openvswitch-agent.service# systemctl start neutron-openvswitch-agent.service Controller节点：验证操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ . admin-openrc$ openstack extension list --network+----------------------------------------------------------------------------------------------+---------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Name | Alias | Description |+----------------------------------------------------------------------------------------------+---------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Default Subnetpools | default-subnetpools | Provides ability to mark and use a subnetpool as the default. || Availability Zone | availability_zone | The availability zone extension. || Network Availability Zone | network_availability_zone | Availability zone support for network. || Auto Allocated Topology Services | auto-allocated-topology | Auto Allocated Topology Services. || Neutron L3 Configurable external gateway mode | ext-gw-mode | Extension of the router abstraction for specifying whether SNAT should occur on the external gateway || Port Binding | binding | Expose port bindings of a virtual port to external application || agent | agent | The agent management extension. || Subnet Allocation | subnet_allocation | Enables allocation of subnets from a subnet pool || L3 Agent Scheduler | l3_agent_scheduler | Schedule routers among l3 agents || Tag support | tag | Enables to set tag on resources. || Neutron external network | external-net | Adds external network attribute to network resource. || Tag support for resources with standard attribute: trunk, policy, security_group, floatingip | standard-attr-tag | Enables to set tag on resources with standard attribute. || Neutron Service Flavors | flavors | Flavor specification for Neutron advanced services. || Network MTU | net-mtu | Provides MTU attribute for a network resource. || Network IP Availability | network-ip-availability | Provides IP availability data for each network and subnet. || Quota management support | quotas | Expose functions for quotas management per tenant || If-Match constraints based on revision_number | revision-if-match | Extension indicating that If-Match based on revision_number is supported. || HA Router extension | l3-ha | Adds HA capability to routers. || Provider Network | provider | Expose mapping of virtual networks to physical networks || Multi Provider Network | multi-provider | Expose mapping of virtual networks to multiple physical networks || Quota details management support | quota_details | Expose functions for quotas usage statistics per project || Address scope | address-scope | Address scopes extension. || Neutron Extra Route | extraroute | Extra routes configuration for L3 router || Network MTU (writable) | net-mtu-writable | Provides a writable MTU attribute for a network resource. || Subnet service types | subnet-service-types | Provides ability to set the subnet service_types field || Resource timestamps | standard-attr-timestamp | Adds created_at and updated_at fields to all Neutron resources that have Neutron standard attributes. || Neutron 服务类型管理 | service-type | 用于为 Neutron 高级服务检索服务提供程序的 API || Router Flavor Extension | l3-flavors | Flavor support for routers. || Port Security | port-security | Provides port security || Neutron Extra DHCP options | extra_dhcp_opt | Extra options configuration for DHCP. For example PXE boot options to DHCP clients can be specified (e.g. tftp-server, server-ip-address, bootfile-name) || Resource revision numbers | standard-attr-revisions | This extension will display the revision number of neutron resources. || Pagination support | pagination | Extension that indicates that pagination is enabled. || Sorting support | sorting | Extension that indicates that sorting is enabled. || security-group | security-group | The security groups extension. || DHCP Agent Scheduler | dhcp_agent_scheduler | Schedule networks among dhcp agents || Router Availability Zone | router_availability_zone | Availability zone support for router. || RBAC Policies | rbac-policies | Allows creation and modification of policies that control tenant access to resources. || Tag support for resources: subnet, subnetpool, port, router | tag-ext | Extends tag support to more L2 and L3 resources. || standard-attr-description | standard-attr-description | Extension to add descriptions to standard attributes || IP address substring filtering | ip-substring-filtering | Provides IP address substring filtering when listing ports || Neutron L3 Router | router | Router abstraction for basic L3 forwarding between L2 Neutron networks and access to external networks via a NAT gateway. || Allowed Address Pairs | allowed-address-pairs | Provides allowed address pairs || project_id field enabled | project-id | Extension that indicates that project_id field is enabled. || Distributed Virtual Router | dvr | Enables configuration of Distributed Virtual Routers. |+----------------------------------------------------------------------------------------------+---------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ 12345678910$ openstack network agent list+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+| ID | Agent Type | Host | Availability Zone | Alive | State | Binary |+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+| 0fcf4aa9-3592-4552-9b4c-f2b55e23ef6b | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent || 1a08e5eb-d867-4697-850d-bd2400134162 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent || 9a33be1e-61bd-4d6b-9ee1-bda6dc7b44cd | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent || bfdb443d-feee-4006-8618-558b73c3c4a2 | L3 agent | controller | nova | :-) | UP | neutron-l3-agent || ce5abc8d-504a-4164-ae0f-801e56a06653 | Linux bridge agent | compute | None | :-) | UP | neutron-linuxbridge-agent |+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（五）Nova服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens5%2F</url>
    <content type="text"><![CDATA[Controller节点：创建 nova_api, nova,和 nova_cell0 的数据库，授予权限：1234567891011121314$ mysql -u root -pMariaDB [(none)]&gt;CREATE DATABASE nova_api;MariaDB [(none)]&gt; CREATE DATABASE nova;MariaDB [(none)]&gt; CREATE DATABASE nova_cell0;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 创建nova用户：1234567891011121314151617$ . admin-openrc$ openstack user create --domain default --password-prompt novaUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 81f1d5dfad5a42bb806d197ceb9881ce || name | nova || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user nova admin 创建nova服务实体：12345678910$ openstack service create --name nova --description "OpenStack Compute" compute+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Compute || enabled | True || id | 3e011d345e4442fe8a232ab5ab1f8323 || name | nova || type | compute |+-------------+----------------------------------+ 创建Compute API服务端点：1234567891011121314$ openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 343b6a8fc9564623aca0097b2383650d || interface | public || region | RegionOne || region_id | RegionOne || service_id | 3e011d345e4442fe8a232ab5ab1f8323 || service_name | nova || service_type | compute || url | http://controller:8774/v2.1 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 3458cf55ac8b44d58c949fe88bf9afe3 || interface | internal || region | RegionOne || region_id | RegionOne || service_id | 3e011d345e4442fe8a232ab5ab1f8323 || service_name | nova || service_type | compute || url | http://controller:8774/v2.1 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 9f9115389c2a49a2874761b92c849bb0 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | 3e011d345e4442fe8a232ab5ab1f8323 || service_name | nova || service_type | compute || url | http://controller:8774/v2.1 |+--------------+----------------------------------+ 创建Placement服务相关：123456789101112131415$ openstack user create --domain default --password-prompt placementUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 74870bc86a7c4108869c620099bffc30 || name | placement || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user placement admin 12345678910$ openstack service create --name placement --description "Placement API" placement+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Placement API || enabled | True || id | bbd270a97c3a499fb73765120094e9da || name | placement || type | placement |+-------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne placement public http://controller:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | d79b3b62302a4055924762ac676fc9b4 || interface | public || region | RegionOne || region_id | RegionOne || service_id | bbd270a97c3a499fb73765120094e9da || service_name | placement || service_type | placement || url | http://controller:8778 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne placement internal http://controller:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 5424919fbee34a7a92946c607706b38a || interface | internal || region | RegionOne || region_id | RegionOne || service_id | bbd270a97c3a499fb73765120094e9da || service_name | placement || service_type | placement || url | http://controller:8778 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne placement admin http://controller:8778+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | d9d5626cdb5442ac91dff8c1588f4726 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | bbd270a97c3a499fb73765120094e9da || service_name | placement || service_type | placement || url | http://controller:8778 |+--------------+----------------------------------+ 安装和配置：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# yum install openstack-nova-api openstack-nova-conductor openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler openstack-nova-placement-api# vi /etc/nova/nova.conf[DEFAULT]my_ip=192.100.10.160use_neutron=truefirewall_driver=nova.virt.firewall.NoopFirewallDriverenabled_apis=osapi_compute,metadatatransport_url=rabbit://openstack:123456@controller[api]auth_strategy=keystone[api_database]connection = mysql+pymysql://nova:123456@controller/nova_api[database]connection = mysql+pymysql://nova:123456@controller/nova[glance]api_servers = http://controller:9292[keystone_authtoken]auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = 123456[libvirt]#virt_type=kvm[neutron]url = http://controller:9696auth_url = http://controller:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = 123456service_metadata_proxy = truemetadata_proxy_shared_secret = 123456[oslo_concurrency]lock_path=/var/lib/nova/tmp[placement]os_region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://controller:5000/v3username = placementpassword = 123456[vnc]enabled=trueserver_listen=$my_ipserver_proxyclient_address=$my_ip#novncproxy_base_url=http://127.0.0.1:6080/vnc_auto.html 12345678910# vi /etc/httpd/conf.d/00-nova-placement-api.conf 在最下方加入&lt;Directory /usr/bin&gt; &lt;IfVersion &gt;= 2.4&gt; Require all granted &lt;/IfVersion&gt; &lt;IfVersion &lt; 2.4&gt; Order allow,deny Allow from all &lt;/IfVersion&gt;&lt;/Directory&gt; 完成安装：1234567891011121314# systemctl restart httpd# su -s /bin/sh -c "nova-manage api_db sync" nova# su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova# su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova# su -s /bin/sh -c "nova-manage db sync" nova# nova-manage cell_v2 list_cells+-------+--------------------------------------+------------------------------------+-------------------------------------------------+| 名称 | UUID | Transport URL | 数据库连接 |+-------+--------------------------------------+------------------------------------+-------------------------------------------------+| cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@controller/nova_cell0 || cell1 | c795b2eb-4814-4fe7-b9ff-090a1b1b2be5 | rabbit://openstack:****@controller | mysql+pymysql://nova:****@controller/nova |+-------+--------------------------------------+------------------------------------+-------------------------------------------------+ 12# systemctl enable openstack-nova-api.service openstack-nova-consoleauth.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service# systemctl start openstack-nova-api.service openstack-nova-consoleauth.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service Compute节点：安装和配置：1234567891011121314151617181920212223242526272829303132333435363738# yum install openstack-nova-compute# vi /etc/nova/nova.conf[DEFAULT]my_ip = 192.100.10.161enabled_apis = osapi_compute,metadatause_neutron = Truefirewall_driver = nova.virt.firewall.NoopFirewallDrivertransport_url = rabbit://openstack:123456@controller[api]auth_strategy = keystone[vnc]enabled = Trueserver_listen = 0.0.0.0server_proxyclient_address = $my_ipnovncproxy_base_url = http://controller:6080/vnc_auto.html[glance]api_servers = http://controller:9292[oslo_concurrency]lock_path = /var/lib/nova/tmp[placement]os_region_name = RegionOneproject_domain_name = Defaultproject_name = serviceauth_type = passworduser_domain_name = Defaultauth_url = http://controller:5000/v3username = placementpassword = 123456[keystone_authtoken]auth_url = http://controller:5000/v3memcached_servers = controller:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = 123456 完成安装12# systemctl enable libvirtd.service openstack-nova-compute.service# systemctl start libvirtd.service openstack-nova-compute.service Controller节点：将计算节点添加到cell数据库：12345678$ . admin-openrc$ openstack compute service list --service nova-compute+----+--------------+-----------------------+------+---------+-------+----------------------------+| ID | Binary | Host | Zone | Status | State | Updated At |+----+--------------+-----------------------+------+---------+-------+----------------------------+| 9 | nova-compute | localhost.localdomain | nova | enabled | up | 2018-09-13T02:59:06.000000 |+----+--------------+-----------------------+------+---------+-------+----------------------------+ 发现计算主机：123456789101112131415# su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWarning: Configuration option(s) ['use_tpool'] not supported exception.NotSupportedWarningFound 2 cell mappings.Skipping cell0 since it does not contain hosts.Getting computes from cell 'cell1': c795b2eb-4814-4fe7-b9ff-090a1b1b2be5Checking host mapping for compute host 'localhost.localdomain': 58be78ad-5220-4869-ab31-33c9674ecfd1Creating host mapping for compute host 'localhost.localdomain': 58be78ad-5220-4869-ab31-33c9674ecfd1Found 1 unmapped computes in cell: c795b2eb-4814-4fe7-b9ff-090a1b1b2be5注意：添加新计算节点时，必须在控制器节点上运行nova-manage cell_v2 discover_hosts以注册这些新计算节点。或者，您可以在 /etc/nova/nova.conf 中设置适当的间隔：[scheduler]discover_hosts_in_cells_interval = 300 验证：1234567891011$ . admin-openrc$ openstack compute service list+----+------------------+-----------------------+----------+---------+-------+----------------------------+| ID | Binary | Host | Zone | Status | State | Updated At |+----+------------------+-----------------------+----------+---------+-------+----------------------------+| 1 | nova-conductor | controller | internal | enabled | up | 2018-09-13T03:00:28.000000 || 3 | nova-consoleauth | controller | internal | enabled | up | 2018-09-13T03:00:29.000000 || 4 | nova-scheduler | controller | internal | enabled | up | 2018-09-13T03:00:29.000000 || 9 | nova-compute | localhost.localdomain | nova | enabled | up | 2018-09-13T03:00:26.000000 |+----+------------------+-----------------------+----------+---------+-------+----------------------------+ 123456789101112131415161718192021222324252627282930313233$ openstack catalog list+-----------+-----------+-----------------------------------------+| Name | Type | Endpoints |+-----------+-----------+-----------------------------------------+| keystone | identity | RegionOne || | | public: http://controller:5000/v3/ || | | RegionOne || | | internal: http://controller:5000/v3/ || | | RegionOne || | | admin: http://controller:5000/v3/ || | | || nova | compute | RegionOne || | | public: http://controller:8774/v2.1 || | | RegionOne || | | internal: http://controller:8774/v2.1 || | | RegionOne || | | admin: http://controller:8774/v2.1 || | | || glance | image | RegionOne || | | internal: http://controller:9292 || | | RegionOne || | | admin: http://controller:9292 || | | RegionOne || | | public: http://controller:9292 || | | || placement | placement | RegionOne || | | internal: http://controller:8778 || | | RegionOne || | | public: http://controller:8778 || | | RegionOne || | | admin: http://controller:8778 || | | |+-----------+-----------+-----------------------------------------+ 123456$ openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| ad7da2d4-cb83-4a41-836f-e58e47e899f5 | cirros | active |+--------------------------------------+--------+--------+ 123456789101112131415161718192021222324252627# nova-status upgrade check/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:332: NotSupportedWarning: Configuration option(s) ['use_tpool'] not supported exception.NotSupportedWarningOption "os_region_name" from group "placement" is deprecated. Use option "region-name" from group "placement".+-------------------------------+| 升级检查结果 |+-------------------------------+| 检查: Cells v2 || 结果: 成功 || 详情: None |+-------------------------------+| 检查: Placement API || 结果: 成功 || 详情: None |+-------------------------------+| 检查: Resource Providers || 结果: 成功 || 详情: None |+-------------------------------+| 检查: Ironic Flavor Migration || 结果: 成功 || 详情: None |+-------------------------------+| 检查: API Service Version || 结果: 成功 || 详情: None |+-------------------------------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（四）Glance服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens4%2F</url>
    <content type="text"><![CDATA[Controller节点：创建glance数据库，授予权限：12345$ mysql -u root -pMariaDB [(none)]&gt; CREATE DATABASE glance;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 创建glance用户：1234567891011121314151617$ . admin-openrc$ openstack user create --domain default --password-prompt glanceUser Password: 123456Repeat User Password: 123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 5b7e76213b4b4945b7c702be5b595c0e || name | glance || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+$ openstack role add --project service --user glance admin 创建glance服务实体：12345678910$ openstack service create --name glance --description "OpenStack Image" image+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | OpenStack Image || enabled | True || id | b9cfd97d134e4ec2bf19d78306e85a5a || name | glance || type | image |+-------------+----------------------------------+ 创建API端点：1234567891011121314$ openstack endpoint create --region RegionOne image public http://controller:9292+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | b9c90172de704ea4a867190ba44fc931 || interface | public || region | RegionOne || region_id | RegionOne || service_id | b9cfd97d134e4ec2bf19d78306e85a5a || service_name | glance || service_type | image || url | http://controller:9292 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne image internal http://controller:9292+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 074bde7662044e93830f4eca15d9c887 || interface | internal || region | RegionOne || region_id | RegionOne || service_id | b9cfd97d134e4ec2bf19d78306e85a5a || service_name | glance || service_type | image || url | http://controller:9292 |+--------------+----------------------------------+ 1234567891011121314$ openstack endpoint create --region RegionOne image admin http://controller:9292+--------------+----------------------------------+| Field | Value |+--------------+----------------------------------+| enabled | True || id | 17030061f9b84301ac515765706933b2 || interface | admin || region | RegionOne || region_id | RegionOne || service_id | b9cfd97d134e4ec2bf19d78306e85a5a || service_name | glance || service_type | image || url | http://controller:9292 |+--------------+----------------------------------+ 安装和配置：12345678910111213141516171819202122232425262728293031323334353637383940# yum install openstack-glance# vi /etc/glance/glance-api.conf[database]connection = mysql+pymysql://glance:123456@controller/glance[glance_store]stores = file,httpdefault_store = filefilesystem_store_datadir = /var/lib/glance/images/[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = glancepassword = 123456[paste_deploy]flavor = keystone# vi /etc/glance/glance-registry.conf[database]connection = mysql+pymysql://glance:123456@controller/glance[keystone_authtoken]auth_uri = http://controller:5000auth_url = http://controller:5000memcached_servers = controller:11211auth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultproject_name = serviceusername = glancepassword = 123456[paste_deploy]flavor = keystone# su -s /bin/sh -c "glance-manage db_sync" glance 完成安装12# systemctl enable openstack-glance-api.service openstack-glance-registry.service# systemctl start openstack-glance-api.service openstack-glance-registry.service 验证操作123456789101112131415161718192021222324252627282930$ . admin-openrc$ wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img$ openstack image create "cirros" \ --file cirros-0.3.5-x86_64-disk.img \ --disk-format qcow2 --container-format bare \ --public+------------------+------------------------------------------------------+| Field | Value |+------------------+------------------------------------------------------+| checksum | f8ab98ff5e73ebab884d80c9dc9c7290 || container_format | bare || created_at | 2018-09-13T00:55:04Z || disk_format | qcow2 || file | /v2/images/ad7da2d4-cb83-4a41-836f-e58e47e899f5/file || id | ad7da2d4-cb83-4a41-836f-e58e47e899f5 || min_disk | 0 || min_ram | 0 || name | cirros || owner | 4a5e42dd8cbf410f85a5f145039d69a6 || protected | False || schema | /v2/schemas/image || size | 13267968 || status | active || tags | || updated_at | 2018-09-13T00:55:04Z || virtual_size | None || visibility | public |+------------------+------------------------------------------------------+ 123456$ openstack image list+--------------------------------------+--------+--------+| ID | Name | Status |+--------------------------------------+--------+--------+| ad7da2d4-cb83-4a41-836f-e58e47e899f5 | cirros | active |+--------------------------------------+--------+--------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（三）Keystone服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens3%2F</url>
    <content type="text"><![CDATA[Controller节点：创建keystone数据库，授予权限：12345678$ mysql -u root -p密码：123456MariaDB [(none)]&gt; CREATE DATABASE keystone;MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \IDENTIFIED BY '123456';MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \IDENTIFIED BY '123456';MariaDB [(none)]&gt; exit; 安装及配置组件12345678910111213141516# yum install openstack-keystone httpd mod_wsgi# vi /etc/keystone/keystone.conf[database]connection = mysql+pymysql://keystone:123456@controller/keystone[token]provider = fernet# su -s /bin/sh -c "keystone-manage db_sync" keystone# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone# keystone-manage bootstrap --bootstrap-password 123456 \ --bootstrap-admin-url http://controller:5000/v3/ \ --bootstrap-internal-url http://controller:5000/v3/ \ --bootstrap-public-url http://controller:5000/v3/ \ --bootstrap-region-id RegionOne 配置Apache HTTP Server1234# vi /etc/httpd/conf/httpd.confServerName controller# ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ 完成安装：12# systemctl enable httpd.service# systemctl start httpd.service 配置管理帐户1234567$ export OS_USERNAME=admin$ export OS_PASSWORD=123456$ export OS_PROJECT_NAME=admin$ export OS_USER_DOMAIN_NAME=Default$ export OS_PROJECT_DOMAIN_NAME=Default$ export OS_AUTH_URL=http://controller:35357/v3$ export OS_IDENTITY_API_VERSION=3 创建域、项目、用户和角色：12345678910$ openstack domain create --description "An Example Domain" example+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | An Example Domain || enabled | True || id | 2f338489f6c64472a0b2b6db54ecc2df || name | example || tags | [] |+-------------+----------------------------------+ 12345678910111213$ openstack project create --domain default --description "Service Project" service+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Service Project || domain_id | default || enabled | True || id | 84218999229845e2ad7f4e88208b3bee || is_domain | False || name | service || parent_id | default || tags | [] |+-------------+----------------------------------+ 12345678910111213$ openstack project create --domain default --description "Demo Project" demo+-------------+----------------------------------+| Field | Value |+-------------+----------------------------------+| description | Demo Project || domain_id | default || enabled | True || id | 5c4692ce6659454eb830e7e9633a09f1 || is_domain | False || name | demo || parent_id | default || tags | [] |+-------------+----------------------------------+ 12345678910111213$ openstack user create --domain default --password-prompt demoUser Password:123456Repeat User Password:123456+---------------------+----------------------------------+| Field | Value |+---------------------+----------------------------------+| domain_id | default || enabled | True || id | 803e7ad2e94b4af39f9be9e0742b45fd || name | demo || options | &#123;&#125; || password_expires_at | None |+---------------------+----------------------------------+ 12345678910$ openstack role create user+-----------+----------------------------------+| Field | Value |+-----------+----------------------------------+| domain_id | None || id | cbe4799bac204eacbf0012a77dc349c4 || name | user |+-----------+----------------------------------+$ openstack role add --project demo --user demo user 验证操作：123456789101112131415161718192021222324252627$ unset OS_AUTH_URL OS_PASSWORD$ openstack --os-auth-url http://controller:35357/v3 \ --os-project-domain-name Default --os-user-domain-name Default \ --os-project-name admin --os-username admin token issuePassword: 123456+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| expires | 2018-09-12T09:43:34+0000 || id | gAAAAABbmNG25wIya-0xFYb3zCW3ljtDTWnr8ZCpB4iAZPMfQnP-62EGiIr6aKEjO847h6jH5nNONRqeLXO2BC_bJ0O-b5Fwj2GZpYGWRSSucAU4Mh6MqLQzetbOsRCv9-ZGO6VQYkmr0cPTEm7kzuzUL2bwTcUCbAVCpuFvCnRUZ7Hu4FE5bAI || project_id | 4a5e42dd8cbf410f85a5f145039d69a6 || user_id | 2ffffa1e6cbe4d239bdacc9760a54dd5 |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+$ openstack --os-auth-url http://controller:5000/v3 \ --os-project-domain-name Default --os-user-domain-name Default \ --os-project-name demo --os-username demo token issuePassword: 123456+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| expires | 2018-09-12T09:45:20+0000 || id | gAAAAABbmNIgtMBObdQXwOlGu-HMLvKNTBZuYvVizTCn3aDJLMvqzQRTyjhfm5RjEkAgIWcYfal9TrjZan2VWL_AZ8cASpkBwoa0TQn_rWlZw1wh8xcDeb5XNES3jMNxhtZA87peDCnMkGJoMaJVhvkR4gsDQiIUmCImzjYv6ZvJjLgGEotBszY || project_id | 5c4692ce6659454eb830e7e9633a09f1 || user_id | 803e7ad2e94b4af39f9be9e0742b45fd |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 创建OpenStack客户端环境脚本：12345678910111213141516171819# vi /root/admin-openrcexport OS_PROJECT_DOMAIN_NAME=Defaultexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=123456export OS_AUTH_URL=http://controller:5000/v3export OS_IDENTITY_API_VERSION=3export OS_IMAGE_API_VERSION=2# vi /root/demo-openrcexport OS_PROJECT_DOMAIN_NAME=Defaultexport OS_USER_DOMAIN_NAME=Defaultexport OS_PROJECT_NAME=demoexport OS_USERNAME=demoexport OS_PASSWORD=123456export OS_AUTH_URL=http://controller:5000/v3export OS_IDENTITY_API_VERSION=3export OS_IMAGE_API_VERSION=2 使用脚本验证：1234567891011$ . admin-openrc$ openstack token issue+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Field | Value |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| expires | 2018-09-12T09:55:59+0000 || id | gAAAAABbmNSfM00gw3qvJi-U8ytTcBxfuVhgNkETRa-gh3PqLp6Md9cW_5FfbkUL1nyQGW4Bg_XvvdIhSBv7fXRnbfyqGxTxOUloe7BmnWgM9LqLn8Fm2FLQp8qcuFamyW-9_FZA5SPqxbYS1Ozk6fO7TRDWAIWdzy5i0-qqB4Ypt6vQOyW-pqk || project_id | 4a5e42dd8cbf410f85a5f145039d69a6 || user_id | 2ffffa1e6cbe4d239bdacc9760a54dd5 |+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（二）环境相关服务]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens2%2F</url>
    <content type="text"><![CDATA[Controller节点：安装NTP服务1234567891011121314# yum install chrony# vi /etc/chrony.confserver 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst...allow 192.100.10.0/24...# systemctl enable chronyd.service 开机启用NTP# systemctl start chronyd.service 开启NTP服务 验证NTP服务： 1234567# chronyc sources 210 Number of sources = 2 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^- 192.0.2.11 2 7 12 137 -2814us[-3000us] +/- 43ms ^* 192.0.2.12 2 6 177 46 +17us[ -23us] +/- 68ms 安装Openstack相关库1234# yum install centos-release-openstack-queens 安装Openstack库# yum upgrade 更新包# yum install python-openstackclient 安装Openstack客户端# yum install openstack-selinux 安装openstack-selinux用来管理Openstack服务的安全策略 关闭防火墙12# systemctl stop firewalld 关闭防火墙服务# systemctl disable firewalld 永久防火墙开机自启动 关闭SELINUX服务123# setenforce 0 关闭selinux服务# vi /etc/selinux/config 永久关闭selinux服务 SELINUX=disabled 安装数据库服务12345678910111213141516# yum install mariadb mariadb-server python2-PyMySQL# vi /etc/my.cnf.d/openstack.cnf[mysqld]bind-address = 192.100.10.160default-storage-engine = innodbinnodb_file_per_table = onmax_connections = 4096collation-server = utf8_general_cicharacter-set-server = utf8# systemctl enable mariadb.service 开机启用Mysql服务# systemctl start mariadb.service 开启Mysql服务# mysql_secure_installation 设置Mysql密码-&gt;123456 安装消息队列1234567# yum install rabbitmq-server# systemctl enable rabbitmq-server.service# systemctl start rabbitmq-server.service# rabbitmqctl add_user openstack 123456# rabbitmqctl set_permissions openstack ".*" ".*" ".*" 安装Memcached缓存1234567# yum install memcached python-memcached# vi /etc/sysconfig/memcachedOPTIONS="-l 127.0.0.1,::1,controller"# systemctl enable memcached.service# systemctl start memcached.service 安装Etcd1234567891011121314151617# yum install etcd# vi /etc/etcd/etcd.conf#[Member]ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="http://192.100.10.160:2380"ETCD_LISTEN_CLIENT_URLS="http://192.100.10.160:2379"ETCD_NAME="controller"#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS="http://192.100.10.160:2380"ETCD_ADVERTISE_CLIENT_URLS="http://192.100.10.160:2379"ETCD_INITIAL_CLUSTER="controller=http://192.100.10.160:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster-01"ETCD_INITIAL_CLUSTER_STATE="new"# systemctl enable etcd# systemctl start etcd Compute节点：安装NTP服务1234567891011# yum install chrony# vi /etc/chrony.confserver controller iburst...allow 192.100.10.0/24...# systemctl enable chronyd.service 开机启用NTP# systemctl start chronyd.service 开启NTP服务 安装Openstack相关库1234# yum install centos-release-openstack-queens 安装Openstack库# yum upgrade 更新包# yum install python-openstackclient 安装Openstack客户端# yum install openstack-selinux 安装openstack-selinux用来管理Openstack服务的安全策略 关闭防火墙12# systemctl stop firewalld 关闭防火墙服务# systemctl disable firewalld 永久防火墙开机自启动 关闭SELINUX服务123# setenforce 0 关闭selinux服务# vi /etc/selinux/config 永久关闭selinux服务 SELINUX=disabled]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack Queens 环境搭建（一）环境准备]]></title>
    <url>%2F2019%2F03%2F19%2FOpenstack%2FOpenstackQueens1%2F</url>
    <content type="text"><![CDATA[环境准备：基于CentOS Linux release 7.6.1810 (Core) 控制节点（Controller）：eth0：192.100.10.160/24eth1：10.0.0.11/24eth2：预留 计算节点（Compute):eth0：192.100.10.161/24eth1：10.0.0.12/24eth2：预留 网卡0接口为管理网络 -&gt; 交换机 + 路由器网卡1接口为Overlay网络 -&gt; 目前直连 / 交换机连接网卡2接口为外部网络 -&gt; 路由器 -（可以先使用eth1作为外部网络下载Openstack安装所需资源，后修改） 通用密码： 123456 Controller节点：配置网卡信息： 12345# vi /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=staticIPADDR=192.100.10.160NETMASK=255.255.255.0GATEWAY=192.100.10.1 1234# vi /etc/sysconfig/network-scripts/ifcfg-eth1BOOTPROTO=staticIPADDR=10.0.0.11NETMASK=255.255.255.0 配置主机信息： 12345# vi /etc/hosts# controller192.100.10.160 controller# compute192.100.10.161 compute 配置主机名：控制节点的主机名为controller，设置如下： 1~# hostnamectl set-hostname controller 对主机名进行验证： 1~# hostname 看到输出为controller即可 配置DNS： 12# vi /etc/resolv.confnameserver 114.114.114.114 Compute节点：配置管理网络： 12345# vi /etc/sysconfig/network-scripts/ifcfg-eth0BOOTPROTO=staticIPADDR=192.100.10.161NETMASK=255.255.255.0GATEWAY=192.100.10.1 1234# vi /etc/sysconfig/network-scripts/ifcfg-eth1BOOTPROTO=staticIPADDR=10.0.0.21NETMASK=255.255.255.0 配置主机信息： 12345# vi /etc/hosts# controller192.100.10.160 controller# compute192.100.10.161 compute 配置主机名：计算节点的主机名为compute，设置如下： 1~# hostnamectl set-hostname compute 对主机名进行验证： 1~# hostname 看到输出为compute即可 配置DNS： 12# vi /etc/resolv.confnameserver 114.114.114.114]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KDPA RestAPI]]></title>
    <url>%2F2019%2F03%2F10%2FOther%2FKDPA%20RestAPI%2F</url>
    <content type="text"><![CDATA[KDPA RestAPI定义及说明 1 主机实例 1-1 创建主机实例 1-2 删除主机实例 1-3 配置主机实例 1-4 启动主机实例 1-5 关闭主机实例 1-6 挂起主机实例 1-7 恢复主机实例 1-8 获取主机实例基本信息 1-9 主机实例控制台 1-10 重命名主机实例 1-11 创建浮动IP 1-12 删除浮动IP 1-13 获取浮动IP信息 1-14 批量关闭实例组件 1-15 获取所有组件的状态 2 网线 2-1 创建网线 2-2 删除网线 3 通用 3-1 清除当前用户的实验室环境 3-2 设置实训平台系统配置 3-3 获取系统网卡信息及预留网段信息 3-4 用户实验室环境未保存退出 3-5 获取系统资源 3-6 获取系统资源使用率 3-7 按日期获取系统资源使用率 4 系统 4-1 创建镜像 4-2 删除镜像 5 纵向 5-1 创建纵向 5-2 删除纵向 6 串口线 6-1 创建串口线连接 6-2 删除串口线连接 7 UKEY 7-1 创建UKEY 7-2 删除UKEY 7-3 创建UKEY与纵向实例的连接 7-4 删除UKEY与纵向实例的连接 8 隔离 8-1 创建隔离 8-2 删除隔离 8-3 启动隔离 8-4 关闭隔离 8-5 挂起隔离 8-6 恢复隔离 8-7 隔离控制台 8-8 隔离创建浮动IP 8-9 隔离删除浮动IP 8-10 创建隔离镜像 8-11 删除隔离镜像 6-2 删除串口线连接 9 虚拟交换机 9-1 创建Untag虚拟交换机 9-2 删除Untag虚拟交换机 9-3 创建虚拟交换机 9-4 删除虚拟交换机 9-5 启动虚拟交换机 9-6 关闭虚拟交换机 9-7 设置虚拟交换机端口 9-8 获取被占用vlan 10 虚拟路由器 10-1 创建虚拟路由器 10-2 删除虚拟路由器 10-3 查看虚拟路由器配置 10-4 虚拟路由器上传镜像 10-5 虚拟路由器删除镜像 Notice: 1.以下所有API的方法都为POST 2.传参及返回值都为json格式，通用返回值格式为: {“code”: 状态码, “data”: 数据 }。 状态码为 0 代表操作成功，其他代表操作失败 3.api地址中，controller为计算节点的IP地址（已配置在主机配置文件中。8000为系统默认提供服务的端口号。 4.*参数为必填参数，其余为非必填，非必填参数系统传参默认值。 限制: 1.所有组件: 所有组件在关机状态下不能连接网线，不能删除网线。 实验室环境在未点击保存时会被清理，如有需要，手动点击保存按钮。 2.主机: 处于有网线连接或者关机状态下的主机不能修改配置。 处于挂起状态下的主机只能执行恢复操作，不能执行其他操作。 3.纵向: UKEY与纵向连接后，不能直接删除纵向，必须先拔出UKEY。 纵向与纵向之间通过网卡1连接，处理业务，如果纵向与纵向之间通过其他网卡连接，不予处理。 4.串口线: 串口线目前仅支持主机、隔离。 5.虚拟路由器: 虚拟路由器定义的配置在初始化后不能修改。 虚拟路由器与主机通过网线连接两端的网段必须相同。 6.虚拟交换机: 虚拟交换机与虚拟交换机不能通过网线连接。 虚拟交换机VLAN接口只能连接虚拟组件，虚实接口只能连接实体组件。 不同虚拟交换机中的VLAN ID不能重复。 在接口有连接的情况下，不能修改虚拟交换机端口的类型（VLAN接口/虚实接口）。 7.其他问题: 虚拟路由器与虚拟交换机网线连接后，目前虚拟路由器重启DHCP获取不到IP，导致虚拟路由器不可用。 虚拟路由器与主机组件之间有其他组件的情况下，需要手动为主机配置远端静态路由。 1主机实例1-1创建主机实例Request Method: POST API: 123456789101112- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63 - **name**(str.)*: 主机名称，必填，长度1~63 - **imageName**(str.)*: 镜像名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - template(int.): 模板类型，非必填， - 1代表 1 vcpu, 1G ram, 10G disk - 2代表 2 vcpu, 2G ram, 20G disk### 1-2删除主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/delete Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-3配置主机实例Request Method: POST API: 1234567891011- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63 - **ipAddr**(str.)*: IPv4地址，必填，例如:192.168.1.100 - netmask(str.): 掩码地址，非必填，默认值为”255.255.255.0” - gateway(str.): 网关地址，非必填 - number(int.): 网卡编号，非必填，默认值为1，表示主机目前都为1块网卡### 1-4启动主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/start Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-5关闭主机实例Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63### 1-6挂起主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/suspend Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-7恢复主机实例Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63### 1-8获取主机实例基本信息#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/show Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 Response Body123456789101112131415&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;name&quot;: &quot;HOST_1&quot;, &quot;state&quot;: &quot;Up&quot;, &quot;interface&quot;: [&#123; &quot;macAddr&quot;: &quot;fa:16:3e:62:7b:cb&quot;, // MAC地址 &quot;ipAddr&quot;: &quot;192.168.1.5&quot;, // IP地址 &quot;number&quot;: 0, // 网卡编号 &quot;netmask&quot;: &quot;255.255.255.0&quot;, // 掩码地址 &quot;cidr&quot;: &quot;192.168.1.0/24&quot;, // 网段地址 &quot;gateway&quot;: &quot;192.168.1.1&quot; // 网关地址 &#125;] &#125;&#125; 1-9主机实例控制台Request Method: POST API: 12345- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63#### Response- Body { “code”: 0, “data”: { “console”: { “url”: “http://controller:6080/vnc_auto.html?token=aca31aec-fd05-46e4-9618-0e409c1e8b1e&quot;, “type”: “novnc” } }} 12345### 1-10重命名主机实例#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/rename Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 currentName(str.)*: 修改后主机名称，必填，长度1~63 1-11创建浮动IPRequest Method: POST API: 1234567- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63 ### 1-12删除主机浮动IP#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/deleteFIP Params: uuid(str.)*: 主机UUID，唯一标识，必填，长度1~63 1-13获取浮动IP信息Request Method: POST API: 12345- Params: - **uuid**(str.)*: 主机UUID，唯一标识，必填，长度1~63#### Response- Body { “code”: 0, “data”: { “ftpHost”: “192.100.10.146”, “ftpPath”: ftp://192.100.10.146/ “username”: “ftpuser”, “passwd”: “ftpuser123”, “windowsPath”: “c:\ftpuser\“, “linuxPath”: “/home/ftpuser/“, }} 12345### 1-14批量关闭实例组件#### Request- Method: **POST**- API: ```http://controller:8000/api/instance/batchStop Params: userId(int.)*: 用户ID，必填 1-15获取所有组件的状态Request Method: POST API: 12345- Params: - **userId**(int.)*: 用户ID，必填#### Response- Body { “code”: 0, “data”: { “lineList”: [], “instanceList”: [{ “state”: “Up”, “uuid”: “n-djsgs10124o”, “ukeyid”: “n-fds52326574vf” }] }} 12345678state: 包括 ”UP”: 开机，”Down”：关机，“Suspend”：挂起。## 2网线### 2-1创建网线#### Request- Method: **POST**- API: ```http://controller:8000/api/netline/create Params: uuid(str.)*: 源组件UUID，唯一标识，必填，长度1~63 dstUuid(str.)*: 网线对端组件UUID，必填，长度1~63 netlineUuid(int.)*: 网线UUID，必填，网线的唯一标识 userId(int.)*: 用户ID，必填 number(int.): 网卡编号，非必填，默认值为1，表示主机的第1块网卡 dstNumber(int.): 网线对端网设备卡编号，非必填，默认值为1 vlan(int.): 连接网线时所占用的vlan标签，非必填，默认值为0 0: 默认值，表示当前连接的网线为常规网线，即虚拟组件与虚拟组件连接 14094: 当vlan为14094之前的正整数时，表示此网线为虚实连线，vlan标签表示外部实体设备实际的vlan标签，此标签每个实体设备间不能相同。 2-2删除网线Request Method: POST API: 12345678910- Params: - **uuid**(str.)*: 网线UUID，唯一标识，必填，长度1~63 - **userId**(int.)*: 用户ID，必填## 3通用### 3-1清除当前用户的实验室环境#### Request- Method: **POST**- API: ```http://controller:8000/api/env/clear Params: userId(int.)*: 用户ID，必填 3-2设置实训平台系统配置Request Method: POST API: 1234567- Params: - **maxVmNumber**(str.)*: 用户最大创建虚拟机数量，默认值为10### 3-3获取系统网卡信息及预留网段信息#### Request- Method: **POST**- API: ```http://controller:8000/api/system/info Params: 无 Response Body12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;networkParameters&quot;: [&#123; &quot;nodeType&quot;: &quot;控制节点&quot;, &quot;nodeName&quot;: &quot;controller&quot;, &quot;interfaceInfo&quot;: [&#123; &quot;ethName&quot;: &quot;enp2s0&quot;, &quot;ipAddr&quot;: &quot;192.100.10.58&quot; &#125;, &#123; &quot;ethName&quot;: &quot;enp3s0&quot;, &quot;ipAddr&quot;: &quot;10.0.0.11&quot; &#125;] &#125;,&#123; &quot;nodeType&quot;: &quot;计算节点&quot;, &quot;nodeName&quot;: &quot;compute1&quot;, &quot;interfaceInfo&quot;: [&#123; &quot;ethName&quot;: &quot;enp0s31f6&quot;, &quot;ipAddr&quot;: &quot;192.100.10.160&quot; &#125;, &#123; &quot;ethName&quot;: &quot;enp0s20f0u8&quot;, &quot;ipAddr&quot;: &quot;10.0.0.31&quot; &#125;] &#125;] , &quot;reserveCidr&quot;: [ &#123; &quot;name&quot;: &quot;浮动IP网段&quot;, &quot;cidr&quot;: [&#123; &quot;start&quot;: &quot;192.100.10.140&quot;, &quot;end&quot;: &quot;192.100.10.141&quot; &#125;, &#123; &quot;start&quot;: &quot;192.100.10.161&quot;, &quot;end&quot;: &quot;192.100.10.169&quot; &#125;, &#123; &quot;start&quot;: &quot;192.100.10.144&quot;, &quot;end&quot;: &quot;192.100.10.149&quot; &#125;] &#125;,&#123; &quot;name&quot;: &quot;Overlay网段&quot;, &quot;cidr&quot;: [&#123; &quot;start&quot;: &quot;10.0.0.11&quot;, &quot;end&quot;: &quot;10.0.0.30&quot; &#125; ] &#125;,&#123; &quot;name&quot;: &quot;内部网段&quot;, &quot;cidr&quot;: [&#123; &quot;start&quot;: &quot;20.0.0.2&quot;, &quot;end&quot;: &quot;20.0.0.254&quot; &#125; ] &#125; ] &#125;&#125; 3-4用户实验室环境未保存退出Request Method: POST API: 12345678910- Params: - **instanceList**(list.)*: 实例组件uuid列表，必填 - **netlineList**(list.)*: 网线组件uuid列表，必填 - **userId**(int.)*: 用户ID，必填 - **clickF5**(str)*: 是否点击F5进行刷新，默认为&quot;False&quot;,非必填 ### 3-5获取系统资源#### Request- Method: **POST**- API: ```http://controller:8000/api/system/resource Params: 无 Response Body1234567891011121314151617&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;nodeNumber&quot;: 2, # 节点数量 &quot;runningNodeNumber&quot;: 2, # 正在运行的节点数量 &quot;instanceNumber&quot;: 2, # 实例数量 &quot;vcpuUsed&quot;: 3, # VCPU使用量 个数 &quot;vcpuTotal&quot;: 24, # VCPU总量 个数 &quot;vcpu&quot;: &quot;3/24&quot;, # VCPU使用情况 个数 &quot;memoryUsed&quot;: 4.0, # 内存使用量 GB &quot;memoryTotal&quot;: 23.8, # 内存总量 GB &quot;memory&quot;: &quot;4.0/23.8&quot;, # 内存使用情况 GB &quot;diskUsed&quot;: 30, # 磁盘使用量 GB &quot;diskTotal&quot;: 2198, # 磁盘总量 GB &quot;disk&quot;: &quot;30/2198&quot; # 磁盘使用情况 GB &#125;&#125; 3-6获取系统资源使用率Request Method: POST API: 12345- Params: - 无 #### Response- Body { “code”: 0, “data”: { “cpu”: [“4.1”, “4.1”, “3.9”, “4.6”], “memory”: [“67.6”, “67.8”, “67.8”, “67.9”], “disk”: [“5.7”, “5.7”, “5.7”, “5.7”], “net_out”: [“0”, “653”, “17702”, “0”], “net_in”: [“0”, “2203”, “18517”, “0”], “time”: [ “2019-06-14 07:38:01”, “2019-06-14 07:38:10”, “2019-06-14 07:38:20”, “2019-06-14 07:38:30”] }} 12345### 3-7按日期获取系统资源使用率#### Request- Method: **POST**- API: ```http://controller:8000/api/system/dateUsage Params: date(str.)*: 日期，例：”2019-06-17” Response Body1234567891011121314151617&#123; &quot;code&quot;: 0, &quot;data&quot;: &#123; &quot;memory&quot;: [&quot;71.8&quot;, &quot;74.5&quot;, &quot;74.5&quot;, &quot;74.5&quot;, &quot;74.1&quot;], &quot;net_out&quot;: [&quot;0&quot;, &quot;772940&quot;, &quot;130350&quot;, &quot;167966&quot;, &quot;172898&quot;], &quot;net_in&quot;: [&quot;0&quot;, &quot;14704&quot;, &quot;3530&quot;, &quot;4194&quot;, &quot;4442&quot;], &quot;time&quot;: [ &quot;2019-06-17 02:00:02&quot;, &quot;2019-06-17 03:00:02&quot;, &quot;2019-06-17 04:00:02&quot;, &quot;2019-06-17 05:00:02&quot;, &quot;2019-06-17 06:00:02&quot; ], &quot;disk&quot;: [&quot;5.7&quot;, &quot;5.7&quot;, &quot;5.7&quot;, &quot;5.7&quot;, &quot;5.7&quot;], &quot;cpu&quot;: [&quot;4.6&quot;, &quot;13.2&quot;, &quot;13.8&quot;, &quot;13.6&quot;, &quot;13.5&quot;] &#125;&#125; 4系统4-1创建镜像Request Method: POST API: 1234567891011121314- Params: - **name**(str.)*: 镜像名称，必填 - **url**(str.)*: 镜像路径，必填 - defaultVCPU(int.): 默认虚拟CPU个数，非必填，默认值1 - defaultRAM(int.): 默认内存大小，非必填，单位MB，默认值1024 - defaultDISK (int.): 默认磁盘大小，非必填，单位GB，默认值10 - advancedVCPU(int.): 高级虚拟CPU个数，非必填，默认值2 - advancedRAM (int.): 高级内存大小，非必填，默认值2048 - advancedDISK (int.): 高级磁盘大小，非必填，单位GB，默认值20 ### 4-2删除镜像#### Request- Method: **POST**- API: ```http://controller:8000/api/image/delete Params: name(str.)*: 镜像名称，必填 5纵向5-1创建纵向Request Method: POST API: 123456789101112- Params: - **uuid**(str.)*: 纵向UUID，唯一标识，必填，长度1~63 - **name**(str.)*: 纵向名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - template(int.): 模板类型，非必填， - 1代表 1 vcpu, 1G ram, 10G disk - 2代表 2 vcpu, 2G ram, 20G disk### 5-2删除纵向#### Request- Method: **POST**- API: ```http://controller:8000/api/pstunnel/delete Params: uuid(str.)*: 纵向UUID，唯一标识，必填，长度1~63 6串口线6-1创建串口线连接Request Method: POST API: 123456789101112- Params: - **uuid**(str.)*: 实例组件UUID，唯一标识，必填，长度1~63 - **dstUuid**(str.)*: 目的实例组件UUID，唯一标识，必填，长度1~63 - **seriallineUuid**(str.)*: 串口线UUID，唯一标识，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - number(int.): 默认值为0。对于主机，数值无意义。对于隔离，0==内隔离串口，1==外隔离串口 - dstNumber(int.): 默认值为0。对于主机，数值无意义。对于隔离，0==内隔离串口，1==外隔离串口### 6-2删除串口线连接#### Request- Method: **POST**- API: ```http://controller:8000/api/serline/delete Params: uuid(str.)*: 串口线UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 7UKEY7-1创建UKEYRequest Method: POST API: 123456789- Params: - **uuid**(str.)*: UKEY UUID，唯一标识，必填，长度1~63 - **name**(str.)*: UKEY 名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填### 7-2删除UKEY#### Request- Method: **POST**- API: ```http://controller:8000/api/ukey/delete Params: uuid(str.)*: UKEY UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 7-3创建UKEY与纵向实例的连接Request Method: POST API: 123456789- Params: - **uuid**(str.)*: UKEY UUID，唯一标识，必填，长度1~63 - **psUuid**(str.)*: 纵向UUID，唯一标识，必填，长度1~63 - **userId**(int.)*: 用户ID，必填### 7-4删除UKEY与纵向实例的连接#### Request- Method: **POST**- API: ```http://controller:8000/api/ukey/disconnect Params: uuid(str.)*: UKEY UUID，唯一标识，必填，长度1~63 psUuid(str.)*: 纵向UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 8隔离8-1创建隔离Request Method: POST API: 12345678910111213- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63 - **name**(str.)*: 隔离名称，必填，长度1~63 - **imageName**(str.)*: 隔离镜像名称，必填，长度1~63 - **userId**(int.)*: 用户ID，必填 - template(int.): 模板类型，非必填， - 1代表 1 vcpu, 1G ram, 10G disk - 2代表 2 vcpu, 2G ram, 20G disk### 8-2删除隔离#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/delete Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 userId(int.)*: 用户ID，必填 8-3启动隔离Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63### 8-4关闭隔离#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/stop Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 8-5挂起隔离Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63### 8-6恢复隔离#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/resume Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 8-7隔离控制台Request Method: POST API: 123456- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63 - number(int.): 标识内网/外网隔离，值范围：0/1，0代表内，1代表外，默认值为0#### Response- Body { “code”: 0, “data”: { “console”: { “url”: “http://controller:6080/vnc_auto.html?token=aca31aec-fd05-46e4-9618-0e409c1e8b1e&quot;, “type”: “novnc” } }} 12345### 8-8隔离创建浮动IP#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/createFIP Params: uuid(str.)*: 隔离UUID，唯一标识，必填，长度1~63 number(int.): 标识内网/外网隔离，值范围：0/1，0代表内，1代表外，默认值为0 8-9隔离删除浮动IPRequest Method: POST API: 12345678- Params: - **uuid**(str.)*: 隔离UUID，唯一标识，必填，长度1~63 - number(int.): 标识内网/外网隔离，值范围：0/1，0代表内，1代表外，默认值为0### 8-10创建隔离镜像#### Request- Method: **POST**- API: ```http://controller:8000/api/stonewall/createImg Params: name(str.)*: 镜像名称，必填 urlInt(str.)*: 内镜像路径，必填 urlExt(str.)*: 外镜像路径，必填 defaultVCPU(int.): 默认虚拟CPU个数，非必填，默认值1 defaultRAM(int.): 默认内存大小，非必填，单位MB，默认值1024 defaultDISK (int.): 默认磁盘大小，非必填，单位GB，默认值10 advancedVCPU(int.): 高级虚拟CPU个数，非必填，默认值2 advancedRAM (int.): 高级内存大小，非必填，默认值2048 advancedDISK (int.): 高级磁盘大小，非必填，单位GB，默认值20 8-11删除隔离镜像Request Method: POST API: 123456789101112131415- Params: - **name**(str.)*: 镜像名称，必填## 9虚拟交换机### 9-1创建Untag虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/createUntagSwitch`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗 - **name&lt;str, 必填&gt;**: 虚拟交换机名称 - **userId&lt;str, 必填&gt;**: 用户ID - *number&lt;str, 非必填&gt;*: 虚拟交换机网口数量，默认值8#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-2删除Untag虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/deleteUntagSwitch`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 12345678910### 9-3创建虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/create`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗 - **name&lt;str, 必填&gt;**: 虚拟交换机名称 - **userId&lt;str, 必填&gt;**: 用户ID - *number&lt;str, 非必填&gt;*: 虚拟交换机网口数量，默认值8#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-4删除虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/delete`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-5启动虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/start`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-6关闭虚拟交换机#### Request- Method: **POST**- API: `http://controller:8000/api/switch/stop`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 123456789101112### 9-7设置虚拟交换机端口#### Request- Method: **POST**- API: `http://controller:8000/api/switch/configSwitchPort`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗 - **number&lt;str, 必填&gt;**: 虚拟交换机端口序号，从0开始，最大值由交换机端口数量决定，必填 - **vlan&lt;str, 必填&gt;**: 端口将要设置的具体vlan标签 - *-1*：表示端口要设置成为【虚实口】 - *0*： 表示端口默认状态，此状态下端口不可用，即不能连接网线 - *1~4094*：表示端口设置为【vlan口】，vlan标签为1至4094之间的任意正整数#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码;} 1234567### 9-8获取被占用vlan#### Request- Method: **POST**- API: `http://controller:8000/api/switch/getUsedVlanList`- Params: - **uuid&lt;str, 必填&gt;**: 虚拟交换机UUID，唯一标识吗#### Response { “code”: API执行结果码，0-执行成功，其他正整数-执行失败的错误信息编码; “data”: [1, 23, 129, …]} 1234567## 10虚拟路由器### 10-1创建虚拟路由器#### Request- Method: **POST**- API: ```http://controller:8000/api/router/create Params: uuid(str.)*: 虚拟路由器UUID，唯一标识，必填，长度1~63 name(str.)*: 虚拟路由器名称，必填，长度1~63 number(int.)*: 虚拟路由器接口数量，默认值为2，必填 cidrList(list.)*: 虚拟路由器网段列表，必填 例如：[“192.168.1.0/24”, “192.168.2.0/24”] 网段的格式：网段地址/掩码位数， 网段不能重复。 imageName(str.)*: 镜像名称，必填，长度1~63 userId(int.)*: 用户ID，必填 10-2删除虚拟路由器Request Method: POST API: 1234567- Params: - **uuid**(str.)*: 虚拟路由器UUID，唯一标识，必填，长度1~63### 10-3查看虚拟路由器配置 #### Request- Method: **POST**- API: ```http://controller:8000/api/router/show Params: uuid(str.)*: 虚拟路由器UUID，唯一标识，必填，长度1~63 Response Body123456789101112131415&#123; &quot;code&quot;: 0, &quot;data&quot;: [ &#123; &quot;number&quot;: 0, &quot;cidr&quot;: &quot;192.168.1.0/24&quot;, &quot;gateway&quot;: &quot;192.168.1.1&quot; &#125;, &#123; &quot;number&quot;: 1, &quot;cidr&quot;: &quot;192.168.2.0/24&quot;, &quot;gateway&quot;: &quot;192.168.2.1&quot; &#125; ]&#125; 10-4虚拟路由器上传镜像Request Method: POST API: 12345678910- Params: - **name**(str.)*: 镜像名称，必填 - **url**(str.)*: 镜像路径，必填 虚拟路由器镜像默认1VCPU，1G内存，10G磁盘### 10-5虚拟路由器删除镜像 #### Request- Method: **POST**- API: ```http://controller:8000/api/router/deleteImg Params: name(str.)*: 镜像名称，必填]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
>>>>>>> 9e302a13055574168cd05b455b005761c6bd137a
